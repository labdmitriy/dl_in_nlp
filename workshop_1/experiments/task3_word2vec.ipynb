{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive word2vec\n",
    "\n",
    "This task can be formulated very simply. Follow this [paper](https://arxiv.org/pdf/1411.2738.pdf) and implement word2vec like a two-layer neural network with matrices $W$ and $W'$. One matrix projects words to low-dimensional 'hidden' space and the other - back to high-dimensional vocabulary space.\n",
    "\n",
    "![word2vec](https://i.stack.imgur.com/6eVXZ.jpg)\n",
    "\n",
    "You can use TensorFlow/PyTorch (numpy too, if you love to calculate gradients on your own and want some extra points, but don't forget to numerically check your gradients) and code from your previous task. Again: you don't have to implement negative sampling (you may reduce your vocabulary size for faster computation).\n",
    "\n",
    "**Results of this task**:\n",
    " * trained word vectors (mention somewhere, how long it took to train)\n",
    " * plotted loss (so we can see that it has converged)\n",
    " * function to map token to corresponding word vector\n",
    " * beautiful visualizations (PCE, T-SNE), you can use TensorBoard and play with your vectors in 3D (don't forget to add screenshots to the task)\n",
    " * qualitative evaluations of word vectors: nearest neighbors, word analogies\n",
    "\n",
    "**Extra:**\n",
    " * quantitative evaluation:\n",
    "   * for intrinsic evaluation you can find datasets [here](https://aclweb.org/aclwiki/Analogy_(State_of_the_art))\n",
    "   * for extrincis evaluation you can use [these](https://medium.com/@dataturks/rare-text-classification-open-datasets-9d340c8c508e)\n",
    "\n",
    "Also, you can find any other datasets for quantitative evaluation. If you chose to do this, please use the same datasets across tasks 3, 4, 5 and 6.\n",
    "\n",
    "Again. It is **highly recommended** to read this [paper](https://arxiv.org/pdf/1411.2738.pdf)\n",
    "\n",
    "Example of visualization in tensorboard:\n",
    "https://projector.tensorflow.org\n",
    "\n",
    "Example of 2D visualisation:\n",
    "\n",
    "![2dword2vec](https://www.tensorflow.org/images/tsne.png)\n",
    "\n",
    "If you struggle with something, ask your neighbor. If it is not obvious for you, probably someone else is looking for the answer too. And in contrast, if you see that you can help someone - do it! Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from itertools import islice, product, chain\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "MODELS_PATH = Path('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGramBatcher():\n",
    "    def __init__(self, text):\n",
    "        self.text = text\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file(cls, file_path):\n",
    "        with open(file_path) as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        return cls(text)\n",
    "    \n",
    "    def _tokenize(self):\n",
    "        self.tokens = self.text.split()\n",
    "    \n",
    "    def _count_tokens(self):\n",
    "        self.token_counts = Counter(self.tokens)\n",
    "    \n",
    "    def _build_vocab(self, cutoff):\n",
    "        filtered_token_counts = dict(filter(lambda x: x[1] >= cutoff, self.token_counts.items()))\n",
    "        self.token_to_idx = {token:idx for (idx, (token, _)) \n",
    "                             in enumerate(filtered_token_counts.items())}\n",
    "        self.idx_to_token = {idx:token for (token, idx) in self.token_to_idx.items()}\n",
    "        self.vocab = set(self.token_to_idx)\n",
    "\n",
    "    def _filter_tokens(self):\n",
    "        self.tokens = [token for token in self.tokens if token in self.vocab]\n",
    "    \n",
    "    def _vectorize_tokens(self):\n",
    "        self.vectorized_tokens = [self.token_to_idx[token] for token in self.tokens]\n",
    "    \n",
    "    def _create_sliding_window(self, window_size):\n",
    "        tokens_size = len(self.tokens)\n",
    "\n",
    "        for i in range(0, tokens_size):\n",
    "#             center_word = islice(self.vectorized_tokens, i, i + 1)\n",
    "#             left_context = islice(self.vectorized_tokens, i + 1, \n",
    "#                                   min(tokens_size, i + window_size + 1))\n",
    "#             right_context = islice(self.vectorized_tokens, \n",
    "#                                    max(0, i - window_size), i)\n",
    "#             yield from product(center_word, chain(left_context, right_context))\n",
    "            center_word = self.vectorized_tokens[i:i+1]\n",
    "#             context = []\n",
    "#             context.extend(self.vectorized_tokens[max(0, i - window_size): i])\n",
    "#             context.extend(self.vectorized_tokens[i + 1: min(tokens_size, i + window_size + 1)])\n",
    "            left_context = self.vectorized_tokens[max(0, i - window_size): i]\n",
    "            right_context = self.vectorized_tokens[i + 1: min(tokens_size, i + window_size + 1)]\n",
    "            yield from product(center_word, chain(left_context, right_context))\n",
    "        \n",
    "    def devectorize_tokens(self, indices):\n",
    "        return [self.idx_to_token[idx] for idx in indices]\n",
    "        \n",
    "    def prepare_data(self, cutoff=1):\n",
    "        self._tokenize()\n",
    "        self._count_tokens()\n",
    "        self._build_vocab(cutoff)\n",
    "        self._filter_tokens()\n",
    "        self._vectorize_tokens()\n",
    "        \n",
    "    def generate_batches(self, window_size=1, batch_size=1, drop_last=True):\n",
    "        window = self._create_sliding_window(window_size)\n",
    "        batch = list(zip(*islice(window, batch_size)))\n",
    "        x_batch, labels_batch = torch.tensor(batch[0]), torch.tensor(batch[1])\n",
    "\n",
    "        if drop_last:\n",
    "            while batch and len(batch[0]) == batch_size:\n",
    "                yield x_batch, labels_batch\n",
    "                batch = list(zip(*islice(window, batch_size)))\n",
    "                x_batch, labels_batch = torch.tensor(batch[0]), torch.tensor(batch[1])\n",
    "        else:\n",
    "            while batch:\n",
    "                yield x_batch, labels_batch\n",
    "                batch = list(zip(*islice(window, batch_size)))\n",
    "                x_batch, labels_batch = torch.tensor(batch[0]), torch.tensor(batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveWord2VecClassifier(nn.Module):\n",
    "    def __init__(self, vocabulary_size, embedding_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.utils.weight_norm(nn.Embedding(num_embeddings=vocabulary_size,\n",
    "                                      embedding_dim=embedding_size), dim=1)\n",
    "#                                       max_norm=1.0)\n",
    "#                                       scale_grad_by_freq=True)\n",
    "                                      \n",
    "        self.fc1 = nn.utils.weight_norm(nn.Linear(in_features=embedding_size,\n",
    "                             out_features=vocabulary_size,\n",
    "                             bias=False), dim=1)\n",
    "        \n",
    "    def forward(self, x_in):\n",
    "#         self.embedding.weight.data = F.normalize(self.embedding.weight.data, p=2, dim=1)\n",
    "#         self.fc1.weight.data = F.normalize(self.fc1.weight.data, p=2, dim=1)\n",
    "        x_embedded = self.embedding(x_in)\n",
    "        y_out = self.fc1(x_embedded)\n",
    "        \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    file_path = DATA_PATH/'text8',\n",
    "    model_state_path = MODELS_PATH/'naive_word2vec_embeddings.pth',\n",
    "    \n",
    "    embedding_size = 100,\n",
    "    \n",
    "    seed = 42,\n",
    "    cutoff = 10, # 10\n",
    "    window_size = 3, # 1\n",
    "    batch_size = 1024, #  1024\n",
    "    learning_rate = 0.03, # 0.03\n",
    "    iterations = 1000,\n",
    "    save_iterations = 100,\n",
    "    early_stopping_criteria = 1e8,\n",
    "    factor=0.7, # 0.7\n",
    "    patience=1e8, # 1000\n",
    "    \n",
    "    cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': [], # args.learning_rate\n",
    "            'batch_idx': 0,\n",
    "            'loss': [],\n",
    "            'model_file_name': args.model_state_path}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    if train_state['batch_idx'] == 0:\n",
    "        train_state['stop_early'] = False\n",
    "        torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "    else:\n",
    "        loss = train_state['loss'][-1]\n",
    "\n",
    "        if loss < train_state['early_stopping_best_val']:\n",
    "            train_state['early_stopping_best_val'] = loss\n",
    "            train_state['early_stopping_step'] = 0\n",
    "            \n",
    "            if train_state['batch_idx'] % args.save_iterations == 0:\n",
    "                torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "        else:\n",
    "            train_state['early_stopping_step'] += 1 \n",
    "    \n",
    "        train_state['stop_early'] = train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    args.cuda=False\n",
    "    \n",
    "print(f'Using CUDA: {args.cuda}')\n",
    "args.device = torch.device('cuda' if args.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47134"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_batcher = SkipGramBatcher.from_file(args.file_path)\n",
    "sg_batcher.prepare_data(cutoff=args.cutoff)\n",
    "\n",
    "vocabulary_size = len(sg_batcher.vocab)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f47eaeddb34e00a8f21307ec2a70f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=97037, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds(args.seed)\n",
    "\n",
    "classifier = NaiveWord2VecClassifier(vocabulary_size=vocabulary_size,\n",
    "                                     embedding_size=args.embedding_size)\n",
    "classifier = classifier.to(args.device)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = optim.Adam(params=classifier.parameters(),\n",
    "                      lr=args.learning_rate)\n",
    "\n",
    "epoch_size = 2 * (args.window_size * len(sg_batcher.tokens) \n",
    "                  - np.math.factorial(args.window_size)) // args.batch_size\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min',\n",
    "                                                 factor=args.factor,\n",
    "                                                 patience=args.patience)\n",
    "\n",
    "train_bar = tqdm_notebook(desc='Training',\n",
    "                          position=1,\n",
    "#                           total=args.iterations,\n",
    "                          total=epoch_size)\n",
    "\n",
    "batch_generator = sg_batcher.generate_batches(window_size=args.window_size, \n",
    "                                              batch_size=args.batch_size)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "writer = SummaryWriter(log_dir='logs/task_3', comment='embedding_training')\n",
    "\n",
    "running_loss = 0.\n",
    "classifier.train()\n",
    "\n",
    "try:\n",
    "    for batch_idx, (x_batch, labels_batch) in enumerate(batch_generator, 1):\n",
    "        x_batch = x_batch.to(args.device)\n",
    "        labels_batch = labels_batch.to(args.device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = classifier(x_in=x_batch)\n",
    "\n",
    "        loss = loss_func(y_pred, labels_batch)\n",
    "        loss_value = loss.item()\n",
    "        running_loss += (loss_value - running_loss) / (batch_idx)\n",
    "        loss.backward()\n",
    "        \n",
    "        learning_rate = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        train_state['batch_idx'] = batch_idx\n",
    "        train_state['loss'].append(running_loss)\n",
    "        train_state['learning_rate'].append(learning_rate)\n",
    "#         writer.add_scalar('loss', scalar_value=loss, global_step=batch_idx)\n",
    "\n",
    "\n",
    "        train_state = update_train_state(args=args,\n",
    "                                         model=classifier,\n",
    "                                         train_state=train_state)\n",
    "\n",
    "        train_params = dict(loss=running_loss,\n",
    "                            lr=learning_rate,\n",
    "                            early_step=train_state['early_stopping_step'],\n",
    "                            early_best=train_state['early_stopping_best_val'])\n",
    "        train_bar.set_postfix(train_params)\n",
    "        train_bar.update()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step(train_state['loss'][-1])\n",
    "\n",
    "        if train_state['stop_early'] or (batch_idx == epoch_size):\n",
    "            break\n",
    "except KeyboardInterrupt:\n",
    "    print('Exit training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_state_df = pd.DataFrame(train_state)\n",
    "train_state_df['loss'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_state_df['learning_rate'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = list(sg_batcher.token_to_idx)\n",
    "W = classifier.embedding.weight.cpu().detach().numpy()\n",
    "W_prime = classifier.fc1.weight.cpu().detach().numpy()\n",
    "\n",
    "W_avg = (W + W_prime) / 2\n",
    "\n",
    "# writer.add_embedding(W, metadata=metadata, tag='W')\n",
    "# writer.add_embedding(W_prime, metadata=metadata, tag='W_prime')\n",
    "writer.add_embedding(W_avg, metadata=metadata, tag='W_avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-14.473473, 11.7224245, -0.7215085, 0.4329951)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.min(), W.max(), W_prime.min(), W_prime.max()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.heatmap(W)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.heatmap(W_prime)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sns.heatmap(W_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "state_dict = torch.load('../models/naive_word2vec_embeddings_final.pth', map_location='cpu')\n",
    "\n",
    "clf = NaiveWord2VecClassifier(vocabulary_size=vocabulary_size,\n",
    "                              embedding_size=100)\n",
    "clf.load_state_dict(state_dict)\n",
    "\n",
    "W = clf.embedding.weight.detach().numpy()\n",
    "W_prime = clf.fc1.weight.detach().numpy()\n",
    "W_avg = (W + W_prime) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 14.870188, 7.609984)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_norm = W / np.linalg.norm(W, axis=1, keepdims=True)\n",
    "W_prime_norm = W_avg / np.linalg.norm(W_prime, axis=1, keepdims=True)\n",
    "W_avg_norm = (W_norm + W_prime_norm) / 2\n",
    "np.abs(W_norm).max(), np.abs(W_prime_norm).max(), np.abs(W_avg_norm).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from umap import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(embs_reduced, token_to_idx, tokens):\n",
    "    token_embs = embs_reduced[[token_to_idx[token] for token in tokens]]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    ax.scatter(token_embs[:, 0], token_embs[:, 1], alpha=0.2)\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        ax.annotate(token, (token_embs[i, 0], token_embs[i, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 356 ms, sys: 8 ms, total: 364 ms\n",
      "Wall time: 93.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pca = PCA(n_components=2)\n",
    "embs_pca = pca.fit_transform(W_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAKvCAYAAABpkwknAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XvU3XV94Pv3N5cnEhHhFLAeJQWnHFAuEgiWS9UI3ma0YFvapUNHnKlVa2fpzBpHS88UGTvTTkdX7XJ6qtXRSrVaOqAedNpVvAPtjPBEUI8ohUq8jSOgEAmJzYXf+SMxhRhMgOR5Anm91noW+/Lde382P3d4+8tv/54xTVMAALCvWzDfAwAAwN5AGAMAQMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKhq0Xy98MEHHzwdfvjh8/XyAADsI1atWnXbNE2H7GzdvIXx4Ycf3uzs7Hy9PAAA+4gxxld3ZZ1DKQAAIGEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgDAXmT16tUde+yx97ptdna2V73qVfM0EfuSRfM9AADAj7JixYpWrFgx32OwD7DHGADYK33lK19p+fLlvfGNb+z5z39+VRdeeGH/4l/8i1auXNkTnvCE3vKWt2xb/1u/9VsdffTRPetZz+pFL3pRb3rTm+ZrdB6i7DEGAPY6N9xwQy984Qv74z/+4+64444+/elPb7vvy1/+cp/85Ce78847O+qoo/rVX/3VPve5z3XppZd27bXXtmnTpk488cROOumkeXwHPBTZYwwA7FVuvfXWzj777N773vd2wgkn/ND9z3ve81qyZEkHH3xwhx56aN/+9re76qqrOvvss9tvv/161KMe1c/8zM/Mw+Q81NljDADMqzvWbejm2+7qe+s3tva2NT3qgAM67LDD+uu//uuOOeaYH1q/ZMmSbZcXLlzYpk2bmqZpLkfmYcoeYwBg3tyxbkPXfu32Nmy6u4OWzrRh891tbmHvft+f9yd/8ie9733v26Xn+emf/uk+/OEP9/3vf7+1a9f23//7f9/Dk/NwJIwBgHlz8213tXRmUUtnFjXGaL/FC1swRresr4985CO9+c1vbs2aNTt9npNPPrmzzjqrJz/5yf3cz/1cK1as6NGPfvQcvAMeTsZ8/dXDihUrptnZ2Xl5bQBg7/DpG27poKUzjTG23TZNU7ev29DTjzr0fj3X2rVr23///Vu3bl1Pe9rTevvb396JJ564u0fmIWiMsWqapp2e888xxgDAvDlgv8Wt37i5pTP/kCTrN27ugP0W3+/netnLXtb111/f97///c477zxRzP0mjAGAeXPEwY/s2q/dXtV+ixe2fuPm1m3Y1FE/ftD9fq5dPR4Z7otjjAGAeXPg0pmWLzuomUULun3dhmYWLWj5soM6cOnMfI/GPsgeYwBgXm2JYyHM/LPHGAAAEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAgDnyH//jf+yoo47qmc98Zi960Yt605ve1MqVK5udna3qtttu6/DDD69q8+bN/dt/+287+eSTO/744/ujP/qjbc/zxje+cdvtr3/966tavXp1T3ziE/uVX/mVjjnmmJ797Ge3fv36+zWfMAYAYI9btWpVf/Znf9a1117bBz7wga655pofuf6d73xnj370o7vmmmu65ppresc73tHNN9/c5Zdf3o033tjVV1/ddddd16pVq7riiiuquvHGG/u1X/u1vvjFL3bggQd26aWX3q8ZFz3gdwcAALvoyiuv7Gd/9mdbunRpVWedddaPXH/55Zf3+c9/vksuuaSqNWvWdOONN3b55Zd3+eWXt3z58qrWrl3bjTfe2LJlyzriiCM64YQTqjrppJNavXr1/ZpRGAMAsEfcsW5DN992V99bv7Fv3L6uhZvu/qE1ixYt6u67t9z+/e9/f9vt0zT1X/7Lf+k5z3nOvdb/1V/9Veeff34vf/nL73X76tWrW7JkybbrCxcudCgFAADz7451G7r2a7e3YdPdHbR0puNOOqVLLv1A3/rOmu68884+/OEPV3X44Ye3atWqqm17h6ue85zn9Na3vrWNGzdW9bd/+7fdddddPec5z+ld73pXa9eureqb3/xmt9xyy26Z2R5jAAB2u5tvu6ulM4taOrMlN0888aSe9fyf7dSnrOj/+kdH9NSnPrWq17zmNf3iL/5i73nPezrjjDO2Pf6lL31pq1ev7sQTT2yapg455JA+9KEP9exnP7svfelLnXrqqVXtv//+vfe9723hwoUPeuYxTdODfpIHYsWKFdMPvoEIAMDDy6dvuKWDls40xth22zRN3b5uQ08/6tAuvPDC9t9//17zmtfs8VnGGKumaVqxs3UOpQAAYLc7YL/Frd+4+V63rd+4uQP2WzxPE+2cQykAANjtjjj4kV37tdur2m/xwtZv3Ny6DZs66scPqurCCy+cx+l2zB5jAAB2uwOXzrR82UHNLFrQ7es2NLNoQcuXHdSBS2fme7T7ZI8xAAB7xJY43ntDeHv2GAMAQMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAACq+xHGY4yFY4xrxxgf2cF9Lxlj3DrGuG7rz0t375gAALBnLbofa19dfak64D7uv3iapn/54EcCAIC5t0t7jMcYj6+eV/3XPTsOAADMj109lOL3q9dWd/+INT8/xvj8GOOSMcZhD340AACYOzsN4zHG86tbpmla9SOWfbg6fJqm46uPVRfdx3O9bIwxO8aYvfXWWx/QwAAAsCfsyh7j06uzxhirqz+rzhhjvPeeC6Zp+s40TX+/9eo7qpN29ETTNL19mqYV0zStOOSQQx7E2AAAsHvtNIynaTp/mqbHT9N0ePXC6hPTNP3SPdeMMR57j6tnteVLegAA8JBxf85KcS9jjDdUs9M0XVa9aoxxVrWp+m71kt0zHgAAzI0xTdO8vPCKFSum2dnZeXltAAD2HWOMVdM0rdjZOr/5DgAAEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhiAfcCnPvWp/uZv/mbb9Ze85CVdcskl8zgRsDcSxgA87G0fxg/GNE3dfffdu+W5gL2LMAbgIWH16tUdffTRvfSlL+3YY4/t3HPP7WMf+1inn356Rx55ZFdffXXf/e53e8ELXtDxxx/fKaec0uc///lWr17d2972tt785jd3wgkndOWVV1Z1xRVXdNppp/WEJzzhXnuP3/jGN3byySd3/PHH9/rXv37baz/xiU/sla98ZSeeeGJf//rX5+XfAbBnLZrvAQBgV9100039t//233r729/eySef3Pve976uuuqqLrvssn77t3+7ww47rOXLl/ehD32oT3ziE734xS/uuuuu6xWveEX7779/r3nNa6p65zvf2be+9a2uuuqqvvzlL3fWWWd1zjnndPnll3fjjTd29dVXN01TZ511VldccUXLli3rhhtu6I//+I/7wz/8w3n+twDsKcIYgL3aHes2dPNtd3XD393W/3nYT3TYPzqqBQsWdMwxx3TmmWc2xui4445r9erVffWrX+3SSy+t6owzzug73/lOa9as2eHzvuAFL2jBggU96UlP6tvf/nZVl19+eZdffnnLly+vau3atd14440tW7asn/iJn+iUU06ZmzcNzAthDMBe6451G7r2a7e3dGZRj95vpsWLZ7r2a7e3fNlBLViwoCVLllS1YMGCNm3a1KJFP/yftTHGDp/7B4+tLccN/+Cf559/fi9/+cvvtXb16tU98pGP3F1vC9hLOcYYgL3Wzbfd1dKZRS2dWdQYWyJ36cyibr7trh2uf9rTntaf/umfVlu+cHfwwQd3wAEH9KhHPao777xzp6/3nOc8p3e9612tXbu2qm9+85vdcsstu+8NAXs1YQzAXut76ze23+KF97ptv8UL+976jTtcf+GFFzY7O9vxxx/fr//6r3fRRRdV9TM/8zN98IMfvNeX73bk2c9+dv/0n/7TTj311I477rjOOeecXQpqtnjLW97SE5/4xM4999wd3n/dddf1F3/xF9uuX3jhhb3pTW+aq/Fgp8YP/vporq1YsWKanZ2dl9cG4KHh2q/d3oZNd7d05h8OkVi3YVMzixa0fNlB8zgZO3L00Uf3l3/5lx1xxBE7vP/d7353s7Oz/cEf/EG1JYzv+aXI+2vz5s0tXLhw5wvZ540xVk3TtGJn6+wxBmCvdcTBj2zdhk2t27CpaZq2XT7iYMf77m1e8YpX9JWvfKWzzjqr3/3d3+20005r+fLlnXbaad1www1t2LChCy64oIsvvrgTTjihiy++uKrrr7++lStX9oQnPKG3vOUt257vve99b095ylM64YQTevnLX97mzZur2n///bvgggv6qZ/6qf7H//gf8/JeefiyxxiAvdoPzkrxvfUbO2C/xR1x8CM7cOnMfI/FDhx++OHNzs42MzPT0qVLW7RoUR/72Md661vf2qWXXrrDPcaXX355n/zkJ7vzzjs76qij+t//+39300039drXvrYPfOADLV68uFe+8pWdcsopvfjFL26M0cUXX9wv/uIvzvO75aFkV/cYOysFAHu1A5fOtHyZEH4oWbNmTeedd1433nhjY4w2btzxMeFVz3ve81qyZElLlizp0EMP7dvf/nYf//jHW7VqVSeffHJV69ev79BDD61q4cKF/fzP//ycvA/2PcIYAHjA7rlHf8Pmu1uzbkO/dcFv9oxnPKMPfvCDrV69upUrV97n4+952ryFCxe2adOWw2bOO++8fud3fueH1j/iEY9wXDF7jGOMAYAH5Afnmd6w6e4OWjrTNNUXvnlHt3339h73uMdVW75w9wO7etq8M888s0suuWTbqfK++93v9tWvfnWPvAe4J2EMADwg9z7P9GjBqP0WL+qcf/7Kzj///E4//fRtX5qresYzntH1119/ry/f7ciTnvSk/sN/+A89+9nP7vjjj+9Zz3pW3/rWt+biLbGP8+U7AOAB+fQNt3TQ0pl7/XbBaZq6fd2Gnn7UofM4Gdyb07UBAHvUAfstbv3Gzfe6bf3GzR2w3+J5mggeHGEMADwgzjPNw40wBgAekC2n0juomUULun3dhm2/kdB5pnmocro2AOABc55pHk7sMQYAgIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQHU/wniMsXCMce0Y4yM7uG/JGOPiMcZNY4zPjDEO351DAgDAnnZ/9hi/uvrSfdz3y9Xt0zT9ZPXm6ncf7GAAADCXdimMxxiPr55X/df7WHJ2ddHWy5dUZ44xxoMfDwAA5sau7jH+/eq11d33cf/jqq9XTdO0qVpT/diDng4AAObITsN4jPH86pZpmlb9qGU7uG3awXO9bIwxO8aYvfXWW+/HmAAAsGftyh7j06uzxhirqz+rzhhjvHe7Nd+oDqsaYyyqHl19d/snmqbp7dM0rZimacUhhxzyoAYHAIDdaadhPE3T+dM0PX6apsOrF1afmKbpl7Zbdll13tbL52xd80N7jAEAYG+16IE+cIzxhmp2mqbLqndW7xlj3NSWPcUv3E3zAQDAnLhfYTxN06eqT229fME9bv9+9Qu7czAAAJhLfvMdAAAkjAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAANUuhPEY4xFjjKvHGJ8bY3xxjPHvd7DmJWOMW8cY1239eemeGRcAAPaMRbuw5u+rM6ZpWjvGWFxdNcb4y2ma/ud26y6epulf7v4RAQBgz9tpGE/TNFVrt15dvPVn2pNDAQDAXNulY4zHGAvHGNdVt1QfnabpMztY9vNjjM+PMS4ZYxx2H8/zsjHG7Bhj9tZbb30QYwMAwO61S2E8TdPmaZpOqB5fPWWMcex2Sz5cHT5N0/HVx6qL7uN53j5N04ppmlYccsghD2ZuAADYre7XWSmmabqj+lT13O1u/840TX+/9eo7qpN2y3QAADBHduWsFIeMMQ7cenm/6pnVl7db89h7XD2r+tLuHBIAAPa0XTkrxWOri8YYC9sS0n8+TdNHxhhvqGanabqsetUY46xqU/Xd6iV7amAAANgTxpaTTsy9FStWTLOzs/Py2gAA7DvGGKumaVqxs3V+8x0AACSMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAAKpdCOMxxiPGGFePMT43xvjiGOPf72DNkjHGxWOMm8YYnxljHL4nhgUAgD1lV/YY/311xjRNT65OqJ47xjhluzW/XN0+TdNPVm+ufnf3jgkAAHvWTsN42mLt1quLt/5M2y07u7po6+VLqjPHGGO3TQkAAHvYLh1jPMZYOMa4rrql+ug0TZ/Zbsnjqq9XTdO0qVpT/djuHBQAAPakXQrjaZo2T9N0QvX46iljjGO3W7KjvcPb71VujPGyMcbsGGP21ltvvf/TAgDAHnK/zkoxTdMd1aeq52531zeqw6rGGIuqR1ff3cHj3z5N04ppmlYccsghD2hgAADYE3blrBSHjDEO3Hp5v+qZ1Ze3W3ZZdd7Wy+dUn5im6Yf2GAMAwN5q0S6seWx10RhjYVtC+s+nafrIGOMN1ew0TZdV76zeM8a4qS17il+4xyYGAIA9YKdhPE3T56vlO7j9gntc/n71C7t3NAAAmDt+8x0AACSMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBqHw7j//yf/3NvectbqvrX//pfd8YZZ1T18Y9/vF/6pV/q/e9/f8cdd1zHHntsr3vd67Y9bv/99+91r3tdJ510Us985jO7+uqrW7lyZU94whO67LLLqlq9enVPfepTO/HEEzvxxBP7m7/5m6o+9alPtXLlys4555yOPvrozj333KZpmuN3DgDAjuyzYfy0pz2tK6+8sqrZ2dnWrl3bxo0bu+qqqzryyCN73ete1yc+8Ymuu+66rrnmmj70oQ9Vddddd7Vy5cpWrVrVox71qP7dv/t3ffSjH+2DH/xgF1xwQVWHHnpoH/3oR/vsZz/bxRdf3Kte9aptr3vttdf2+7//+11//fV95Stf6a//+q/n/s0DAPBD9tkwPumkk1q1alV33nlnS5Ys6dRTT212drYrr7yyAw88sJUrV3bIIYe0aNGizj333K644oqqZmZmeu5zn1vVcccd19Of/vQWL17ccccd1+rVq6vauHFjv/Irv9Jxxx3XL/zCL3T99ddve92nPOUpPf7xj2/BggWdcMIJ2x4DAMD8WjTfA8y1O9Zt6Obb7up76zf2Yz/++P7wj97Raaed1vHHH98nP/nJ/u7v/q5ly5a1atWqHT5+8eLFjTGqWrBgQUuWLNl2edOmTVW9+c1v7jGPeUyf+9znuvvuu3vEIx6x7fE/WF+1cOHCbY8BAGB+7VN7jO9Yt6Frv3Z7Gzbd3UFLZ3ryyaf0e7/3e534lFN76lOf2tve9rZOOOGETjnllD796U932223tXnz5t7//vf39Kc/fZdfZ82aNT32sY9twYIFvec972nz5s178F0BALA77FNhfPNtd7V0ZlFLZxY1xuinTv3pvnPrtzv0J4/rMY95TI94xCN66lOf2mMf+9h+53d+p2c84xk9+clP7sQTT+zss8/e5dd55Stf2UUXXdQpp5zS3/7t3/bIRz5yD74rAAB2hzFfZ0VYsWLFNDs7O6ev+ekbbumgpTPbDoWomqap29dt6OlHHTqnswAAMDfGGKumaVqxs3X71B7jA/Zb3PqN9z6sYf3GzR2w3+J5mggAgL3FPhXGRxz8yNZt2NS6DZuapmnb5SMOdqgDAMC+bp8K4wOXzrR82UHNLFrQ7es2NLNoQcuXHdSBS2fmezQAAObZPne6ti1xLIQBALi3fWqPMQAA3BdhDAAACWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKh2IYzHGIeNMT45xvjSGOOLY4xX72DNyjHGmjHGdVt/Ltgz4wIAwJ6xaBfWbKr+zTRNnx1jPKpaNcb46DRN12+37sppmp6/+0cEAIA9b6d7jKdp+tY0TZ/devnO6kvV4/b0YAAAMJfu1zHGY4zDq+XVZ3Zw96ljjM+NMf5yjHHMbpgNAADmzK4cSlHVGGP/6tLqX03T9L3t7v5s9RPTNK0dY/yT6kPVkTt4jpdVL6tatmzZAx4aAAB2t13aYzzGWNyWKP7TaZo+sP390zR9b5qmtVsv/0W1eIxx8A7WvX2aphXTNK045JBDHuToAACw++zKWSlG9c7qS9M0/d59rPnxresaYzxl6/N+Z3cOCgAAe9KuHEpxevXPqi+MMa7bettvVMuqpml6W3VO9atjjE3V+uqF0zRNe2BeAADYI3YaxtM0XVWNnaz5g+oPdtdQAAAw1/zmOwAASBgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgDE67rNAAAIIUlEQVSAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMfNk9erVHX300b30pS/t2GOP7dxzz+1jH/tYp59+ekceeWRXX311V199daeddlrLly/vtNNO64Ybbqjq3e9+dz/3cz/Xc5/73I488she+9rXzvO7AQAeDoQx8+amm27q1a9+dZ///Of78pe/3Pve976uuuqq3vSmN/Xbv/3bHX300V1xxRVde+21veENb+g3fuM3tj32uuuu6+KLL+4LX/hCF198cV//+tfn8Z0AAA8Hi+Z7APZdRxxxRMcdd1xVxxxzTGeeeWZjjI477rhWr17dmjVrOu+887rxxhsbY7Rx48Ztjz3zzDN79KMfXdWTnvSkvvrVr3bYYYfNy/sAAB4ehDFz5o51G7r5trv63vqNrb1tTYsWz2y7b8GCBS1ZsmTb5U2bNvWbv/mbPeMZz+iDH/xgq1evbuXKldvW/2Bt1cKFC9u0adOcvQ8A4OHJoRTMiTvWbejar93ehk13d9DSmTZsvrvvb9zcHes23Odj1qxZ0+Me97hqy3HFAAB7kjBmTtx8210tnVnU0plFjTHab/HCFozRzbfddZ+Pee1rX9v555/f6aef3ubNm+dwWgBgXzSmaZqXF16xYsU0Ozs7L6/N3Pv0Dbd00NKZxhjbbpumqdvXbejpRx06j5MBAA93Y4xV0zSt2Nk6e4yZEwfst7j1G++913f9xs0dsN/ieZoIAODehDFz4oiDH9m6DZtat2FT0zRtu3zEwY+c79EAACphzBw5cOlMy5cd1MyiBd2+bkMzixa0fNlBHbh0ZucPBgCYA07XxpzZEsdCGADYO9ljDAAACWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKhqTNM0Py88xq3VV+flxe/bwdVt8z0E95vt9tBjmz302GYPTbbbQ49ttmf8xDRNh+xs0byF8d5ojDE7TdOK+Z6D+8d2e+ixzR56bLOHJtvtocc2m18OpQAAgIQxAABUwnh7b5/vAXhAbLeHHtvsocc2e2iy3R56bLN55BhjAADIHmMAAKj28TAeY/wfY4yPjjFu3PrPg+5j3eYxxnVbfy6b6zmpMcZzxxg3jDFuGmP8+g7uXzLGuHjr/Z8ZYxw+91OyvV3Ybi8ZY9x6j8/XS+djTv7BGONdY4xbxhj/333cP8YYb9m6TT8/xjhxrmfk3nZhm60cY6y5x+fsgrmekXsbYxw2xvjkGONLY4wvjjFevYM1PmvzYJ8O4+rXq49P03Rk9fGt13dk/TRNJ2z9OWvuxqNqjLGw+n+qf1w9qXrRGONJ2y375er2aZp+snpz9btzOyXb28XtVnXxPT5f/3VOh2RH3l0990fc/4+rI7f+vKx66xzMxI/27n70Nqu68h6fszfMwUz8aJuqfzNN0xOrU6pf28Gfjz5r82BfD+Ozq4u2Xr6oesE8zsJ9e0p10zRNX5mmaUP1Z23Zdvd0z215SXXmGGPM4Yz8sF3Zbuxlpmm6ovruj1hydvUn0xb/szpwjPHYuZmOHdmFbcZeZpqmb03T9Nmtl++svlQ9brtlPmvzYF8P48dM0/St2vI/0urQ+1j3iDHG7Bjjf44xxPPce1z19Xtc/0Y//AfItjXTNG2q1lQ/NifTcV92ZbtV/fzWvya8ZIxx2NyMxoOwq9uVvcupY4zPjTH+coxxzHwPwz/Yeujf8uoz293lszYPFs33AHvaGONj1Y/v4K7/+348zbJpmv7XGOMJ1SfGGF+Ypunvds+E7IId7fnd/nQqu7KGubUr2+TD1funafr7McYr2rLX/4w9PhkPhs/aQ89n2/LrcNeOMf5J9aG2/PU882yMsX91afWvpmn63vZ37+AhPmt72MM+jKdpeuZ93TfG+PYY47HTNH1r619P3HIfz/G/tv7zK2OMT7Xl/9kJ47nzjeqeexIfX/2v+1jzjTHGourR+avF+bbT7TZN03fucfUdOTb8oWBXPo/sRe4ZXNM0/cUY4w/HGAdP03TbfM61rxtjLG5LFP/pNE0f2MESn7V5sK8fSnFZdd7Wy+dV/+/2C8YYB40xlmy9fHB1enX9nE1I1TXVkWOMI8YYM9UL27Lt7ume2/Kc6hOTk3TPt51ut+2OlzurLcfZsXe7rHrx1m/Mn1Kt+cEhaeydxhg//oPvXIwxntKW//Z/50c/ij1p6/Z4Z/WlaZp+7z6W+azNg4f9HuOd+E/Vn48xfrn6WvULVWOMFdUrpml6afXE6o/GGHe35Q+T/zRNkzCeQ9M0bRpj/Mvqr6qF1bumafriGOMN1ew0TZe15Q+Y94wxbmrLnuIXzt/E1C5vt1eNMc5qyze0v1u9ZN4GpqoxxvurldXBY4xvVK+vFldN0/S26i+qf1LdVK2r/vn8TMoP7MI2O6f61THGpmp99UI7Dubd6dU/q74wxrhu622/US0rn7X55DffAQBADqUAAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAVf3/B9hPM9rbVYUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = ['man', 'woman', 'king', 'queen', 'mother', 'father']\n",
    "# tokens = list(dict(sg_batcher.token_counts.most_common(100)).keys())\n",
    "plot_embeddings(embs_pca, sg_batcher.token_to_idx, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tsne = TSNE(n_components=2, n_iter=1000, n_jobs=-1)\n",
    "embs_tsne = tsne.fit_transform(W_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['man', 'woman', 'king', 'queen', 'mother', 'father']\n",
    "# tokens = list(dict(sg_batcher.token_counts.most_common(100)).keys())\n",
    "plot_embeddings(embs_tsne, sg_batcher.token_to_idx, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap = UMAP(metric='cosine')\n",
    "embs_umap = umap.fit_transform(W_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = ['man', 'woman', 'king', 'queen', 'mother', 'father']\n",
    "# tokens = list(dict(sg_batcher.token_counts.most_common(100)).keys())\n",
    "plot_embeddings(embs_umap, sg_batcher.token_to_idx, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsExplorer():\n",
    "    def __init__(self, token_to_idx, vectors, metric='euclidean'):\n",
    "        self.token_to_idx = token_to_idx\n",
    "        self.idx_to_token = {idx: token for token, idx \n",
    "                             in self.token_to_idx.items()}\n",
    "        self.vectors = vectors\n",
    "        self.metric = metric\n",
    "        \n",
    "        self.index = AnnoyIndex(vectors.shape[1], metric=metric)\n",
    "        \n",
    "        print('Building index is started')\n",
    "        for i in self.token_to_idx.values():\n",
    "            self.index.add_item(i, self.vectors[i])\n",
    "        \n",
    "        self.index.build(50)\n",
    "        print('Building index is finished')\n",
    "        \n",
    "    def get_embedding(self, token):\n",
    "        return self.vectors[self.token_to_idx[token]]\n",
    "    \n",
    "    def get_closest_to_vector(self, vector, n=1):\n",
    "        nn_indices = self.index.get_nns_by_vector(vector, n)\n",
    "        return [self.idx_to_token[neighbor] for neighbor in nn_indices]\n",
    "    \n",
    "    def compute_analogy(self, token1, token2, token3, n=20):\n",
    "        vec1 = self.get_embedding(token1)\n",
    "        vec2 = self.get_embedding(token2)\n",
    "        vec3 = self.get_embedding(token3)\n",
    "        vec4 = vec3 + vec2 - vec1\n",
    "        \n",
    "        tokens = set([token1, token2, token3])\n",
    "        closest_tokens = self.get_closest_to_vector(vec4, n=n)\n",
    "        closest_tokens = [token for token in closest_tokens\n",
    "                          if token not in tokens]\n",
    "        \n",
    "        if len(closest_tokens) == 0:\n",
    "            print('Could not find nearest neighbors for the computed vector')\n",
    "            return\n",
    "        \n",
    "        for token4 in closest_tokens:\n",
    "            print(f'{token1}:{token2} :: {token3}:{token4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building index is started\n",
      "Building index is finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingsExplorer at 0x7fd1c3b8b390>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = EmbeddingsExplorer(sg_batcher.token_to_idx, W_avg, metric='euclidean')\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man:he :: woman:she\n",
      "man:he :: woman:briefly\n",
      "man:he :: woman:himself\n",
      "man:he :: woman:him\n",
      "man:he :: woman:afterwards\n",
      "man:he :: woman:prison\n",
      "man:he :: woman:apparently\n",
      "man:he :: woman:parents\n",
      "man:he :: woman:publicly\n",
      "man:he :: woman:subsequently\n",
      "man:he :: woman:abroad\n",
      "man:he :: woman:reportedly\n",
      "man:he :: woman:marry\n",
      "man:he :: woman:allegedly\n",
      "man:he :: woman:succeed\n",
      "man:he :: woman:personally\n",
      "man:he :: woman:her\n",
      "man:he :: woman:formally\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('man', 'he', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fly:plane :: sail:circle\n",
      "fly:plane :: sail:outer\n",
      "fly:plane :: sail:ring\n",
      "fly:plane :: sail:probe\n",
      "fly:plane :: sail:blown\n",
      "fly:plane :: sail:gate\n",
      "fly:plane :: sail:segment\n",
      "fly:plane :: sail:junction\n",
      "fly:plane :: sail:spin\n",
      "fly:plane :: sail:burst\n",
      "fly:plane :: sail:intersection\n",
      "fly:plane :: sail:path\n",
      "fly:plane :: sail:grid\n",
      "fly:plane :: sail:crater\n",
      "fly:plane :: sail:mound\n",
      "fly:plane :: sail:deck\n",
      "fly:plane :: sail:arch\n",
      "fly:plane :: sail:tail\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('fly', 'plane', 'sail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitten:cat :: puppy:dog\n",
      "kitten:cat :: puppy:devil\n",
      "kitten:cat :: puppy:cow\n",
      "kitten:cat :: puppy:hey\n",
      "kitten:cat :: puppy:bird\n",
      "kitten:cat :: puppy:dwarf\n",
      "kitten:cat :: puppy:rat\n",
      "kitten:cat :: puppy:wolf\n",
      "kitten:cat :: puppy:leopard\n",
      "kitten:cat :: puppy:beast\n",
      "kitten:cat :: puppy:bean\n",
      "kitten:cat :: puppy:flower\n",
      "kitten:cat :: puppy:crazy\n",
      "kitten:cat :: puppy:dream\n",
      "kitten:cat :: puppy:dragon\n",
      "kitten:cat :: puppy:bottle\n",
      "kitten:cat :: puppy:pants\n",
      "kitten:cat :: puppy:chorus\n",
      "kitten:cat :: puppy:monkey\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('kitten', 'cat', 'puppy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue:color :: dog:breed\n",
      "blue:color :: dog:strokes\n",
      "blue:color :: dog:doubling\n",
      "blue:color :: dog:ideally\n",
      "blue:color :: dog:offspring\n",
      "blue:color :: dog:creature\n",
      "blue:color :: dog:joke\n",
      "blue:color :: dog:fitting\n",
      "blue:color :: dog:recipe\n",
      "blue:color :: dog:loud\n",
      "blue:color :: dog:obviously\n",
      "blue:color :: dog:clever\n",
      "blue:color :: dog:slice\n",
      "blue:color :: dog:strange\n",
      "blue:color :: dog:sticky\n",
      "blue:color :: dog:perfect\n",
      "blue:color :: dog:luck\n",
      "blue:color :: dog:tastes\n",
      "blue:color :: dog:tune\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('blue', 'color', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leg:legs :: hand:fingers\n",
      "leg:legs :: hand:hands\n",
      "leg:legs :: hand:side\n",
      "leg:legs :: hand:clothes\n",
      "leg:legs :: hand:neck\n",
      "leg:legs :: hand:horns\n",
      "leg:legs :: hand:surfaces\n",
      "leg:legs :: hand:ingredients\n",
      "leg:legs :: hand:balls\n",
      "leg:legs :: hand:wooden\n",
      "leg:legs :: hand:holes\n",
      "leg:legs :: hand:shoulders\n",
      "leg:legs :: hand:colours\n",
      "leg:legs :: hand:coloured\n",
      "leg:legs :: hand:teeth\n",
      "leg:legs :: hand:stones\n",
      "leg:legs :: hand:edges\n",
      "leg:legs :: hand:eyes\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('leg', 'legs', 'hand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toe:finger :: foot:leg\n",
      "toe:finger :: foot:shoulders\n",
      "toe:finger :: foot:shoulder\n",
      "toe:finger :: foot:neck\n",
      "toe:finger :: foot:bottom\n",
      "toe:finger :: foot:fingers\n",
      "toe:finger :: foot:arm\n",
      "toe:finger :: foot:bow\n",
      "toe:finger :: foot:legs\n",
      "toe:finger :: foot:front\n",
      "toe:finger :: foot:chest\n",
      "toe:finger :: foot:hanging\n",
      "toe:finger :: foot:roof\n",
      "toe:finger :: foot:door\n",
      "toe:finger :: foot:deck\n",
      "toe:finger :: foot:face\n",
      "toe:finger :: foot:tail\n",
      "toe:finger :: foot:plate\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('toe', 'finger', 'foot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "talk:communicate :: read:manipulate\n",
      "talk:communicate :: read:translate\n",
      "talk:communicate :: read:commands\n",
      "talk:communicate :: read:dynamically\n",
      "talk:communicate :: read:merge\n",
      "talk:communicate :: read:integrate\n",
      "talk:communicate :: read:reproduce\n",
      "talk:communicate :: read:convert\n",
      "talk:communicate :: read:modify\n",
      "talk:communicate :: read:efficiently\n",
      "talk:communicate :: read:enlarge\n",
      "talk:communicate :: read:rendered\n",
      "talk:communicate :: read:cipher\n",
      "talk:communicate :: read:confuse\n",
      "talk:communicate :: read:render\n",
      "talk:communicate :: read:interrupts\n",
      "talk:communicate :: read:sorted\n",
      "talk:communicate :: read:interpret\n",
      "talk:communicate :: read:removing\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('talk', 'communicate', 'read')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man:king :: woman:son\n",
      "man:king :: woman:prince\n",
      "man:king :: woman:crowned\n",
      "man:king :: woman:elizabeth\n",
      "man:king :: woman:heir\n",
      "man:king :: woman:daughter\n",
      "man:king :: woman:viii\n",
      "man:king :: woman:cousin\n",
      "man:king :: woman:queen\n",
      "man:king :: woman:throne\n",
      "man:king :: woman:illegitimate\n",
      "man:king :: woman:augustus\n",
      "man:king :: woman:princess\n",
      "man:king :: woman:vii\n",
      "man:king :: woman:henry\n",
      "man:king :: woman:chancellor\n",
      "man:king :: woman:regent\n",
      "man:king :: woman:aragon\n",
      "man:king :: woman:nephew\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('man', 'king', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man:doctor :: woman:christina\n",
      "man:doctor :: woman:child\n",
      "man:doctor :: woman:boyfriend\n",
      "man:doctor :: woman:gertrude\n",
      "man:doctor :: woman:sara\n",
      "man:doctor :: woman:preacher\n",
      "man:doctor :: woman:survivor\n",
      "man:doctor :: woman:janet\n",
      "man:doctor :: woman:dio\n",
      "man:doctor :: woman:farmer\n",
      "man:doctor :: woman:researcher\n",
      "man:doctor :: woman:lawyer\n",
      "man:doctor :: woman:marrying\n",
      "man:doctor :: woman:precocious\n",
      "man:doctor :: woman:secretly\n",
      "man:doctor :: woman:superstar\n",
      "man:doctor :: woman:niece\n",
      "man:doctor :: woman:colleague\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('man', 'doctor', 'woman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fast:fastest :: old:richest\n",
      "fast:fastest :: old:fourteen\n",
      "fast:fastest :: old:nineteen\n",
      "fast:fastest :: old:eighteen\n",
      "fast:fastest :: old:founding\n",
      "fast:fastest :: old:iranian\n",
      "fast:fastest :: old:wealthiest\n",
      "fast:fastest :: old:poorest\n",
      "fast:fastest :: old:elite\n",
      "fast:fastest :: old:earlier\n",
      "fast:fastest :: old:tribe\n",
      "fast:fastest :: old:oldest\n",
      "fast:fastest :: old:eleven\n",
      "fast:fastest :: old:nordic\n",
      "fast:fastest :: old:diaspora\n",
      "fast:fastest :: old:ninth\n",
      "fast:fastest :: old:fifteen\n",
      "fast:fastest :: old:sixteen\n",
      "fast:fastest :: old:ancestral\n"
     ]
    }
   ],
   "source": [
    "embeddings.compute_analogy('fast', 'fastest', 'small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_batcher = SkipGramBatcher.from_file(args.file_path)\n",
    "sg_batcher.prepare_data(cutoff=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0]), tensor([1, 2, 3, 2, 3]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = sg_batcher.generate_batches(window_size=5, \n",
    "                                batch_size=5)\n",
    "x_batch, labels_batch = next(g)\n",
    "\n",
    "x_batch, labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 50)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(sg_batcher.vocab)\n",
    "embedding_size = 50\n",
    "\n",
    "vocabulary_size, embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = NaiveWord2VecClassifier(vocabulary_size=vocabulary_size,\n",
    "                              embedding_size=embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1679, -0.7678, -0.4254,  0.3084,  0.4510, -0.2278, -0.0301,  0.1163,\n",
       "          0.0782,  0.1542, -0.5275, -0.5969, -0.2852,  0.9326, -0.0609,  1.0134,\n",
       "          0.7858, -0.3970, -0.0972,  0.2352, -0.1621, -0.3524],\n",
       "        [ 0.1679, -0.7678, -0.4254,  0.3084,  0.4510, -0.2278, -0.0301,  0.1163,\n",
       "          0.0782,  0.1542, -0.5275, -0.5969, -0.2852,  0.9326, -0.0609,  1.0134,\n",
       "          0.7858, -0.3970, -0.0972,  0.2352, -0.1621, -0.3524],\n",
       "        [ 0.1679, -0.7678, -0.4254,  0.3084,  0.4510, -0.2278, -0.0301,  0.1163,\n",
       "          0.0782,  0.1542, -0.5275, -0.5969, -0.2852,  0.9326, -0.0609,  1.0134,\n",
       "          0.7858, -0.3970, -0.0972,  0.2352, -0.1621, -0.3524],\n",
       "        [ 0.1679, -0.7678, -0.4254,  0.3084,  0.4510, -0.2278, -0.0301,  0.1163,\n",
       "          0.0782,  0.1542, -0.5275, -0.5969, -0.2852,  0.9326, -0.0609,  1.0134,\n",
       "          0.7858, -0.3970, -0.0972,  0.2352, -0.1621, -0.3524],\n",
       "        [ 0.1679, -0.7678, -0.4254,  0.3084,  0.4510, -0.2278, -0.0301,  0.1163,\n",
       "          0.0782,  0.1542, -0.5275, -0.5969, -0.2852,  0.9326, -0.0609,  1.0134,\n",
       "          0.7858, -0.3970, -0.0972,  0.2352, -0.1621, -0.3524]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf(x_batch)\n",
    "# y_pred = F.softmax(y_pred, dim=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 2, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7678, -0.4254,  0.3084, -0.4254,  0.3084], grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[range(5), labels_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.9903, 3.6480, 2.9141, 3.6480, 2.9141], grad_fn=<NegBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log(y_pred[range(5), labels_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = torch.zeros((5, vocabulary_size), dtype=torch.long)\n",
    "y_true[range(5), labels_batch] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 22]), torch.Size([5, 22]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([3.9903, 3.6480, 2.9141, 3.6480, 2.9141], grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss(reduce=False)\n",
    "loss(y_pred, labels_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = torch.zeros((5, vocabulary_size))\n",
    "arr[range(5), labels_batch] = 1\n",
    "arr.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 2, 3])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "loss = -np.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
