{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посимвольная языковая модель. Часть 2.\n",
    "\n",
    "В этом задании Вам нужно использовать написанную языковую модель для генерации воображаемых какслов.\n",
    "\n",
    "**В процессе написания Вам нужно решить следующие проблемы**:\n",
    "    \n",
    "* как запоминать изменившееся состояние модели и передавать его на следующий временной шаг.\n",
    "* что будет начальным состоянием модели.\n",
    "* как понять, что слово закончилось и нужно прекратить генерацию.\n",
    "\n",
    "**Результаты**:\n",
    "\n",
    "* генератор слов на основе обученной посимвольной модели\n",
    "* посимвольные вероятности сгенерированных слов\n",
    "\n",
    "**Дополнительно**:\n",
    "\n",
    "* ускорение модели за счёт побатчевой генерации"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is better to do all imports at the first cell\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "from functools import partial\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Uncomment to download data\n",
    "!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-train-high\n",
    "!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-dev\n",
    "!wget https://raw.githubusercontent.com/sigmorphon/conll2018/master/task1/surprise/russian-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify base paths for data an model folders\n",
    "DATA_PATH = Path('./data')\n",
    "MODELS_PATH = Path('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary for storing char vocabulary\n",
    "# with required operations: \n",
    "# add token, lookup index by token, lookup token by index\n",
    "class Vocabulary:\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        # Initialize mapping (token -> idx) if empty\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        \n",
    "        # Generate 2 mappings (tokens -> idx, idx -> token)\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            # get index of token if it is already exists in vocabulary\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            # for new token, append it to mapping with new index\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        \n",
    "        # return index of token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # return index by token\n",
    "        return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        # return token by index\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # override len function to get vocabulary size more easily\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocabulary subclass for sequence vocabulary processing\n",
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None,\n",
    "                 unk_token='<UNK>',\n",
    "                 mask_token='<MASK>',\n",
    "                 begin_token='<BEGIN>',\n",
    "                 end_token='<END>'):\n",
    "        super().__init__(token_to_idx)\n",
    "        \n",
    "        # Save special token symbols\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_token = begin_token\n",
    "        self._end_token = end_token\n",
    "        \n",
    "        # Get and save indices for special token symbols\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)        \n",
    "        self.begin_index = self.add_token(self._begin_token)        \n",
    "        self.end_index = self.add_token(self._end_token)\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # Override method to use <UNK> index \n",
    "        # if the token is not in vocabulary\n",
    "        return self._token_to_idx.get(token, self.unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vectorizer for transforming the word \n",
    "# to source/target vectors and saving its lengths\n",
    "class CharLMVectorizer:\n",
    "    def __init__(self, char_vocab):\n",
    "        # Save character vocabulary\n",
    "        self.char_vocab = char_vocab\n",
    "        \n",
    "    def vectorize(self, word):\n",
    "        # Wrap word with <BEGIN> and <END> tokens\n",
    "        indices = [self.char_vocab.begin_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\n",
    "        indices.append(self.char_vocab.end_index)\n",
    "        \n",
    "        # Create source vector\n",
    "        # <BEGIN> <char1> ... <charN>\n",
    "        # where N - length of original word\n",
    "        source_vector = indices[:-1]\n",
    "        \n",
    "        # Create target vector\n",
    "        # <char1> ... <charN> <END> \n",
    "        # where N - length of original word\n",
    "        target_vector = indices[1:]\n",
    "        \n",
    "        # Calculate length of both created vectors\n",
    "        length = len(source_vector)\n",
    "        \n",
    "        # Return ource and target vectors with its length\n",
    "        return {'source_vector': source_vector, \n",
    "                'target_vector': target_vector,\n",
    "                'length': length}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, full_df, data_type):\n",
    "        # Create sequence vocabulary\n",
    "        char_vocab = SequenceVocabulary()\n",
    "        \n",
    "        # Get dataframe subset to built vocabulary\n",
    "        target_df = full_df[full_df['data_type'].isin(data_type)]\n",
    "        \n",
    "        # Add tokens to vocabulary from dataset\n",
    "        for _, row in target_df.iterrows():\n",
    "            for char in row['word']:\n",
    "                char_vocab.add_token(char)\n",
    "            \n",
    "        return cls(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset for char language model\n",
    "class CharLMDataset(Dataset):\n",
    "    def __init__(self, full_df, vectorizer):\n",
    "        # Save original dataset (train/val/test)\n",
    "        self.full_df = full_df\n",
    "        \n",
    "        # Save vectorizer\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        # Save train/val/test datasets separately\n",
    "        # and save its sizes (number of rows)\n",
    "        self.train_df = self.full_df[self.full_df['data_type'] == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.full_df[self.full_df['data_type'] == 'val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.full_df[self.full_df['data_type'] == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        # Store information about datasets in dictionary\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.val_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "        \n",
    "        # Set train data as default\n",
    "        self.set_data_type('train')\n",
    "    \n",
    "    @classmethod\n",
    "    def read_dataset(cls, file_path, data_type):\n",
    "        # Read specific file and save its data type (train/dev/test)\n",
    "        df = pd.read_csv(file_path, sep='\\t', \n",
    "                         header=None, names=['word'], \n",
    "                         usecols=[0])\n",
    "        df['data_type'] = data_type\n",
    "        \n",
    "        # Return dataframe with data and its type\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset(cls, file_paths):\n",
    "        dfs_list = []\n",
    "        \n",
    "        # Read all datasets specified in files_path\n",
    "        for data_type, file_path in file_paths.items():\n",
    "            df = cls.read_dataset(file_path, data_type)\n",
    "            dfs_list.append(df)\n",
    "        \n",
    "        # Concatenate all datasets\n",
    "        full_df = pd.concat(dfs_list, axis=0, ignore_index=True)\n",
    "        \n",
    "        # Return concatenated dataframe with specified data types\n",
    "        return full_df\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file_paths(cls, file_paths):\n",
    "        # Load all data from files specified in files_path\n",
    "        full_df = cls.load_dataset(file_paths)\n",
    "        \n",
    "        # Create CharLMDataset class using full dataset and vectorizer\n",
    "        return cls(full_df, CharLMVectorizer.from_dataframe(full_df, \n",
    "                                                            data_type=['train']))\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        # Return vectorizer related to Dataset\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_data_type(self, data_type='train'):\n",
    "        # Set type, data, and its size as current dataset\n",
    "        self._target_type = data_type\n",
    "        self._target_df, self._target_size = self._lookup_dict[data_type] \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return length of the current dataset\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get example by index from the current dataset\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        # Vectorize example (generate source/target vector and its length)\n",
    "        vector_dict = self._vectorizer.vectorize(row['word'])\n",
    "        \n",
    "        # Return generated vectors with its length\n",
    "        return vector_dict\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        # Calculate the number of full batches\n",
    "        # for tracking progress in tqdm\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad batch element to specified max length\n",
    "def pad_sequence(elem, item_name, max_length, value=0):\n",
    "    \n",
    "    data = elem[item_name]\n",
    "    data_len = elem['length']\n",
    "    data = np.pad(data, (0, max_length - data_len), \n",
    "                  mode='constant', constant_values=value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine padded source/target vectors and its lengths in batch for DataLoader\n",
    "def collate_fn(batch):\n",
    "    # Get length of batch elements\n",
    "    get_length_item = itemgetter('length')\n",
    "    batch_lengths = torch.tensor(list(map(get_length_item, batch)))\n",
    "    \n",
    "    # Find max length of element in batch\n",
    "    max_batch_length = torch.max(batch_lengths)\n",
    "    \n",
    "    # Pad source vectors with <MASK> token\n",
    "    padded_source_batch = partial(pad_sequence, item_name='source_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_source_batch = list(map(padded_source_batch, batch))\n",
    "    padded_source_batch = np.vstack(padded_source_batch)\n",
    "    padded_source_batch = torch.from_numpy(padded_source_batch)\n",
    "    \n",
    "    # Pad target vectors with <MASK> token\n",
    "    padded_target_batch = partial(pad_sequence, item_name='target_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_target_batch = list(map(padded_target_batch, batch))\n",
    "    padded_target_batch = np.vstack(padded_target_batch)\n",
    "    padded_target_batch = torch.from_numpy(padded_target_batch)\n",
    "    \n",
    "    # Return dictionary with source/target vectors and its lengths\n",
    "    return {'source_batch': padded_source_batch, \n",
    "            'target_batch': padded_target_batch,\n",
    "            'batch_lengths': batch_lengths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches with padding within specific batch\n",
    "def generate_batches(dataset, batch_size, collate_fn,\n",
    "                     shuffle=True, drop_last=True,\n",
    "                     device='cpu'):\n",
    "    # Create DataLoader from dataset with additional parameters\n",
    "    # Use collate_fn to pad sequences in batches \n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                             shuffle=shuffle, drop_last=drop_last,\n",
    "                             collate_fn=collate_fn)\n",
    "    \n",
    "    for data_dict in data_loader:\n",
    "        # Find indices for sorting of batch elements\n",
    "        # in decreasing order\n",
    "        lengths = data_dict['batch_lengths'].numpy()\n",
    "        sort_idx = lengths.argsort()[::-1].tolist()\n",
    "        \n",
    "        # Sort batch in decreasing order and yield it\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sort_idx].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create character model\n",
    "class CharLMModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size,\n",
    "                 hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create embedding with zero vectors for <MASK> token \n",
    "        # for ignoring it while backprop\n",
    "        self.embedding = nn.utils.weight_norm(nn.Embedding(num_embeddings, embedding_size, \n",
    "                                              padding_idx=0), dim=1)\n",
    "        \n",
    "        # Use unidirectional 1-layer GRU\n",
    "        # For input and output, consider batch dimension at dim 0        \n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, \n",
    "                          bidirectional=False, batch_first=True)\n",
    "        \n",
    "        # Linear layer for prediction\n",
    "        self.fc1 = nn.Linear(in_features=hidden_size,\n",
    "                             out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x_source, x_lengths):\n",
    "        # Get embedding for source vectors\n",
    "        x_embedded = self.embedding(x_source)\n",
    "        \n",
    "        # Pack sequences for RNN\n",
    "        x_packed = pack_padded_sequence(x_embedded, x_lengths.detach().cpu().numpy(),\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        \n",
    "        # Forward sequences through RNN \n",
    "        x_rnn_out, x_rnn_h = self.rnn(x_packed, )\n",
    "        \n",
    "        # Unpack sequences\n",
    "        x_unpacked, _ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        \n",
    "        # Transform sequences to vocabulary size dimension\n",
    "        y_out = self.fc1(x_unpacked)\n",
    "        \n",
    "        # Return scores\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting all possible random states to fixed number\n",
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create namespace with all parameters for training\n",
    "args = Namespace(\n",
    "    # File paths for train/val/test dataset\n",
    "    file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "                  'val': DATA_PATH/'russian-dev',\n",
    "                  'test': DATA_PATH/'russian-test'},\n",
    "    # File name for model saving\n",
    "    model_state_path = MODELS_PATH/'charLMModel.pth',\n",
    "    \n",
    "    # NN hyperparameters\n",
    "    embedding_size = 100,\n",
    "    hidden_size = 100,\n",
    "    \n",
    "    # Random seed\n",
    "    seed = 42,\n",
    "    \n",
    "    # Learning hyperparameters\n",
    "    num_epochs = 100,\n",
    "    batch_size = 100,\n",
    "    learning_rate = 0.01,\n",
    "    save_iterations = 1e8,\n",
    "    early_stopping_criteria = 3,\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    clip_norm=5,\n",
    "    weight_decay=1e-3,\n",
    "    \n",
    "    # Flag whether to use GPU (if available)\n",
    "    cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for creating and updating necessary parameters while training\n",
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': [], \n",
    "            'epoch_idx': 0,\n",
    "            'train_loss': [],\n",
    "            'train_perplexity': [],\n",
    "            'val_loss': [],\n",
    "            'val_perplexity': [],\n",
    "            'test_loss': -1,\n",
    "            'test_perplexity': -1,\n",
    "            'model_file_name': args.model_state_path}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    if train_state['epoch_idx'] == 0:\n",
    "        train_state['stop_early'] = False\n",
    "        torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "    else:\n",
    "        loss = train_state['val_loss'][-1]\n",
    "\n",
    "        if loss < train_state['early_stopping_best_val']:\n",
    "            train_state['early_stopping_best_val'] = loss\n",
    "            train_state['early_stopping_step'] = 0\n",
    "            \n",
    "            if train_state['epoch_idx'] % args.save_iterations == 0:\n",
    "                torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "        else:\n",
    "            train_state['early_stopping_step'] += 1 \n",
    "    \n",
    "        train_state['stop_early'] = (train_state['early_stopping_step'] >= args.early_stopping_criteria)\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n"
     ]
    }
   ],
   "source": [
    "# Check if we can use GPU or CPU\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda=False\n",
    "    \n",
    "print(f'Using CUDA: {args.cuda}')\n",
    "args.device = torch.device('cuda' if args.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de45725ba274d459ce059801766c089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', style=ProgressStyle(description_width='initial')), H…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366b2bf9fc2f4d6ebc1e8c5a40f58546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train data', style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61855ce95b3e42c8a1791fbce0b8f658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation data', max=10, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seeds\n",
    "set_seeds(args.seed)\n",
    "\n",
    "# Create dataset from train/val/test file paths\n",
    "lm_dataset = CharLMDataset.from_file_paths(args.file_paths)\n",
    "\n",
    "# Get vectorizer\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "\n",
    "# Get mask index for training process\n",
    "mask_index = vectorizer.char_vocab.mask_index\n",
    "\n",
    "# Get vocabulary size\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "# Create language model and set device\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=args.embedding_size,\n",
    "                    hidden_size=args.hidden_size,\n",
    "                    num_classes=vocab_size)\n",
    "model = model.to(args.device)\n",
    "\n",
    "# Create optimizer & scheduler\n",
    "optimizer = optim.Adam(params=model.parameters(),\n",
    "                       lr=args.learning_rate,\n",
    "                       weight_decay=args.weight_decay)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', \n",
    "                                                 factor=args.factor,\n",
    "                                                 patience=args.patience)\n",
    "\n",
    "# Create tqdm progress bars\n",
    "epoch_bar = tqdm_notebook(desc='Epochs', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('train')\n",
    "train_bar = tqdm_notebook(desc='Train data',\n",
    "                          total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('val')\n",
    "val_bar = tqdm_notebook(desc='Validation data',\n",
    "                        total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                        position=0)\n",
    "\n",
    "# Create dictionary with training state\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "try:\n",
    "    # Epochs loop\n",
    "    for epoch_idx in range(1, args.num_epochs + 1):\n",
    "        # Save epoch index\n",
    "        train_state['epoch_idx'] = epoch_idx\n",
    "        \n",
    "        # Create generator based on train data\n",
    "        lm_dataset.set_data_type('train')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        # Init values for calculating loss and cross-entropy\n",
    "        running_loss = 0.0\n",
    "        ce_sum = 0.0\n",
    "        ce_len = 0\n",
    "        \n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get predictions for batch and reshape for loss calculation\n",
    "            y_pred = model(batch_dict['source_batch'], \n",
    "                           batch_dict['batch_lengths'])\n",
    "            y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "            \n",
    "            # Get classes for batch and reshape for loss calculation\n",
    "            y_true = batch_dict['target_batch']\n",
    "            y_true = y_true.reshape(-1)\n",
    "            \n",
    "            # Get cross-entropy for each element without aggregation\n",
    "            # Ignore <MASK> indices for calculation\n",
    "            loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                                   reduction='none')\n",
    "            \n",
    "            # Accumulate sum of cross-entropy for perplexity calculation\n",
    "            ce_sum += loss.sum().detach().item()\n",
    "            \n",
    "            # Calculate loss on non-mask tokens\n",
    "            ce_values = loss[torch.nonzero(loss).flatten()]\n",
    "            loss = ce_values.mean()\n",
    "            \n",
    "            # Run backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients for avoiding exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "            \n",
    "            # Accumulate number of tokens (chars) for perplexity calculation\n",
    "            ce_len += len(ce_values.detach())\n",
    "            \n",
    "            # Calculate running loss\n",
    "            loss_value = loss.item()\n",
    "            running_loss += (loss_value - running_loss) / batch_idx\n",
    "            \n",
    "            # Calculate current value of perplexity\n",
    "            perplexity = np.exp(ce_sum / ce_len)\n",
    "            \n",
    "            # Get current learning rate\n",
    "            learning_rate = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Update training progress bar\n",
    "            train_params = dict(loss=running_loss,\n",
    "                                perplexity=perplexity,\n",
    "                                lr=learning_rate)\n",
    "            train_bar.set_postfix(train_params)\n",
    "            train_bar.update()\n",
    "            \n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Save training params & metrics in current epoch\n",
    "        train_state['learning_rate'].append(learning_rate)\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_perplexity'].append(perplexity)\n",
    "        \n",
    "        \n",
    "        # Create generator based on validation data\n",
    "        lm_dataset.set_data_type('val')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        # Init values for calculating loss and cross-entropy\n",
    "        running_loss = 0.0\n",
    "        ce_sum = 0.0\n",
    "        ce_len = 0\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Do not calculate gradients\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "                # Get predictions for batch and reshape for loss calculation\n",
    "                y_pred = model(batch_dict['source_batch'], \n",
    "                               batch_dict['batch_lengths'])\n",
    "                y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "                \n",
    "                # Get classes for batch and reshape for loss calculation\n",
    "                y_true = batch_dict['target_batch']\n",
    "                y_true = y_true.reshape(-1)\n",
    "                \n",
    "                # Get cross-entropy for each element without aggregation\n",
    "                # Ignore <MASK> indices for calculation\n",
    "                loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                               reduction='none')\n",
    "                \n",
    "                # Accumulate sum of cross-entropy for perplexity calculation\n",
    "                ce_sum += loss.sum().detach().item()\n",
    "                \n",
    "                # Calculate loss on non-mask tokens\n",
    "                ce_values = loss[torch.nonzero(loss).flatten()]\n",
    "                loss = ce_values.mean()\n",
    "                \n",
    "                # Accumulate number of tokens (chars) for perplexity calculation\n",
    "                ce_len += len(ce_values.detach())\n",
    "                \n",
    "                # Calculate running loss\n",
    "                loss_value = loss.item()\n",
    "                running_loss += (loss_value - running_loss) / batch_idx\n",
    "                \n",
    "                # Calculate current value of perplexity\n",
    "                perplexity = np.exp(ce_sum / ce_len)\n",
    "                \n",
    "                # Update validation progress bar\n",
    "                val_params = dict(loss=running_loss, \n",
    "                                  perplexity=perplexity)\n",
    "                val_bar.set_postfix(val_params)\n",
    "                val_bar.update()\n",
    "        \n",
    "        # Save validation metrics in current epoch\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_perplexity'].append(perplexity)\n",
    "        \n",
    "        # Update train state\n",
    "        train_state = update_train_state(args=args, \n",
    "                                         model=model, \n",
    "                                         train_state=train_state)\n",
    "        \n",
    "        # Update scheduling \n",
    "        # Decrease learning rate by factor of args.factor\n",
    "        # if validation loss is not decreasing \n",
    "        # for args.patience epochs\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "        \n",
    "        # Early stop if validation loss is not decreasing\n",
    "        # for args.early_stopping_criteria epochs\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "        \n",
    "        # Zero & update progress bars\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        \n",
    "        epoch_params = dict(early_stopping_best_val=train_state['early_stopping_best_val'],\n",
    "                            early_stopping_step=train_state['early_stopping_step'])\n",
    "        epoch_bar.set_postfix(epoch_params)\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print('Exit training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final perplexity on validation data: 6.79\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print validation dataset perplexity\n",
    "# and visualize loss/perplexity values per epoch\n",
    "val_perplexity_final = train_state['val_perplexity'][-1]\n",
    "\n",
    "print(f'Final perplexity on validation data: {np.round(val_perplexity_final, 2)}')\n",
    "train_state_df = pd.DataFrame(train_state)\n",
    "train_state_df.filter(regex='(train|val)_loss').plot()\n",
    "train_state_df.filter(regex='(train|val)_perplexity').plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(model, vectorizer, \n",
    "                   batch_size=5,\n",
    "                   max_length=20):\n",
    "    indices = []\n",
    "    probs = []\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    h_t = torch.zeros(1, batch_size, \n",
    "                      model.rnn.hidden_size).to(args.device)\n",
    "\n",
    "    x_t = torch.full((batch_size, 1), \n",
    "                     vectorizer.char_vocab.begin_index,\n",
    "                     dtype=torch.int64).to(args.device)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for time_step in range(max_length):\n",
    "            emb_t = model.embedding(x_t)\n",
    "            rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "            y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "            y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "            y_pred_idx_best = torch.multinomial(y_pred_proba, num_samples=1).squeeze(1)\n",
    "            y_pred_proba_best = y_pred_proba[range(batch_size), y_pred_idx_best]\n",
    "\n",
    "            indices.append(y_pred_idx_best)\n",
    "            probs.append(y_pred_proba_best)\n",
    "            x_t = y_pred_idx_best.unsqueeze(1)\n",
    "        \n",
    "    indices = torch.stack(indices, dim=1)\n",
    "    probs = torch.stack(probs, dim=1)\n",
    "    \n",
    "    return indices, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_word_probs(vectorizer, \n",
    "                               indices, probs):\n",
    "    batch_size = indices.shape[0]\n",
    "    max_length = indices.shape[1]\n",
    "    \n",
    "    for sample_idx in range(batch_size):\n",
    "        word_prob = 1.\n",
    "        word = ''\n",
    "        char_probs = ''\n",
    "        \n",
    "        for time_step in range(max_length):\n",
    "            char_idx = indices[sample_idx, time_step].item()\n",
    "                \n",
    "            char = vectorizer.char_vocab.lookup_index(char_idx)\n",
    "            char_prob = probs[sample_idx, time_step]\n",
    "            \n",
    "            word += char\n",
    "            char_probs += f'{char}: {char_prob:.5f} '\n",
    "            word_prob *= char_prob\n",
    "            \n",
    "            if char_idx == vectorizer.char_vocab.end_index:\n",
    "                break\n",
    "        \n",
    "        print(word)\n",
    "        print(char_probs)\n",
    "        print(f'Word propability: {word_prob}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "скоция<END>\n",
      "с: 0.09187 к: 0.06645 о: 0.36718 ц: 0.00342 и: 0.34320 я: 0.11278 <END>: 0.76685 \n",
      "Word propability: 2.272884671583597e-07\n",
      "\n",
      "амирождание<END>\n",
      "а: 0.04104 м: 0.07529 и: 0.17081 р: 0.10505 о: 0.44192 ж: 0.01050 д: 0.00433 а: 0.43605 н: 0.17757 и: 0.28019 е: 0.46229 <END>: 0.91798 \n",
      "Word propability: 1.0250040399784055e-11\n",
      "\n",
      "подчаль<END>\n",
      "п: 0.16440 о: 0.33243 д: 0.21311 ч: 0.01365 а: 0.21653 л: 0.05979 ь: 0.25146 <END>: 0.20098 \n",
      "Word propability: 1.0405182138129021e-07\n",
      "\n",
      "тограть<END>\n",
      "т: 0.03435 о: 0.16035 г: 0.05321 р: 0.24105 а: 0.30603 т: 0.33566 ь: 0.34671 <END>: 0.78231 \n",
      "Word propability: 1.968500555449282e-06\n",
      "\n",
      "моретон<END>\n",
      "м: 0.03723 о: 0.21505 р: 0.12878 е: 0.08837 т: 0.10769 о: 0.04137 н: 0.05288 <END>: 0.43152 \n",
      "Word propability: 9.260388900145244e-09\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indices, probs = generate_words(model, vectorizer)\n",
    "print_generated_word_probs(vectorizer, indices, probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
