{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посимвольная языковая модель.\n",
    "\n",
    "В первом задании Вам нужно написать и обучить посимвольную нейронную языковую модель для вычисления вероятностей буквенных последовательностей (то есть слов). Такие модели используются в задачах словоизменения и распознавания/порождения звучащей речи. Для обучения модели используйте данные для русского языка из [репозитория](https://github.com/sigmorphon/conll2018/tree/master/task1/surprise).\n",
    "\n",
    "**В процессе написания Вам нужно решить следующие проблемы:**\n",
    "    \n",
    "* как будет выглядеть обучающая выборка; что будет являться признаками, и что - метками классов.\n",
    "* как сделать так, чтобы модель при предсказании символа учитывала все предыдущие символы слова.\n",
    "* какие специальные символы нужно использовать.\n",
    "* как передавать в модель текущее состояние рекуррентной сети\n",
    "\n",
    "**Результаты:**\n",
    "\n",
    "* предобработчик данных,\n",
    "* генератор обучающих данных (батчей),\n",
    "* обученная модель\n",
    "* перплексия модели на настроечной выборке\n",
    "* посимвольные вероятности слов в контрольной выборке\n",
    "\n",
    "**Дополнительно:**\n",
    "\n",
    "* дополнительный вход модели (часть речи слова, другие морфологические признаки), влияет ли его добавление на перплексию\n",
    "* сравнение различных архитектур нейронной сети (FC, RNN, LSTM, QRNN, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумайте, какие вспомогательные токены могут быть вам полезны. Выдайте им индексы от `0` до `len(AUXILIARY) - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План**\n",
    "- Данные\n",
    "    - Признаки: набор символов токена, заканчивается токеном END\n",
    "    - Метки класса: набор символов того же токена, начинается с токена BEGIN\n",
    "- Для учета всех предыдущих символов, при предсказании следующего символа, дополнительно мы должны передавать на вход предыдущий токен\n",
    "- Специальные символы\n",
    "    - BEGIN, END, MASK, UNK\n",
    "- (???) Как передавать в модель текущее состояние рекуррентной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is better to do all imports at the first cell\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "from functools import partial\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download data\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-train-high\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-dev\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data')\n",
    "MODELS_PATH = Path('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "              'val': DATA_PATH/'russian-dev',\n",
    "              'test': DATA_PATH/'russian-test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        # Initialize mapping (token -> idx) if empty\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        \n",
    "        # Generate 2 mappings (tokens -> idx, idx -> token)\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            # get index of token if it is already exists in vocabulary\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            # for new token, append it to mapping with new index\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        \n",
    "        # return index of token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # return index by token\n",
    "        return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        # return token by index\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # override len function to get vocabulary size more easily\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None,\n",
    "                 unk_token='<UNK>',\n",
    "                 mask_token='<MASK>',\n",
    "                 begin_token='<BEGIN>',\n",
    "                 end_token='<END>'):\n",
    "        super().__init__(token_to_idx)\n",
    "        \n",
    "        # Save special token symbols\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_token = begin_token\n",
    "        self._end_token = end_token\n",
    "        \n",
    "        # Get and save indices for special token symbols\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)        \n",
    "        self.begin_index = self.add_token(self._begin_token)        \n",
    "        self.end_index = self.add_token(self._end_token)\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # Override method to use <UNK> index \n",
    "        # if the token is not in vocabulary\n",
    "        return self._token_to_idx.get(token, self.unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMVectorizer:\n",
    "    def __init__(self, char_vocab):\n",
    "        # Save character vocabulary\n",
    "        self.char_vocab = char_vocab\n",
    "        \n",
    "    def vectorize(self, word):\n",
    "        # Wrap word with <BEGIN> and <END> tokens\n",
    "        indices = [self.char_vocab.begin_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\n",
    "        indices.append(self.char_vocab.end_index)\n",
    "        \n",
    "        # Create source vector\n",
    "        # <BEGIN> <char1> ... <charN>\n",
    "        # where N - length of original word\n",
    "        source_vector = indices[:-1]\n",
    "        \n",
    "        # Create target vector\n",
    "        # <char1> ... <charN> <END> \n",
    "        # where N - length of original word\n",
    "        target_vector = indices[1:]\n",
    "        \n",
    "        # Calculate length of both created vectors\n",
    "        length = len(source_vector)\n",
    "        \n",
    "        # Return ource and target vectors with its length\n",
    "        return {'source_vector': source_vector, \n",
    "                'target_vector': target_vector,\n",
    "                'length': length}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, full_df, data_type):\n",
    "        # Create sequence vocabulary\n",
    "        char_vocab = SequenceVocabulary()\n",
    "        \n",
    "        # Get dataframe subset to built vocabulary\n",
    "        target_df = full_df[full_df['data_type'].isin(data_type)]\n",
    "        \n",
    "        # Add tokens to vocabulary from train dataset\n",
    "        for _, row in target_df.iterrows():\n",
    "            for char in row['word']:\n",
    "                char_vocab.add_token(char)\n",
    "            \n",
    "        return cls(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMDataset(Dataset):\n",
    "    def __init__(self, full_df, vectorizer):\n",
    "        # Save original dataset (train/val/test)\n",
    "        self.full_df = full_df\n",
    "        \n",
    "        # Save vectorizer\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        # Save train/val/test datasets separately\n",
    "        # and save its sizes (number of rows)\n",
    "        self.train_df = self.full_df[self.full_df['data_type'] == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.full_df[self.full_df['data_type'] == 'val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.full_df[self.full_df['data_type'] == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        # Store information about datasets in dictionary\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.val_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "        \n",
    "        # Set train data as default\n",
    "        self.set_data_type('train')\n",
    "    \n",
    "    @classmethod\n",
    "    def read_dataset(cls, file_path, data_type):\n",
    "        # Read specific file and save its data type (train/dev/test)\n",
    "        df = pd.read_csv(file_path, sep='\\t', \n",
    "                         header=None, names=['word'], \n",
    "                         usecols=[0])\n",
    "        df['data_type'] = data_type\n",
    "        \n",
    "        # Return dataframe with data and its type\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset(cls, file_paths):\n",
    "        dfs_list = []\n",
    "        \n",
    "        # Read all datasets specified in files_path\n",
    "        for data_type, file_path in file_paths.items():\n",
    "            df = cls.read_dataset(file_path, data_type)\n",
    "            dfs_list.append(df)\n",
    "        \n",
    "        # Concatenate all datasets\n",
    "        full_df = pd.concat(dfs_list, axis=0, ignore_index=True)\n",
    "        \n",
    "        # Return concatenated dataframe with specified data types\n",
    "        return full_df\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file_paths(cls, file_paths):\n",
    "        # Load all data from files specified in files_path\n",
    "        full_df = cls.load_dataset(file_paths)\n",
    "        \n",
    "        # Create CharLMDataset class using full dataset and vectorizer\n",
    "        return cls(full_df, CharLMVectorizer.from_dataframe(full_df, \n",
    "                                                            data_type=['train']))\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        # Return vectorizer related to Dataset\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_data_type(self, data_type='train'):\n",
    "        # Set type, data, and its size as current dataset\n",
    "        self._target_type = data_type\n",
    "        self._target_df, self._target_size = self._lookup_dict[data_type] \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return length of the current dataset\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get example by index from the current dataset\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        # Vectorize example (generate source/target vector and its length)\n",
    "        vector_dict = self._vectorizer.vectorize(row['word'])\n",
    "        \n",
    "        # Return generated vectors with its length\n",
    "        return vector_dict\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        # Calculate the number of full batches\n",
    "        # for tracking progress in tqdm\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad batch element to max batch length\n",
    "def pad_sequence(elem, item_name, max_length, value=0):\n",
    "    data = elem[item_name]\n",
    "    data_len = elem['length']\n",
    "    data = np.pad(data, (0, max_length - data_len), \n",
    "                  mode='constant', constant_values=value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine padded source/target vectors and its lengths in batch for DataLoader\n",
    "def collate_fn(batch):\n",
    "    get_length_item = itemgetter('length')\n",
    "    \n",
    "    batch_lengths = torch.tensor(list(map(get_length_item, batch)))\n",
    "    max_batch_length = torch.max(batch_lengths)\n",
    "    \n",
    "    padded_source_batch = partial(pad_sequence, item_name='source_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_source_batch = list(map(padded_source_batch, batch))\n",
    "    padded_source_batch = np.vstack(padded_source_batch)\n",
    "    padded_source_batch = torch.from_numpy(padded_source_batch)\n",
    "    \n",
    "    padded_target_batch = partial(pad_sequence, item_name='target_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_target_batch = list(map(padded_target_batch, batch))\n",
    "    padded_target_batch = np.vstack(padded_target_batch)\n",
    "    padded_target_batch = torch.from_numpy(padded_target_batch)\n",
    "    \n",
    "    return {'source_batch': padded_source_batch, \n",
    "            'target_batch': padded_target_batch,\n",
    "            'batch_lengths': batch_lengths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches with padding within specific batch\n",
    "def generate_batches(dataset, batch_size, collate_fn,\n",
    "                     shuffle=True, drop_last=True,\n",
    "                     device='cpu'):\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                             shuffle=shuffle, drop_last=drop_last,\n",
    "                             collate_fn=collate_fn)\n",
    "    \n",
    "    for data_dict in data_loader:\n",
    "        lengths = data_dict['batch_lengths'].numpy()\n",
    "        sort_idx = lengths.argsort()[::-1].tolist()\n",
    "        \n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sort_idx].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size,\n",
    "                 hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_size, \n",
    "                                      padding_idx=0)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, \n",
    "                          bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=hidden_size,\n",
    "                             out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x_source, x_lengths, apply_softmax=False):\n",
    "        x_embedded = self.embedding(x_source)\n",
    "        x_packed = pack_padded_sequence(x_embedded, x_lengths.detach().cpu().numpy(),\n",
    "                                        batch_first=True)\n",
    "        x_rnn_out, x_rnn_h = self.rnn(x_packed)\n",
    "        x_unpacked, _ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        y_out = self.fc1(x_unpacked)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=2)\n",
    "        \n",
    "        return y_out # x_unpacked #, x_rnn_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "{'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'в': 4, 'а': 5, 'л': 6, 'о': 7, 'н': 8, 'с': 9, 'к': 10, 'и': 11, 'й': 12, 'е': 13, 'з': 14, 'ч': 15, 'ы': 16, 'т': 17, 'р': 18, 'ё': 19, 'п': 20, 'ь': 21, 'г': 22, 'б': 23, 'ю': 24, 'я': 25, 'д': 26, 'у': 27, 'ш': 28, 'м': 29, 'х': 30, 'ж': 31, 'ц': 32, ' ': 33, 'щ': 34, '-': 35, 'ф': 36, 'э': 37, 'ъ': 38, 'С': 39, 'Ш': 40, 'И': 41, 'З': 42, 'А': 43, 'Г': 44, 'Э': 45, 'Л': 46, 'Ф': 47, 'В': 48, 'П': 49, 'М': 50, 'Р': 51, 'Б': 52, 'Х': 53, 'Н': 54, 'Е': 55}\n",
      "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'в', 5: 'а', 6: 'л', 7: 'о', 8: 'н', 9: 'с', 10: 'к', 11: 'и', 12: 'й', 13: 'е', 14: 'з', 15: 'ч', 16: 'ы', 17: 'т', 18: 'р', 19: 'ё', 20: 'п', 21: 'ь', 22: 'г', 23: 'б', 24: 'ю', 25: 'я', 26: 'д', 27: 'у', 28: 'ш', 29: 'м', 30: 'х', 31: 'ж', 32: 'ц', 33: ' ', 34: 'щ', 35: '-', 36: 'ф', 37: 'э', 38: 'ъ', 39: 'С', 40: 'Ш', 41: 'И', 42: 'З', 43: 'А', 44: 'Г', 45: 'Э', 46: 'Л', 47: 'Ф', 48: 'В', 49: 'П', 50: 'М', 51: 'Р', 52: 'Б', 53: 'Х', 54: 'Н', 55: 'Е'}\n"
     ]
    }
   ],
   "source": [
    "lm_dataset = CharLMDataset.from_file_paths(file_paths)\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "\n",
    "print(len(vectorizer.char_vocab))\n",
    "print(vectorizer.char_vocab._token_to_idx)\n",
    "print(vectorizer.char_vocab._idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_batch': tensor([[ 2,  8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12],\n",
      "        [ 2, 11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  0,  0],\n",
      "        [ 2,  4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0]]), 'target_batch': tensor([[ 8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12,  3],\n",
      "        [11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  3,  0,  0],\n",
      "        [ 4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  3,  0,  0,  0]]), 'batch_lengths': tensor([14, 12, 11])}\n",
      "tensor([[ 2,  8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12],\n",
      "        [ 2, 11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  0,  0],\n",
      "        [ 2,  4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0]]) tensor([14, 12, 11])\n"
     ]
    }
   ],
   "source": [
    "for batch in islice(generate_batches(lm_dataset, batch_size=3, \n",
    "                                     shuffle=False, collate_fn=collate_fn), 1):\n",
    "    print(batch)\n",
    "    x_source = batch['source_batch']\n",
    "    lengths = batch['batch_lengths']\n",
    "    print(x_source, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=3,\n",
    "                    hidden_size=2,\n",
    "                    num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 56])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out = model(x_source, lengths)\n",
    "y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all possible random states to fixed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create namespace with all parameters for training (specified values were used for the final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "                  'val': DATA_PATH/'russian-dev',\n",
    "                  'test': DATA_PATH/'russian-test'},\n",
    "    model_state_path = MODELS_PATH/'charLMModel.pth',\n",
    "    \n",
    "    embedding_size = 100,\n",
    "    hidden_size = 100,\n",
    "    \n",
    "    seed = 42,\n",
    "    \n",
    "    num_epochs = 10,\n",
    "    batch_size = 100,\n",
    "    learning_rate = 0.03,\n",
    "    save_iterations = 1e8,\n",
    "    early_stopping_criteria = 1e8,\n",
    "    factor=0.5,\n",
    "    patience=1e8,\n",
    "    clip_norm=1,\n",
    "    \n",
    "    cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions for creating and updating necessary parameters while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': [], \n",
    "            'epoch_idx': 0,\n",
    "            'batch_idx': 0,\n",
    "            'train_loss': [],\n",
    "            'train_perplexity': [],\n",
    "            'val_loss': [],\n",
    "            'val_perplexity': [],\n",
    "            'test_loss': -1,\n",
    "            'test_perplexity': -1,\n",
    "            'model_file_name': args.model_state_path}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    if train_state['epoch_idx'] == 0:\n",
    "        train_state['stop_early'] = False\n",
    "        torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "    else:\n",
    "        loss = train_state['dev_loss'][-1]\n",
    "\n",
    "        if loss < train_state['early_stopping_best_val']:\n",
    "            train_state['early_stopping_best_val'] = loss\n",
    "            train_state['early_stopping_step'] = 0\n",
    "            \n",
    "            if train_state['batch_idx'] % args.save_iterations == 0:\n",
    "                torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "        else:\n",
    "            train_state['early_stopping_step'] += 1 \n",
    "    \n",
    "        train_state['stop_early'] = train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we can use GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    args.cuda=False\n",
    "    \n",
    "print(f'Using CUDA: {args.cuda}')\n",
    "args.device = torch.device('cuda' if args.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc8b48444c84d4da7e4aaebc7a1ba86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=10, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ff69c400ca45b4b49a3e608b09217f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train data', style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d0ad83b62a420480913e65cdf3479d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation data', max=10, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit training\n"
     ]
    }
   ],
   "source": [
    "set_seeds(args.seed)\n",
    "\n",
    "lm_dataset = CharLMDataset.from_file_paths(args.file_paths)\n",
    "\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "mask_index = vectorizer.char_vocab.mask_index\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=args.embedding_size,\n",
    "                    hidden_size=args.hidden_size,\n",
    "                    num_classes=vocab_size)\n",
    "model = model.to(args.device)\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(),\n",
    "                      lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', \n",
    "                                                 factor=args.factor,\n",
    "                                                 patience=args.patience)\n",
    "\n",
    "epoch_bar = tqdm_notebook(desc='Epochs', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('train')\n",
    "train_bar = tqdm_notebook(desc='Train data',\n",
    "                          total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('val')\n",
    "val_bar = tqdm_notebook(desc='Validation data',\n",
    "                        total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                        position=0)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "# writer = SummaryWriter(log_dir='logs', comment='task_1')\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(1, args.num_epochs + 1):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "        \n",
    "        lm_dataset.set_data_type('train')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        ce_sum = 0.0\n",
    "        ce_len = 0\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(batch_dict['source_batch'], \n",
    "                           batch_dict['batch_lengths'])\n",
    "            y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "            \n",
    "            y_true = batch_dict['target_batch']\n",
    "            y_true = y_true.reshape(-1)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                               reduction='none')\n",
    "            ce_sum += loss.sum().detach().item()\n",
    "            ce_values = loss[torch.nonzero(loss).flatten()]\n",
    "            loss = ce_values.mean()\n",
    "\n",
    "            ce_len += len(ce_values.detach())\n",
    "                  \n",
    "            loss_value = loss.item()\n",
    "            running_loss += (loss_value - running_loss) / batch_idx\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "            \n",
    "            perplexity = np.exp(ce_sum / ce_len)\n",
    "            \n",
    "            learning_rate = optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "            train_state = update_train_state(args=args,\n",
    "                                             model=model,\n",
    "                                             train_state=train_state)\n",
    "\n",
    "            train_params = dict(loss=running_loss,\n",
    "                                perplexity=perplexity,\n",
    "                                lr=learning_rate)\n",
    "            train_bar.set_postfix(train_params)\n",
    "            train_bar.update()\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_state['learning_rate'].append(learning_rate)\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_perplexity'].append(perplexity)\n",
    "        \n",
    "        lm_dataset.set_data_type('val')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        ce_sum = 0.0\n",
    "        ce_len = 0\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "                y_pred = model(batch_dict['source_batch'], \n",
    "                               batch_dict['batch_lengths'])\n",
    "                y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "\n",
    "                y_true = batch_dict['target_batch']\n",
    "                y_true = y_true.reshape(-1)\n",
    "\n",
    "                loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                               reduction='none')\n",
    "                ce_sum += loss.sum().detach().item()\n",
    "                ce_values = loss[torch.nonzero(loss).flatten()]\n",
    "                loss = ce_values.mean()\n",
    "\n",
    "                ce_len += len(ce_values.detach())\n",
    "\n",
    "                loss_value = loss.item()\n",
    "                running_loss += (loss_value - running_loss) / batch_idx\n",
    "                \n",
    "                perplexity = np.exp(ce_sum / ce_len)\n",
    "                \n",
    "                val_params = dict(loss=running_loss, \n",
    "                                  perplexity=perplexity)\n",
    "                val_bar.set_postfix(val_params)\n",
    "                val_bar.update()\n",
    "        \n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_perplexity'].append(perplexity)\n",
    "\n",
    "        train_state = update_train_state(args=args, \n",
    "                                         model=model, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print('Exit training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final perplexity on validation data: 7.14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'Final perplexity on validation data: {np.round(perplexity, 2)}')\n",
    "train_state_df = pd.DataFrame(train_state)\n",
    "train_state_df.filter(regex='(train|val)_loss').plot()\n",
    "train_state_df.filter(regex='(train|val)_perplexity').plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                word data_type\n",
       " 11000    мальтийский      test\n",
       " 11001     расчленить      test\n",
       " 11002       лопаться      test\n",
       " 11003  индексировать      test\n",
       " 11004  своевременный      test, 1000)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset.set_data_type('test')\n",
    "lm_dataset._target_df.head(), len(lm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_batch': tensor([[ 2, 29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12],\n",
       "         [ 2, 18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  0]]),\n",
       " 'target_batch': tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "         [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]),\n",
       " 'batch_lengths': tensor([12, 11])}"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                   batch_size=2,\n",
    "                                   collate_fn=collate_fn,\n",
    "                                   shuffle=False,\n",
    "                                   drop_last=False,\n",
    "                                   device=args.device)\n",
    "for batch_dict in islice(batch_generator, 1):\n",
    "    pass\n",
    "\n",
    "batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2, 29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12],\n",
       "         [ 2, 18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  0]]),\n",
       " tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "         [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]),\n",
       " tensor([12, 11]))"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_batch = batch_dict['source_batch']\n",
    "target_batch = batch_dict['target_batch']\n",
    "batch_lengths = batch_dict['batch_lengths']\n",
    "\n",
    "source_batch, target_batch, batch_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[2],\n",
       "         [2]])]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.full((source_batch.shape[0], 1),\n",
    "                     vectorizer.char_vocab.begin_index,\n",
    "                     dtype=torch.int64)\n",
    "h_t = None\n",
    "\n",
    "indices = [indices]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 100])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.0382e-02, 2.8284e-01, 5.3351e-02, 1.0025e-01, 7.6129e-02, 1.7347e-01,\n",
       "         1.2875e-01, 1.0229e-01, 7.5572e-01, 8.9095e-01, 9.9307e-01, 9.3183e-01],\n",
       "        [5.5565e-02, 5.3692e-01, 1.6903e-01, 8.6532e-03, 2.5530e-03, 1.1568e-01,\n",
       "         2.1142e-01, 5.2851e-01, 1.0305e-02, 7.4257e-01, 7.2096e-01, 3.3914e-07]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "h_t = torch.zeros(1, source_batch.shape[0], args.hidden_size)\n",
    "print(h_t.shape)\n",
    "\n",
    "probs = []\n",
    "with(torch.no_grad()):\n",
    "    for time_step in range(source_batch.shape[1]):\n",
    "        x_t = source_batch[:, time_step].unsqueeze(1)\n",
    "#         print(x_t.shape)\n",
    "        emb_t = model.embedding(x_t)\n",
    "#         print(emb_t.shape)\n",
    "        rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "#         print(rnn_out_t.shape, h_t.shape)\n",
    "#         print(rnn_out_t.shape)\n",
    "        y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "#         print(y_pred.shape)\n",
    "        y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "        print(y_pred_proba.shape)\n",
    "        y_true_proba = y_pred_proba[range(source_batch.shape[0]), \n",
    "                                          target_batch[:, time_step]]\n",
    "#         print(y_true_proba.shape)\n",
    "        probs.append(y_true_proba)\n",
    "probs = torch.stack(probs, dim=1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "        [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "м: 0.03038155846297741\n",
      "а: 0.2828406095504761\n",
      "л: 0.05335060507059097\n",
      "ь: 0.10024875402450562\n",
      "т: 0.07612878829240799\n",
      "и: 0.173465296626091\n",
      "й: 0.12875482439994812\n",
      "с: 0.10229194909334183\n",
      "к: 0.7557221055030823\n",
      "и: 0.8909469842910767\n",
      "й: 0.9930688142776489\n",
      "<END>: 0.9318332672119141\n",
      "Word propability: 4.980445389435317e-09\n",
      "р: 0.055564992129802704\n",
      "а: 0.5369189977645874\n",
      "с: 0.16903004050254822\n",
      "ч: 0.008653227239847183\n",
      "л: 0.0025530161801725626\n",
      "е: 0.11568107455968857\n",
      "н: 0.21142107248306274\n",
      "и: 0.5285053253173828\n",
      "т: 0.010305234231054783\n",
      "ь: 0.7425680160522461\n",
      "<END>: 0.7209640741348267\n",
      "Word propability: 7.944624125233446e-12\n"
     ]
    }
   ],
   "source": [
    "for sample_idx in range(target_batch.shape[0]):\n",
    "    word_prob = 1\n",
    "    for time_step in range(batch_lengths[sample_idx]):\n",
    "        char = vectorizer.char_vocab.lookup_index(target_batch[sample_idx, time_step].item())\n",
    "        char_prob = probs[sample_idx, time_step]\n",
    "        print(f'{char}: {char_prob}')\n",
    "        word_prob *= char_prob\n",
    "    print(f'Word propability: {word_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 100])\n"
     ]
    }
   ],
   "source": [
    "best_indices = []\n",
    "best_probs = []\n",
    "batch_size = 10\n",
    "max_size = 10\n",
    "\n",
    "model.eval()\n",
    "h_t = torch.rand(1, batch_size, args.hidden_size)\n",
    "print(h_t.shape)\n",
    "\n",
    "x_t = torch.full((batch_size, 1), \n",
    "                 vectorizer.char_vocab.begin_index,\n",
    "                 dtype=torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for time_step in range(max_size):\n",
    "        emb_t = model.embedding(x_t)\n",
    "#         print(emb_t.shape)\n",
    "        rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "#         print(rnn_out_t.shape)\n",
    "        y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "#         print(y_pred.shape)\n",
    "        y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "#         print(y_pred_proba.shape)\n",
    "        y_pred_idx_best = torch.multinomial(y_pred_proba, num_samples=1).squeeze(1)\n",
    "#         print(y_pred_idx_best)\n",
    "        y_pred_proba_best = y_pred_proba[range(batch_size), y_pred_idx_best]\n",
    "#         print(y_pred_proba_best)\n",
    "        \n",
    "        best_indices.append(y_pred_idx_best)\n",
    "        best_probs.append(y_pred_proba_best)\n",
    "        x_t = y_pred_idx_best.unsqueeze(1)\n",
    "#         print(x_t)\n",
    "best_probs = torch.stack(best_probs, dim=1)\n",
    "best_indices = torch.stack(best_indices, dim=1)\n",
    "#best_probs, best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "з: 0.061420198529958725\n",
      "о: 0.031722307205200195\n",
      "ч: 0.1572331339120865\n",
      "е: 0.30524522066116333\n",
      "ц: 0.008515279740095139\n",
      "Word : зочец\n",
      "Word propability: 7.96283700310596e-07\n",
      "д: 0.037683214992284775\n",
      "у: 0.2834266424179077\n",
      "б: 0.02551225945353508\n",
      "о: 0.05529022589325905\n",
      "т: 0.3558487296104431\n",
      "ь: 0.6600194573402405\n",
      "Word : дуботь\n",
      "Word propability: 3.5384091461310163e-06\n",
      "у: 0.08457167446613312\n",
      "с: 0.06196969747543335\n",
      "у: 0.3333575427532196\n",
      "ч: 0.12156964838504791\n",
      "и: 0.30893462896347046\n",
      "т: 0.6379993557929993\n",
      "ь: 0.9406260848045349\n",
      "с: 0.5005928874015808\n",
      "я: 0.9762810468673706\n",
      "Word : усучиться\n",
      "Word propability: 1.924434764077887e-05\n",
      "к: 0.006677425466477871\n",
      "о: 0.26556408405303955\n",
      "п: 0.2542363405227661\n",
      "р: 0.11586259305477142\n",
      "а: 0.08767888695001602\n",
      "д: 0.07423495501279831\n",
      "Word : копрад\n",
      "Word propability: 3.3998733783846546e-07\n",
      "п: 0.7279301881790161\n",
      "о: 0.3385339379310608\n",
      "т: 0.10789524763822556\n",
      "о: 0.20798292756080627\n",
      "в: 0.12753024697303772\n",
      "и: 0.042344219982624054\n",
      "н: 0.053756825625896454\n",
      "е: 0.17163033783435822\n",
      "с: 0.1217675730586052\n",
      "т: 0.7059271335601807\n",
      "Word : потовинест\n",
      "Word propability: 2.3683643490812756e-08\n",
      "ж: 0.02211662195622921\n",
      "е: 0.6500122547149658\n",
      "д: 0.09134422242641449\n",
      "а: 0.01755981706082821\n",
      "в: 0.04237609729170799\n",
      "я: 0.055107422173023224\n",
      "т: 0.2937873899936676\n",
      "ь: 0.9490729570388794\n",
      "Word : жедавять\n",
      "Word propability: 1.5014302690019576e-08\n",
      "п: 0.47892528772354126\n",
      "о: 0.5382949113845825\n",
      "ю: 0.0005779189523309469\n",
      "ц: 0.012904807925224304\n",
      "п: 0.003995055332779884\n",
      "о: 0.21423405408859253\n",
      "ч: 0.007596026640385389\n",
      "и: 0.2992234528064728\n",
      "т: 0.6906726360321045\n",
      "ь: 0.8535358309745789\n",
      "Word : поюцпочить\n",
      "Word propability: 2.204925695151183e-12\n",
      "п: 0.6696540117263794\n",
      "е: 0.09698175638914108\n",
      "у: 0.025693686679005623\n",
      "т: 0.14532437920570374\n",
      "е: 0.271969199180603\n",
      "л: 0.11048424988985062\n",
      "ь: 0.6842544078826904\n",
      "н: 0.6422989964485168\n",
      "ы: 0.9052348136901855\n",
      "й: 0.9995682835578918\n",
      "Word : пеутельный\n",
      "Word propability: 2.8977046895306557e-06\n",
      "п: 0.6534440517425537\n",
      "л: 0.024040494114160538\n",
      "а: 0.21150265634059906\n",
      "в: 0.07878686487674713\n",
      "с: 0.023872319608926773\n",
      "л: 0.0634223222732544\n",
      "я: 0.13618029654026031\n",
      "в: 0.027887430042028427\n",
      "ы: 0.6308643817901611\n",
      "х: 0.0007253160583786666\n",
      "Word : плавслявых\n",
      "Word propability: 6.887225165175259e-13\n",
      "з: 0.02353280782699585\n",
      "е: 0.18021470308303833\n",
      "ч: 0.10611976683139801\n",
      "е: 0.2569543123245239\n",
      "щ: 0.0075687444768846035\n",
      "а: 0.2006445676088333\n",
      "ю: 0.0168165136128664\n",
      " : 0.10366054624319077\n",
      "д: 0.025102391839027405\n",
      "е: 0.21075430512428284\n",
      "Word : зечещаю де\n",
      "Word propability: 1.6196024556214272e-12\n"
     ]
    }
   ],
   "source": [
    "for sample_idx in range(batch_size):\n",
    "    word = ''\n",
    "    word_prob = 1.\n",
    "    for time_step in range(max_size):\n",
    "        char_idx = best_indices[sample_idx, time_step].item()\n",
    "        if char_idx == vectorizer.char_vocab.end_index:\n",
    "            break\n",
    "        char = vectorizer.char_vocab.lookup_index(char_idx)\n",
    "        word += char\n",
    "        char_prob = best_probs[sample_idx, time_step]\n",
    "        print(f'{char}: {char_prob}')\n",
    "        word_prob *= char_prob\n",
    "    print(f'Word : {word}')\n",
    "    print(f'Word propability: {word_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
