{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посимвольная языковая модель.\n",
    "\n",
    "В первом задании Вам нужно написать и обучить посимвольную нейронную языковую модель для вычисления вероятностей буквенных последовательностей (то есть слов). Такие модели используются в задачах словоизменения и распознавания/порождения звучащей речи. Для обучения модели используйте данные для русского языка из [репозитория](https://github.com/sigmorphon/conll2018/tree/master/task1/surprise).\n",
    "\n",
    "**В процессе написания Вам нужно решить следующие проблемы:**\n",
    "    \n",
    "* как будет выглядеть обучающая выборка; что будет являться признаками, и что - метками классов.\n",
    "* как сделать так, чтобы модель при предсказании символа учитывала все предыдущие символы слова.\n",
    "* какие специальные символы нужно использовать.\n",
    "* как передавать в модель текущее состояние рекуррентной сети\n",
    "\n",
    "**Результаты:**\n",
    "\n",
    "* предобработчик данных,\n",
    "* генератор обучающих данных (батчей),\n",
    "* обученная модель\n",
    "* перплексия модели на настроечной выборке\n",
    "* посимвольные вероятности слов в контрольной выборке\n",
    "\n",
    "**Дополнительно:**\n",
    "\n",
    "* дополнительный вход модели (часть речи слова, другие морфологические признаки), влияет ли его добавление на перплексию\n",
    "* сравнение различных архитектур нейронной сети (FC, RNN, LSTM, QRNN, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумайте, какие вспомогательные токены могут быть вам полезны. Выдайте им индексы от `0` до `len(AUXILIARY) - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План**\n",
    "- Данные\n",
    "    - Признаки: набор символов токена, заканчивается токеном END\n",
    "    - Метки класса: набор символов того же токена, начинается с токена BEGIN\n",
    "- Для учета всех предыдущих символов, при предсказании следующего символа, дополнительно мы должны передавать на вход предыдущий токен\n",
    "- Специальные символы\n",
    "    - BEGIN, END, MASK, UNK\n",
    "- (???) Как передавать в модель текущее состояние рекуррентной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is better to do all imports at the first cell\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "from functools import partial\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download data\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-train-high\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-dev\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data')\n",
    "MODELS_PATH = Path('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "              'val': DATA_PATH/'russian-dev',\n",
    "              'test': DATA_PATH/'russian-test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        # Initialize mapping (token -> idx) if empty\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        \n",
    "        # Generate 2 mappings (tokens -> idx, idx -> token)\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            # get index of token if it is already exists in vocabulary\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            # for new token, append it to mapping with new index\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        \n",
    "        # return index of token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # return index by token\n",
    "        return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        # return token by index\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # override len function to get vocabulary size more easily\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None,\n",
    "                 unk_token='<UNK>',\n",
    "                 mask_token='<MASK>',\n",
    "                 begin_token='<BEGIN>',\n",
    "                 end_token='<END>'):\n",
    "        super().__init__(token_to_idx)\n",
    "        \n",
    "        # Save special token symbols\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_token = begin_token\n",
    "        self._end_token = end_token\n",
    "        \n",
    "        # Get and save indices for special token symbols\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)        \n",
    "        self.begin_index = self.add_token(self._begin_token)        \n",
    "        self.end_index = self.add_token(self._end_token)\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # Override method to use <UNK> index \n",
    "        # if the token is not in vocabulary\n",
    "        return self._token_to_idx.get(token, self.unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMVectorizer:\n",
    "    def __init__(self, char_vocab):\n",
    "        # Save character vocabulary\n",
    "        self.char_vocab = char_vocab\n",
    "        \n",
    "    def vectorize(self, word):\n",
    "        # Wrap word with <BEGIN> and <END> tokens\n",
    "        indices = [self.char_vocab.begin_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\n",
    "        indices.append(self.char_vocab.end_index)\n",
    "        \n",
    "        # Create source vector\n",
    "        # <BEGIN> <char1> ... <charN>\n",
    "        # where N - length of original word\n",
    "        source_vector = indices[:-1]\n",
    "        \n",
    "        # Create target vector\n",
    "        # <char1> ... <charN> <END> \n",
    "        # where N - length of original word\n",
    "        target_vector = indices[1:]\n",
    "        \n",
    "        # Calculate length of both created vectors\n",
    "        length = len(source_vector)\n",
    "        \n",
    "        # Return ource and target vectors with its length\n",
    "        return {'source_vector': source_vector, \n",
    "                'target_vector': target_vector,\n",
    "                'length': length}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, full_df, data_type):\n",
    "        # Create sequence vocabulary\n",
    "        char_vocab = SequenceVocabulary()\n",
    "        \n",
    "        # Get dataframe subset to built vocabulary\n",
    "        target_df = full_df[full_df['data_type'].isin(data_type)]\n",
    "        \n",
    "        # Add tokens to vocabulary from train dataset\n",
    "        for _, row in target_df.iterrows():\n",
    "            for char in row['word']:\n",
    "                char_vocab.add_token(char)\n",
    "            \n",
    "        return cls(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMDataset(Dataset):\n",
    "    def __init__(self, full_df, vectorizer):\n",
    "        # Save original dataset (train/val/test)\n",
    "        self.full_df = full_df\n",
    "        \n",
    "        # Save vectorizer\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        # Save train/val/test datasets separately\n",
    "        # and save its sizes (number of rows)\n",
    "        self.train_df = self.full_df[self.full_df['data_type'] == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.full_df[self.full_df['data_type'] == 'val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.full_df[self.full_df['data_type'] == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        # Store information about datasets in dictionary\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.val_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "        \n",
    "        # Set train data as default\n",
    "        self.set_data_type('train')\n",
    "    \n",
    "    @classmethod\n",
    "    def read_dataset(cls, file_path, data_type):\n",
    "        # Read specific file and save its data type (train/dev/test)\n",
    "        df = pd.read_csv(file_path, sep='\\t', \n",
    "                         header=None, names=['word'], \n",
    "                         usecols=[0])\n",
    "        df['data_type'] = data_type\n",
    "        \n",
    "        # Return dataframe with data and its type\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset(cls, file_paths):\n",
    "        dfs_list = []\n",
    "        \n",
    "        # Read all datasets specified in files_path\n",
    "        for data_type, file_path in file_paths.items():\n",
    "            df = cls.read_dataset(file_path, data_type)\n",
    "            dfs_list.append(df)\n",
    "        \n",
    "        # Concatenate all datasets\n",
    "        full_df = pd.concat(dfs_list, axis=0, ignore_index=True)\n",
    "        \n",
    "        # Return concatenated dataframe with specified data types\n",
    "        return full_df\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file_paths(cls, file_paths):\n",
    "        # Load all data from files specified in files_path\n",
    "        full_df = cls.load_dataset(file_paths)\n",
    "        \n",
    "        # Create CharLMDataset class using full dataset and vectorizer\n",
    "        return cls(full_df, CharLMVectorizer.from_dataframe(full_df, \n",
    "                                                            data_type=['train']))\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        # Return vectorizer related to Dataset\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_data_type(self, data_type='train'):\n",
    "        # Set type, data, and its size as current dataset\n",
    "        self._target_type = data_type\n",
    "        self._target_df, self._target_size = self._lookup_dict[data_type] \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return length of the current dataset\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get example by index from the current dataset\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        # Vectorize example (generate source/target vector and its length)\n",
    "        vector_dict = self._vectorizer.vectorize(row['word'])\n",
    "        \n",
    "        # Return generated vectors with its length\n",
    "        return vector_dict\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        # Calculate the number of full batches\n",
    "        # for tracking progress in tqdm\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad batch element to specified max length\n",
    "def pad_sequence(elem, item_name, max_length, value=0):\n",
    "    \n",
    "    data = elem[item_name]\n",
    "    data_len = elem['length']\n",
    "    data = np.pad(data, (0, max_length - data_len), \n",
    "                  mode='constant', constant_values=value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine padded source/target vectors and its lengths in batch for DataLoader\n",
    "def collate_fn(batch):\n",
    "    # Get length of batch elements\n",
    "    get_length_item = itemgetter('length')\n",
    "    batch_lengths = torch.tensor(list(map(get_length_item, batch)))\n",
    "    \n",
    "    # Find max length of element in batch\n",
    "    max_batch_length = torch.max(batch_lengths)\n",
    "    \n",
    "    # Pad source vectors with <MASK> token\n",
    "    padded_source_batch = partial(pad_sequence, item_name='source_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_source_batch = list(map(padded_source_batch, batch))\n",
    "    padded_source_batch = np.vstack(padded_source_batch)\n",
    "    padded_source_batch = torch.from_numpy(padded_source_batch)\n",
    "    \n",
    "    # Pad target vectors with <MASK> token\n",
    "    padded_target_batch = partial(pad_sequence, item_name='target_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_target_batch = list(map(padded_target_batch, batch))\n",
    "    padded_target_batch = np.vstack(padded_target_batch)\n",
    "    padded_target_batch = torch.from_numpy(padded_target_batch)\n",
    "    \n",
    "    # Return dictionary with source/target vectors and its lengths\n",
    "    return {'source_batch': padded_source_batch, \n",
    "            'target_batch': padded_target_batch,\n",
    "            'batch_lengths': batch_lengths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches with padding within specific batch\n",
    "def generate_batches(dataset, batch_size, collate_fn,\n",
    "                     shuffle=True, drop_last=True,\n",
    "                     device='cpu'):\n",
    "    # Create DataLoader from dataset with additional parameters\n",
    "    # Use collate_fn to pad sequences in batches \n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                             shuffle=shuffle, drop_last=drop_last,\n",
    "                             collate_fn=collate_fn)\n",
    "    \n",
    "    for data_dict in data_loader:\n",
    "        # Find indices for sorting of batch elements\n",
    "        # in decreasing order\n",
    "        lengths = data_dict['batch_lengths'].numpy()\n",
    "        sort_idx = lengths.argsort()[::-1].tolist()\n",
    "        \n",
    "        # Sort batch in decreasing order and yield it\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sort_idx].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size,\n",
    "                 hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Create embedding with zero vectors for <MASK> token \n",
    "        # for ignoring it while backprop\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_size, \n",
    "                                      padding_idx=0)\n",
    "        \n",
    "        # Use unidirectional 1-layer GRU\n",
    "        # For input and output, consider batch dimension at dim 0        \n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, \n",
    "                          bidirectional=False, batch_first=True)\n",
    "        \n",
    "        # Linear layer for prediction\n",
    "        self.fc1 = nn.Linear(in_features=hidden_size,\n",
    "                             out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x_source, x_lengths):\n",
    "        # Get embedding for source vectors\n",
    "        x_embedded = self.embedding(x_source)\n",
    "        \n",
    "        # Pack sequences for RNN\n",
    "        x_packed = pack_padded_sequence(x_embedded, x_lengths.detach().cpu().numpy(),\n",
    "                                        batch_first=True)\n",
    "        \n",
    "        # Forward sequences through RNN \n",
    "        x_rnn_out, x_rnn_h = self.rnn(x_packed)\n",
    "        \n",
    "        # Unpack sequences\n",
    "        x_unpacked, _ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        \n",
    "        # Transform sequences to vocabulary size dimension\n",
    "        y_out = self.fc1(x_unpacked)\n",
    "        \n",
    "        # Return scores\n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "{'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'в': 4, 'а': 5, 'л': 6, 'о': 7, 'н': 8, 'с': 9, 'к': 10, 'и': 11, 'й': 12, 'е': 13, 'з': 14, 'ч': 15, 'ы': 16, 'т': 17, 'р': 18, 'ё': 19, 'п': 20, 'ь': 21, 'г': 22, 'б': 23, 'ю': 24, 'я': 25, 'д': 26, 'у': 27, 'ш': 28, 'м': 29, 'х': 30, 'ж': 31, 'ц': 32, ' ': 33, 'щ': 34, '-': 35, 'ф': 36, 'э': 37, 'ъ': 38, 'С': 39, 'Ш': 40, 'И': 41, 'З': 42, 'А': 43, 'Г': 44, 'Э': 45, 'Л': 46, 'Ф': 47, 'В': 48, 'П': 49, 'М': 50, 'Р': 51, 'Б': 52, 'Х': 53, 'Н': 54, 'Е': 55}\n",
      "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'в', 5: 'а', 6: 'л', 7: 'о', 8: 'н', 9: 'с', 10: 'к', 11: 'и', 12: 'й', 13: 'е', 14: 'з', 15: 'ч', 16: 'ы', 17: 'т', 18: 'р', 19: 'ё', 20: 'п', 21: 'ь', 22: 'г', 23: 'б', 24: 'ю', 25: 'я', 26: 'д', 27: 'у', 28: 'ш', 29: 'м', 30: 'х', 31: 'ж', 32: 'ц', 33: ' ', 34: 'щ', 35: '-', 36: 'ф', 37: 'э', 38: 'ъ', 39: 'С', 40: 'Ш', 41: 'И', 42: 'З', 43: 'А', 44: 'Г', 45: 'Э', 46: 'Л', 47: 'Ф', 48: 'В', 49: 'П', 50: 'М', 51: 'Р', 52: 'Б', 53: 'Х', 54: 'Н', 55: 'Е'}\n"
     ]
    }
   ],
   "source": [
    "lm_dataset = CharLMDataset.from_file_paths(file_paths)\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "\n",
    "print(len(vectorizer.char_vocab))\n",
    "print(vectorizer.char_vocab._token_to_idx)\n",
    "print(vectorizer.char_vocab._idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_batch': tensor([[ 2,  8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12],\n",
      "        [ 2, 11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  0,  0],\n",
      "        [ 2,  4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0]]), 'target_batch': tensor([[ 8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12,  3],\n",
      "        [11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  3,  0,  0],\n",
      "        [ 4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  3,  0,  0,  0]]), 'batch_lengths': tensor([14, 12, 11])}\n",
      "tensor([[ 2,  8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12],\n",
      "        [ 2, 11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  0,  0],\n",
      "        [ 2,  4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0]]) tensor([14, 12, 11])\n"
     ]
    }
   ],
   "source": [
    "for batch in islice(generate_batches(lm_dataset, batch_size=3, \n",
    "                                     shuffle=False, collate_fn=collate_fn), 1):\n",
    "    print(batch)\n",
    "    x_source = batch['source_batch']\n",
    "    lengths = batch['batch_lengths']\n",
    "    print(x_source, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=3,\n",
    "                    hidden_size=2,\n",
    "                    num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 56])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out = model(x_source, lengths)\n",
    "y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all possible random states to fixed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create namespace with all parameters for training (specified values were used for the final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "                  'val': DATA_PATH/'russian-dev',\n",
    "                  'test': DATA_PATH/'russian-test'},\n",
    "    model_state_path = MODELS_PATH/'charLMModel.pth',\n",
    "    \n",
    "    embedding_size = 50,\n",
    "    hidden_size = 50,\n",
    "    \n",
    "    seed = 42,\n",
    "    \n",
    "    num_epochs = 10,\n",
    "    batch_size = 100,\n",
    "    learning_rate = 0.03,\n",
    "    save_iterations = 1e8,\n",
    "    early_stopping_criteria = 3,\n",
    "    factor=0.5,\n",
    "    patience=1,\n",
    "    clip_norm=1,\n",
    "    \n",
    "    cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions for creating and updating necessary parameters while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': [], \n",
    "            'epoch_idx': 0,\n",
    "            'train_loss': [],\n",
    "            'train_perplexity': [],\n",
    "            'val_loss': [],\n",
    "            'val_perplexity': [],\n",
    "            'test_loss': -1,\n",
    "            'test_perplexity': -1,\n",
    "            'model_file_name': args.model_state_path}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    if train_state['epoch_idx'] == 0:\n",
    "        train_state['stop_early'] = False\n",
    "        torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "    else:\n",
    "        loss = train_state['val_loss'][-1]\n",
    "\n",
    "        if loss < train_state['early_stopping_best_val']:\n",
    "            train_state['early_stopping_best_val'] = loss\n",
    "            train_state['early_stopping_step'] = 0\n",
    "            \n",
    "            if train_state['batch_idx'] % args.save_iterations == 0:\n",
    "                torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "        else:\n",
    "            train_state['early_stopping_step'] += 1 \n",
    "    \n",
    "        train_state['stop_early'] = (train_state['early_stopping_step'] >= args.early_stopping_criteria)\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we can use GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    args.cuda=False\n",
    "    \n",
    "print(f'Using CUDA: {args.cuda}')\n",
    "args.device = torch.device('cuda' if args.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cc9a270669141689433c5146c1d3b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=10, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d038ec30ae9d4e8cb823ae03f76b0068",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train data', style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "313d329ccdd24ec982e46d8ac74c5dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation data', max=10, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set random seeds\n",
    "set_seeds(args.seed)\n",
    "\n",
    "# Create dataset from train/val/test file paths\n",
    "lm_dataset = CharLMDataset.from_file_paths(args.file_paths)\n",
    "\n",
    "# Get vectorizer\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "\n",
    "# Get mask index for training process\n",
    "mask_index = vectorizer.char_vocab.mask_index\n",
    "\n",
    "# Get vocabulary size\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "# Create language model and set device\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=args.embedding_size,\n",
    "                    hidden_size=args.hidden_size,\n",
    "                    num_classes=vocab_size)\n",
    "model = model.to(args.device)\n",
    "\n",
    "# Create optimizer & scheduler\n",
    "optimizer = optim.Adam(params=model.parameters(),\n",
    "                      lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', \n",
    "                                                 factor=args.factor,\n",
    "                                                 patience=args.patience)\n",
    "\n",
    "# Create tqdm progress bars\n",
    "epoch_bar = tqdm_notebook(desc='Epochs', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('train')\n",
    "train_bar = tqdm_notebook(desc='Train data',\n",
    "                          total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('val')\n",
    "val_bar = tqdm_notebook(desc='Validation data',\n",
    "                        total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                        position=0)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "# writer = SummaryWriter(log_dir='logs', comment='task_1')\n",
    "\n",
    "try:\n",
    "    # Epochs loop\n",
    "    for epoch_index in range(1, args.num_epochs + 1):\n",
    "        # Save epoch index\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "        \n",
    "        # Create generator based on train data\n",
    "        lm_dataset.set_data_type('train')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        # Init values for calculating loss and cross-entropy\n",
    "        running_loss = 0.0\n",
    "        ce_sum = 0.0\n",
    "        ce_len = 0\n",
    "        \n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Get predictions for batch and reshape for loss calculation\n",
    "            y_pred = model(batch_dict['source_batch'], \n",
    "                           batch_dict['batch_lengths'])\n",
    "            y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "            \n",
    "            # Get classes for batch and reshape for loss calculation\n",
    "            y_true = batch_dict['target_batch']\n",
    "            y_true = y_true.reshape(-1)\n",
    "            \n",
    "            # Get cross-entropy for each element without aggregation\n",
    "            # Ignore <MASK> indices for calculation\n",
    "            loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                                   reduction='none')\n",
    "            \n",
    "            # Accumulate sum of cross-entropy for perplexity calculation\n",
    "            ce_sum += loss.sum().detach().item()\n",
    "            \n",
    "            # Calculate loss on non-mask tokens\n",
    "            ce_values = loss[torch.nonzero(loss).flatten()]\n",
    "            loss = ce_values.mean()\n",
    "            \n",
    "            # Run backpropagation\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip gradients for avoiding exploding gradients\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "            \n",
    "            # Accumulate number of tokens (chars) for perplexity calculation\n",
    "            ce_len += len(ce_values.detach())\n",
    "            \n",
    "            # Calculate running loss\n",
    "            loss_value = loss.item()\n",
    "            running_loss += (loss_value - running_loss) / batch_idx\n",
    "            \n",
    "            # Calculate current value of perplexity\n",
    "            perplexity = np.exp(ce_sum / ce_len)\n",
    "            \n",
    "            # Get current learning rate\n",
    "            learning_rate = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Update training progress bar\n",
    "            train_params = dict(loss=running_loss,\n",
    "                                perplexity=perplexity,\n",
    "                                lr=learning_rate)\n",
    "            train_bar.set_postfix(train_params)\n",
    "            train_bar.update()\n",
    "            \n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Save training params & metrics in current epoch\n",
    "        train_state['learning_rate'].append(learning_rate)\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_perplexity'].append(perplexity)\n",
    "        \n",
    "        \n",
    "        # Create generator based on validation data\n",
    "        lm_dataset.set_data_type('val')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        # Init values for calculating loss and cross-entropy\n",
    "        running_loss = 0.0\n",
    "        ce_sum = 0.0\n",
    "        ce_len = 0\n",
    "        \n",
    "        # Set model to evaluation mode\n",
    "        model.eval()\n",
    "        \n",
    "        # Do not calculate gradients\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "                # Get predictions for batch and reshape for loss calculation\n",
    "                y_pred = model(batch_dict['source_batch'], \n",
    "                               batch_dict['batch_lengths'])\n",
    "                y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "                \n",
    "                # Get classes for batch and reshape for loss calculation\n",
    "                y_true = batch_dict['target_batch']\n",
    "                y_true = y_true.reshape(-1)\n",
    "                \n",
    "                # Get cross-entropy for each element without aggregation\n",
    "                # Ignore <MASK> indices for calculation\n",
    "                loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                               reduction='none')\n",
    "                \n",
    "                # Accumulate sum of cross-entropy for perplexity calculation\n",
    "                ce_sum += loss.sum().detach().item()\n",
    "                \n",
    "                # Calculate loss on non-mask tokens\n",
    "                ce_values = loss[torch.nonzero(loss).flatten()]\n",
    "                loss = ce_values.mean()\n",
    "                \n",
    "                # Accumulate number of tokens (chars) for perplexity calculation\n",
    "                ce_len += len(ce_values.detach())\n",
    "                \n",
    "                # Calculate running loss\n",
    "                loss_value = loss.item()\n",
    "                running_loss += (loss_value - running_loss) / batch_idx\n",
    "                \n",
    "                # Calculate current value of perplexity\n",
    "                perplexity = np.exp(ce_sum / ce_len)\n",
    "                \n",
    "                # Update validation progress bar\n",
    "                val_params = dict(loss=running_loss, \n",
    "                                  perplexity=perplexity)\n",
    "                val_bar.set_postfix(val_params)\n",
    "                val_bar.update()\n",
    "        \n",
    "        # Save validation metrics in current epoch\n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_perplexity'].append(perplexity)\n",
    "        \n",
    "        # Update train state\n",
    "        train_state = update_train_state(args=args, \n",
    "                                         model=model, \n",
    "                                         train_state=train_state)\n",
    "        \n",
    "        # Update scheduling \n",
    "        # Decrease learning rate by factor of args.factor\n",
    "        # if validation loss is not decreasing \n",
    "        # for args.patience epochs\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "        \n",
    "        # Early stop if validation loss is not decreasing\n",
    "        # for args.early_stopping_criteria epochs\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "        \n",
    "        # Zero & update progress bars\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print('Exit training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final perplexity on validation data: 7.28\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_perplexity_final = train_state['val_perplexity'][-1]\n",
    "\n",
    "print(f'Final perplexity on validation data: {np.round(val_perplexity_final, 2)}')\n",
    "train_state_df = pd.DataFrame(train_state)\n",
    "train_state_df.filter(regex='(train|val)_loss').plot()\n",
    "train_state_df.filter(regex='(train|val)_perplexity').plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probs(dataset, model, data_type='test',\n",
    "                    batch_size=10):\n",
    "    dataset.set_data_type(data_type)\n",
    "    batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                   batch_size=batch_size,\n",
    "                                   collate_fn=collate_fn,\n",
    "                                   shuffle=False,\n",
    "                                   drop_last=False,\n",
    "                                   device=args.device)\n",
    "    \n",
    "    probs = []\n",
    "    model.eval()\n",
    "    \n",
    "    for batch_dict in islice(batch_generator, 1):\n",
    "        source_batch = batch_dict['source_batch']\n",
    "        target_batch = batch_dict['target_batch']\n",
    "        batch_lengths = batch_dict['batch_lengths']\n",
    "        \n",
    "        h_t = torch.zeros(1, source_batch.shape[0], \n",
    "                          model.rnn.hidden_size)\n",
    "        \n",
    "        with(torch.no_grad()):\n",
    "            for time_step in range(source_batch.shape[1]):\n",
    "                x_t = source_batch[:, time_step].unsqueeze(1)\n",
    "                emb_t = model.embedding(x_t)\n",
    "                rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "                \n",
    "                y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "                y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "                y_true_proba = y_pred_proba[range(source_batch.shape[0]), \n",
    "                                                  target_batch[:, time_step]]\n",
    "                probs.append(y_true_proba)\n",
    "        \n",
    "        probs = torch.stack(probs, dim=1)\n",
    "    \n",
    "    return batch_dict, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_word_probs(batch_dict, probs):\n",
    "    target_batch = batch_dict['target_batch']\n",
    "    batch_lengths = batch_dict['batch_lengths']\n",
    "       \n",
    "    for sample_idx in range(target_batch.shape[0]):\n",
    "        word_prob = 1.\n",
    "        word = ''\n",
    "        char_probs = ''\n",
    "        \n",
    "        for time_step in range(batch_lengths[sample_idx]):\n",
    "            char_idx = target_batch[sample_idx, time_step].item()\n",
    "            char = vectorizer.char_vocab.lookup_index(char_idx)\n",
    "            char_prob = probs[sample_idx, time_step]\n",
    "            \n",
    "            word += char\n",
    "            char_probs += f'{char}: {char_prob:.5f} '\n",
    "            word_prob *= char_prob     \n",
    "            \n",
    "        print(word)\n",
    "        print(char_probs)\n",
    "        print(f'Word propability: {word_prob}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "своевременный<END>\n",
      "с: 0.09771 в: 0.04814 о: 0.25881 е: 0.03328 в: 0.08659 р: 0.03992 е: 0.17182 м: 0.00663 е: 0.23240 н: 0.63696 н: 0.40620 ы: 0.89467 й: 0.99864 <END>: 0.94817 \n",
      "Word propability: 8.132163345497823e-12\n",
      "\n",
      "индексировать<END>\n",
      "и: 0.02360 н: 0.12235 д: 0.08673 е: 0.27500 к: 0.02498 с: 0.09709 и: 0.12955 р: 0.34857 о: 0.76098 в: 0.82557 а: 0.87808 т: 0.46660 ь: 0.93799 <END>: 0.79058 \n",
      "Word propability: 1.4400227676958366e-09\n",
      "\n",
      "мальтийский<END>\n",
      "м: 0.03920 а: 0.31618 л: 0.10899 ь: 0.13005 т: 0.12049 и: 0.11977 й: 0.02103 с: 0.19018 к: 0.87714 и: 0.89901 й: 0.98315 <END>: 0.93001 \n",
      "Word propability: 7.3108257225840134e-09\n",
      "\n",
      "расчленить<END>\n",
      "р: 0.04852 а: 0.59851 с: 0.31260 ч: 0.02733 л: 0.01495 е: 0.04883 н: 0.06743 и: 0.35324 т: 0.24852 ь: 0.68994 <END>: 0.54859 \n",
      "Word propability: 4.058234581716391e-10\n",
      "\n",
      "лопаться<END>\n",
      "л: 0.02237 о: 0.14441 п: 0.06485 а: 0.09252 т: 0.46924 ь: 0.14354 с: 0.26725 я: 0.97455 <END>: 0.99782 \n",
      "Word propability: 3.393217014036054e-07\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_dict, test_probs = calculate_probs(lm_dataset, model, batch_size=5)\n",
    "print_word_probs(batch_dict, test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_words(model, vectorizer, \n",
    "                   max_length=20,\n",
    "                   batch_size=10):\n",
    "    indices = []\n",
    "    probs = []\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    h_t = torch.zeros(1, batch_size, \n",
    "                      model.rnn.hidden_size)\n",
    "\n",
    "    x_t = torch.full((batch_size, 1), \n",
    "                     vectorizer.char_vocab.begin_index,\n",
    "                     dtype=torch.int64)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for time_step in range(max_length):\n",
    "            emb_t = model.embedding(x_t)\n",
    "            rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "            y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "            y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "            y_pred_idx_best = torch.multinomial(y_pred_proba, num_samples=1).squeeze(1)\n",
    "            y_pred_proba_best = y_pred_proba[range(batch_size), y_pred_idx_best]\n",
    "\n",
    "            indices.append(y_pred_idx_best)\n",
    "            probs.append(y_pred_proba_best)\n",
    "            x_t = y_pred_idx_best.unsqueeze(1)\n",
    "        \n",
    "    indices = torch.stack(indices, dim=1)\n",
    "    probs = torch.stack(probs, dim=1)\n",
    "    \n",
    "    return best_indices, best_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_generated_word_probs(vectorizer,\n",
    "                               indices, probs):\n",
    "    batch_size = indices.shape[0]\n",
    "    \n",
    "    for sample_idx in range(batch_size):\n",
    "        word_prob = 1.\n",
    "        word = ''\n",
    "        char_probs = ''\n",
    "        \n",
    "        for time_step in range(max_size):\n",
    "            char_idx = best_indices[sample_idx, time_step].item()\n",
    "            \n",
    "            if char_idx == vectorizer.char_vocab.end_index:\n",
    "                break\n",
    "                \n",
    "            char = vectorizer.char_vocab.lookup_index(char_idx)\n",
    "            char_prob = best_probs[sample_idx, time_step]\n",
    "            \n",
    "            word += char\n",
    "            char_probs += f'{char}: {char_prob:.5f} '\n",
    "            word_prob *= char_prob\n",
    "        \n",
    "        print(word)\n",
    "        print(char_probs)\n",
    "        print(f'Word propability: {word_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "жезмать\n",
      "ж: 0.01343 е: 0.23506 з: 0.08671 м: 0.07521 а: 0.34146 т: 0.18844 ь: 0.08018 \n",
      "Word propability: 1.0623301704981714e-07\n",
      "богнухный\n",
      "б: 0.08190 о: 0.02504 г: 0.02381 н: 0.05829 у: 0.59593 х: 0.04144 н: 0.22768 ы: 0.26877 й: 0.99288 \n",
      "Word propability: 4.270277464968331e-09\n",
      "жержение\n",
      "ж: 0.04393 е: 0.47637 р: 0.07109 ж: 0.04645 е: 0.68117 н: 0.54009 и: 0.30731 е: 0.68446 \n",
      "Word propability: 5.346646048565162e-06\n",
      "жездраивать\n",
      "ж: 0.01664 е: 0.22691 з: 0.07062 д: 0.21253 р: 0.03980 а: 0.38419 и: 0.01287 в: 0.49339 а: 0.79916 т: 0.93401 ь: 0.97616 \n",
      "Word propability: 4.008593013082873e-09\n",
      "прогиваться\n",
      "п: 0.24010 р: 0.56647 о: 0.35683 г: 0.05029 и: 0.08880 в: 0.05415 а: 0.22306 т: 0.88341 ь: 0.80292 с: 0.39698 я: 0.97624 \n",
      "Word propability: 7.196476303761301e-07\n",
      "тралий\n",
      "т: 0.31609 р: 0.16353 а: 0.23768 л: 0.07282 и: 0.38772 й: 0.04657 \n",
      "Word propability: 1.615312066860497e-05\n",
      "тшитворок\n",
      "т: 0.28890 ш: 0.00989 и: 0.33332 т: 0.30656 в: 0.01600 о: 0.25647 р: 0.25699 о: 0.22894 к: 0.03390 \n",
      "Word propability: 2.3902668733200017e-09\n",
      "троф\n",
      "т: 0.25030 р: 0.18687 о: 0.13839 ф: 0.04618 \n",
      "Word propability: 0.0002989218628499657\n",
      "фемлоровна\n",
      "ф: 0.03185 е: 0.08437 м: 0.01796 л: 0.04514 о: 0.12751 р: 0.04767 о: 0.40432 в: 0.24524 н: 0.08400 а: 0.05614 \n",
      "Word propability: 6.193270722654187e-12\n",
      "лошковлахт\n",
      "л: 0.07588 о: 0.08767 ш: 0.04481 к: 0.08667 о: 0.26905 в: 0.64219 л: 0.02491 а: 0.09443 х: 0.00031 т: 0.01510 \n",
      "Word propability: 4.946576189022306e-14\n"
     ]
    }
   ],
   "source": [
    "indices, probs = generate_words(model, vectorizer)\n",
    "print_generated_word_probs(vectorizer, indices, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 50])\n"
     ]
    }
   ],
   "source": [
    "best_indices = []\n",
    "best_probs = []\n",
    "batch_size = 10\n",
    "max_size = 20\n",
    "\n",
    "model.eval()\n",
    "h_t = torch.rand(1, batch_size, args.hidden_size)\n",
    "print(h_t.shape)\n",
    "\n",
    "x_t = torch.full((batch_size, 1), \n",
    "                 vectorizer.char_vocab.begin_index,\n",
    "                 dtype=torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for time_step in range(max_size):\n",
    "        emb_t = model.embedding(x_t)\n",
    "#         print(emb_t.shape)\n",
    "        rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "#         print(rnn_out_t.shape)\n",
    "        y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "#         print(y_pred.shape)\n",
    "        y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "#         print(y_pred_proba.shape)\n",
    "        y_pred_idx_best = torch.multinomial(y_pred_proba, num_samples=1).squeeze(1)\n",
    "#         print(y_pred_idx_best)\n",
    "        y_pred_proba_best = y_pred_proba[range(batch_size), y_pred_idx_best]\n",
    "#         print(y_pred_proba_best)\n",
    "        \n",
    "        best_indices.append(y_pred_idx_best)\n",
    "        best_probs.append(y_pred_proba_best)\n",
    "        x_t = y_pred_idx_best.unsqueeze(1)\n",
    "#         print(x_t)\n",
    "best_probs = torch.stack(best_probs, dim=1)\n",
    "best_indices = torch.stack(best_indices, dim=1)\n",
    "#best_probs, best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ж: 0.013434505090117455\n",
      "е: 0.23505818843841553\n",
      "з: 0.08670786768198013\n",
      "м: 0.0752064660191536\n",
      "а: 0.34145569801330566\n",
      "т: 0.1884392350912094\n",
      "ь: 0.08017576485872269\n",
      "Word : жезмать\n",
      "Word propability: 1.0623301704981714e-07\n",
      "б: 0.08189579099416733\n",
      "о: 0.025043155997991562\n",
      "г: 0.023806119337677956\n",
      "н: 0.05829021707177162\n",
      "у: 0.5959314703941345\n",
      "х: 0.04144047945737839\n",
      "н: 0.22767885029315948\n",
      "ы: 0.2687692940235138\n",
      "й: 0.992882251739502\n",
      "Word : богнухный\n",
      "Word propability: 4.270277464968331e-09\n",
      "ж: 0.04392676800489426\n",
      "е: 0.4763668179512024\n",
      "р: 0.0710882917046547\n",
      "ж: 0.046448271721601486\n",
      "е: 0.6811736822128296\n",
      "н: 0.5400915741920471\n",
      "и: 0.3073054254055023\n",
      "е: 0.6844592094421387\n",
      "Word : жержение\n",
      "Word propability: 5.346646048565162e-06\n",
      "ж: 0.01663653366267681\n",
      "е: 0.22691220045089722\n",
      "з: 0.07062467187643051\n",
      "д: 0.2125256359577179\n",
      "р: 0.03980042040348053\n",
      "а: 0.38419288396835327\n",
      "и: 0.012869732454419136\n",
      "в: 0.4933893084526062\n",
      "а: 0.7991614937782288\n",
      "т: 0.934010922908783\n",
      "ь: 0.9761595129966736\n",
      "Word : жездраивать\n",
      "Word propability: 4.008593013082873e-09\n",
      "п: 0.24010123312473297\n",
      "р: 0.5664671659469604\n",
      "о: 0.35683029890060425\n",
      "г: 0.05029077082872391\n",
      "и: 0.08880382776260376\n",
      "в: 0.05414798855781555\n",
      "а: 0.2230609804391861\n",
      "т: 0.8834146857261658\n",
      "ь: 0.802916944026947\n",
      "с: 0.3969828188419342\n",
      "я: 0.9762389063835144\n",
      "Word : прогиваться\n",
      "Word propability: 7.196476303761301e-07\n",
      "т: 0.316087931394577\n",
      "р: 0.1635276973247528\n",
      "а: 0.23768483102321625\n",
      "л: 0.07282137125730515\n",
      "и: 0.38771718740463257\n",
      "й: 0.04656738415360451\n",
      "Word : тралий\n",
      "Word propability: 1.615312066860497e-05\n",
      "т: 0.28889790177345276\n",
      "ш: 0.009891195222735405\n",
      "и: 0.3333243131637573\n",
      "т: 0.30656370520591736\n",
      "в: 0.016004247590899467\n",
      "о: 0.2564728856086731\n",
      "р: 0.2569878101348877\n",
      "о: 0.2289399951696396\n",
      "к: 0.03389647603034973\n",
      "Word : тшитворок\n",
      "Word propability: 2.3902668733200017e-09\n",
      "т: 0.25030121207237244\n",
      "р: 0.1868748962879181\n",
      "о: 0.13838554918766022\n",
      "ф: 0.04617990553379059\n",
      "Word : троф\n",
      "Word propability: 0.0002989218628499657\n",
      "ф: 0.0318533331155777\n",
      "е: 0.08437094837427139\n",
      "м: 0.0179638359695673\n",
      "л: 0.045142002403736115\n",
      "о: 0.12750795483589172\n",
      "р: 0.04766956344246864\n",
      "о: 0.40431880950927734\n",
      "в: 0.2452390342950821\n",
      "н: 0.08399615436792374\n",
      "а: 0.056135933846235275\n",
      "Word : фемлоровна\n",
      "Word propability: 6.193270722654187e-12\n",
      "л: 0.07588431984186172\n",
      "о: 0.08766923099756241\n",
      "ш: 0.044807128608226776\n",
      "к: 0.08667153865098953\n",
      "о: 0.26904579997062683\n",
      "в: 0.6421898603439331\n",
      "л: 0.02491394802927971\n",
      "а: 0.0944313034415245\n",
      "х: 0.00031202592072077096\n",
      "т: 0.015095344744622707\n",
      "Word : лошковлахт\n",
      "Word propability: 4.946576189022306e-14\n"
     ]
    }
   ],
   "source": [
    "for sample_idx in range(batch_size):\n",
    "    word = ''\n",
    "    word_prob = 1.\n",
    "    for time_step in range(max_size):\n",
    "        char_idx = best_indices[sample_idx, time_step].item()\n",
    "        if char_idx == vectorizer.char_vocab.end_index:\n",
    "            break\n",
    "        char = vectorizer.char_vocab.lookup_index(char_idx)\n",
    "        word += char\n",
    "        char_prob = best_probs[sample_idx, time_step]\n",
    "        print(f'{char}: {char_prob}')\n",
    "        word_prob *= char_prob\n",
    "    print(f'Word : {word}')\n",
    "    print(f'Word propability: {word_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                word data_type\n",
       " 11000    мальтийский      test\n",
       " 11001     расчленить      test\n",
       " 11002       лопаться      test\n",
       " 11003  индексировать      test\n",
       " 11004  своевременный      test, 1000)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset.set_data_type('test')\n",
    "lm_dataset._target_df.head(), len(lm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_batch': tensor([[ 2, 29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12],\n",
       "         [ 2, 18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  0]]),\n",
       " 'target_batch': tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "         [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]),\n",
       " 'batch_lengths': tensor([12, 11])}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                   batch_size=2,\n",
    "                                   collate_fn=collate_fn,\n",
    "                                   shuffle=False,\n",
    "                                   drop_last=False,\n",
    "                                   device=args.device)\n",
    "for batch_dict in islice(batch_generator, 1):\n",
    "    pass\n",
    "\n",
    "batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2, 29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12],\n",
       "         [ 2, 18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  0]]),\n",
       " tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "         [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]),\n",
       " tensor([12, 11]))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_batch = batch_dict['source_batch']\n",
    "target_batch = batch_dict['target_batch']\n",
    "batch_lengths = batch_dict['batch_lengths']\n",
    "\n",
    "source_batch, target_batch, batch_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 50])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n",
      "torch.Size([2, 56])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.9200e-02, 3.1618e-01, 1.0899e-01, 1.3005e-01, 1.2049e-01, 1.1977e-01,\n",
       "         2.1030e-02, 1.9018e-01, 8.7714e-01, 8.9901e-01, 9.8315e-01, 9.3001e-01],\n",
       "        [4.8516e-02, 5.9851e-01, 3.1260e-01, 2.7327e-02, 1.4954e-02, 4.8834e-02,\n",
       "         6.7430e-02, 3.5324e-01, 2.4852e-01, 6.8994e-01, 5.4859e-01, 3.7015e-07]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "h_t = torch.zeros(1, source_batch.shape[0], args.hidden_size)\n",
    "print(h_t.shape)\n",
    "\n",
    "probs = []\n",
    "with(torch.no_grad()):\n",
    "    for time_step in range(source_batch.shape[1]):\n",
    "        x_t = source_batch[:, time_step].unsqueeze(1)\n",
    "#         print(x_t.shape)\n",
    "        emb_t = model.embedding(x_t)\n",
    "#         print(emb_t.shape)\n",
    "        rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "#         print(rnn_out_t.shape, h_t.shape)\n",
    "#         print(rnn_out_t.shape)\n",
    "        y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "#         print(y_pred.shape)\n",
    "        y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "        print(y_pred_proba.shape)\n",
    "        y_true_proba = y_pred_proba[range(source_batch.shape[0]), \n",
    "                                          target_batch[:, time_step]]\n",
    "#         print(y_true_proba.shape)\n",
    "        probs.append(y_true_proba)\n",
    "probs = torch.stack(probs, dim=1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "        [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "м: 0.039199721068143845\n",
      "а: 0.3161849081516266\n",
      "л: 0.10898789018392563\n",
      "ь: 0.1300472617149353\n",
      "т: 0.12049396336078644\n",
      "и: 0.1197744756937027\n",
      "й: 0.02102978527545929\n",
      "с: 0.1901758760213852\n",
      "к: 0.8771425485610962\n",
      "и: 0.8990130424499512\n",
      "й: 0.9831482172012329\n",
      "<END>: 0.9300125241279602\n",
      "Word propability: 7.310841709795568e-09\n",
      "р: 0.04851634055376053\n",
      "а: 0.5985133647918701\n",
      "с: 0.3126019835472107\n",
      "ч: 0.027326766401529312\n",
      "л: 0.014953501522541046\n",
      "е: 0.0488337017595768\n",
      "н: 0.06742988526821136\n",
      "и: 0.35324016213417053\n",
      "т: 0.24851635098457336\n",
      "ь: 0.689936637878418\n",
      "<END>: 0.5485886931419373\n",
      "Word propability: 4.0582420757218074e-10\n"
     ]
    }
   ],
   "source": [
    "for sample_idx in range(target_batch.shape[0]):\n",
    "    word_prob = 1\n",
    "    for time_step in range(batch_lengths[sample_idx]):\n",
    "        char = vectorizer.char_vocab.lookup_index(target_batch[sample_idx, time_step].item())\n",
    "        char_prob = probs[sample_idx, time_step]\n",
    "        print(f'{char}: {char_prob}')\n",
    "        word_prob *= char_prob\n",
    "    print(f'Word propability: {word_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 50])\n"
     ]
    }
   ],
   "source": [
    "best_indices = []\n",
    "best_probs = []\n",
    "batch_size = 10\n",
    "max_size = 20\n",
    "\n",
    "model.eval()\n",
    "h_t = torch.rand(1, batch_size, args.hidden_size)\n",
    "print(h_t.shape)\n",
    "\n",
    "x_t = torch.full((batch_size, 1), \n",
    "                 vectorizer.char_vocab.begin_index,\n",
    "                 dtype=torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for time_step in range(max_size):\n",
    "        emb_t = model.embedding(x_t)\n",
    "#         print(emb_t.shape)\n",
    "        rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "#         print(rnn_out_t.shape)\n",
    "        y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "#         print(y_pred.shape)\n",
    "        y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "#         print(y_pred_proba.shape)\n",
    "        y_pred_idx_best = torch.multinomial(y_pred_proba, num_samples=1).squeeze(1)\n",
    "#         print(y_pred_idx_best)\n",
    "        y_pred_proba_best = y_pred_proba[range(batch_size), y_pred_idx_best]\n",
    "#         print(y_pred_proba_best)\n",
    "        \n",
    "        best_indices.append(y_pred_idx_best)\n",
    "        best_probs.append(y_pred_proba_best)\n",
    "        x_t = y_pred_idx_best.unsqueeze(1)\n",
    "#         print(x_t)\n",
    "best_probs = torch.stack(best_probs, dim=1)\n",
    "best_indices = torch.stack(best_indices, dim=1)\n",
    "#best_probs, best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ж: 0.013434505090117455\n",
      "е: 0.23505818843841553\n",
      "з: 0.08670786768198013\n",
      "м: 0.0752064660191536\n",
      "а: 0.34145569801330566\n",
      "т: 0.1884392350912094\n",
      "ь: 0.08017576485872269\n",
      "Word : жезмать\n",
      "Word propability: 1.0623301704981714e-07\n",
      "б: 0.08189579099416733\n",
      "о: 0.025043155997991562\n",
      "г: 0.023806119337677956\n",
      "н: 0.05829021707177162\n",
      "у: 0.5959314703941345\n",
      "х: 0.04144047945737839\n",
      "н: 0.22767885029315948\n",
      "ы: 0.2687692940235138\n",
      "й: 0.992882251739502\n",
      "Word : богнухный\n",
      "Word propability: 4.270277464968331e-09\n",
      "ж: 0.04392676800489426\n",
      "е: 0.4763668179512024\n",
      "р: 0.0710882917046547\n",
      "ж: 0.046448271721601486\n",
      "е: 0.6811736822128296\n",
      "н: 0.5400915741920471\n",
      "и: 0.3073054254055023\n",
      "е: 0.6844592094421387\n",
      "Word : жержение\n",
      "Word propability: 5.346646048565162e-06\n",
      "ж: 0.01663653366267681\n",
      "е: 0.22691220045089722\n",
      "з: 0.07062467187643051\n",
      "д: 0.2125256359577179\n",
      "р: 0.03980042040348053\n",
      "а: 0.38419288396835327\n",
      "и: 0.012869732454419136\n",
      "в: 0.4933893084526062\n",
      "а: 0.7991614937782288\n",
      "т: 0.934010922908783\n",
      "ь: 0.9761595129966736\n",
      "Word : жездраивать\n",
      "Word propability: 4.008593013082873e-09\n",
      "п: 0.24010123312473297\n",
      "р: 0.5664671659469604\n",
      "о: 0.35683029890060425\n",
      "г: 0.05029077082872391\n",
      "и: 0.08880382776260376\n",
      "в: 0.05414798855781555\n",
      "а: 0.2230609804391861\n",
      "т: 0.8834146857261658\n",
      "ь: 0.802916944026947\n",
      "с: 0.3969828188419342\n",
      "я: 0.9762389063835144\n",
      "Word : прогиваться\n",
      "Word propability: 7.196476303761301e-07\n",
      "т: 0.316087931394577\n",
      "р: 0.1635276973247528\n",
      "а: 0.23768483102321625\n",
      "л: 0.07282137125730515\n",
      "и: 0.38771718740463257\n",
      "й: 0.04656738415360451\n",
      "Word : тралий\n",
      "Word propability: 1.615312066860497e-05\n",
      "т: 0.28889790177345276\n",
      "ш: 0.009891195222735405\n",
      "и: 0.3333243131637573\n",
      "т: 0.30656370520591736\n",
      "в: 0.016004247590899467\n",
      "о: 0.2564728856086731\n",
      "р: 0.2569878101348877\n",
      "о: 0.2289399951696396\n",
      "к: 0.03389647603034973\n",
      "Word : тшитворок\n",
      "Word propability: 2.3902668733200017e-09\n",
      "т: 0.25030121207237244\n",
      "р: 0.1868748962879181\n",
      "о: 0.13838554918766022\n",
      "ф: 0.04617990553379059\n",
      "Word : троф\n",
      "Word propability: 0.0002989218628499657\n",
      "ф: 0.0318533331155777\n",
      "е: 0.08437094837427139\n",
      "м: 0.0179638359695673\n",
      "л: 0.045142002403736115\n",
      "о: 0.12750795483589172\n",
      "р: 0.04766956344246864\n",
      "о: 0.40431880950927734\n",
      "в: 0.2452390342950821\n",
      "н: 0.08399615436792374\n",
      "а: 0.056135933846235275\n",
      "Word : фемлоровна\n",
      "Word propability: 6.193270722654187e-12\n",
      "л: 0.07588431984186172\n",
      "о: 0.08766923099756241\n",
      "ш: 0.044807128608226776\n",
      "к: 0.08667153865098953\n",
      "о: 0.26904579997062683\n",
      "в: 0.6421898603439331\n",
      "л: 0.02491394802927971\n",
      "а: 0.0944313034415245\n",
      "х: 0.00031202592072077096\n",
      "т: 0.015095344744622707\n",
      "Word : лошковлахт\n",
      "Word propability: 4.946576189022306e-14\n"
     ]
    }
   ],
   "source": [
    "for sample_idx in range(batch_size):\n",
    "    word = ''\n",
    "    word_prob = 1.\n",
    "    for time_step in range(max_size):\n",
    "        char_idx = best_indices[sample_idx, time_step].item()\n",
    "        if char_idx == vectorizer.char_vocab.end_index:\n",
    "            break\n",
    "        char = vectorizer.char_vocab.lookup_index(char_idx)\n",
    "        word += char\n",
    "        char_prob = best_probs[sample_idx, time_step]\n",
    "        print(f'{char}: {char_prob}')\n",
    "        word_prob *= char_prob\n",
    "    print(f'Word : {word}')\n",
    "    print(f'Word propability: {word_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
