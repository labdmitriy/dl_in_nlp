{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посимвольная языковая модель.\n",
    "\n",
    "В первом задании Вам нужно написать и обучить посимвольную нейронную языковую модель для вычисления вероятностей буквенных последовательностей (то есть слов). Такие модели используются в задачах словоизменения и распознавания/порождения звучащей речи. Для обучения модели используйте данные для русского языка из [репозитория](https://github.com/sigmorphon/conll2018/tree/master/task1/surprise).\n",
    "\n",
    "**В процессе написания Вам нужно решить следующие проблемы:**\n",
    "    \n",
    "* как будет выглядеть обучающая выборка; что будет являться признаками, и что - метками классов.\n",
    "* как сделать так, чтобы модель при предсказании символа учитывала все предыдущие символы слова.\n",
    "* какие специальные символы нужно использовать.\n",
    "* как передавать в модель текущее состояние рекуррентной сети\n",
    "\n",
    "**Результаты:**\n",
    "\n",
    "* предобработчик данных,\n",
    "* генератор обучающих данных (батчей),\n",
    "* обученная модель\n",
    "* перплексия модели на настроечной выборке\n",
    "* посимвольные вероятности слов в контрольной выборке\n",
    "\n",
    "**Дополнительно:**\n",
    "\n",
    "* дополнительный вход модели (часть речи слова, другие морфологические признаки), влияет ли его добавление на перплексию\n",
    "* сравнение различных архитектур нейронной сети (FC, RNN, LSTM, QRNN, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумайте, какие вспомогательные токены могут быть вам полезны. Выдайте им индексы от `0` до `len(AUXILIARY) - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План**\n",
    "- Данные\n",
    "    - Признаки: набор символов токена, заканчивается токеном END\n",
    "    - Метки класса: набор символов того же токена, начинается с токена BEGIN\n",
    "- Для учета всех предыдущих символов, при предсказании следующего символа, дополнительно мы должны передавать на вход предыдущий токен\n",
    "- Специальные символы\n",
    "    - BEGIN, END, MASK, UNK\n",
    "- (???) Как передавать в модель текущее состояние рекуррентной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is better to do all imports at the first cell\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "from functools import partial\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download data\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-train-high\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-dev\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data')\n",
    "MODELS_PATH = Path('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "              'val': DATA_PATH/'russian-dev',\n",
    "              'test': DATA_PATH/'russian-test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        # Initialize mapping (token -> idx) if empty\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        \n",
    "        # Generate 2 mappings (tokens -> idx, idx -> token)\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            # get index of token if it is already exists in vocabulary\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            # for new token, append it to mapping with new index\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        \n",
    "        # return index of token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # return index by token\n",
    "        return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        # return token by index\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # override len function to get vocabulary size more easily\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None,\n",
    "                 unk_token='<UNK>',\n",
    "                 mask_token='<MASK>',\n",
    "                 begin_token='<BEGIN>',\n",
    "                 end_token='<END>'):\n",
    "        super().__init__(token_to_idx)\n",
    "        \n",
    "        # Save special token symbols\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_token = begin_token\n",
    "        self._end_token = end_token\n",
    "        \n",
    "        # Get and save indices for special token symbols\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)        \n",
    "        self.begin_index = self.add_token(self._begin_token)        \n",
    "        self.end_index = self.add_token(self._end_token)\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # Override method to use <UNK> index \n",
    "        # if the token is not in vocabulary\n",
    "        return self._token_to_idx.get(token, self.unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMVectorizer:\n",
    "    def __init__(self, char_vocab):\n",
    "        # Save character vocabulary\n",
    "        self.char_vocab = char_vocab\n",
    "        \n",
    "    def vectorize(self, word):\n",
    "        # Wrap word with <BEGIN> and <END> tokens\n",
    "        indices = [self.char_vocab.begin_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\n",
    "        indices.append(self.char_vocab.end_index)\n",
    "        \n",
    "        # Create source vector\n",
    "        # <BEGIN> <char1> ... <charN>\n",
    "        # where N - length of original word\n",
    "        source_vector = indices[:-1]\n",
    "        \n",
    "        # Create target vector\n",
    "        # <char1> ... <charN> <END> \n",
    "        # where N - length of original word\n",
    "        target_vector = indices[1:]\n",
    "        \n",
    "        # Calculate length of both created vectors\n",
    "        length = len(source_vector)\n",
    "        \n",
    "        # Return ource and target vectors with its length\n",
    "        return {'source_vector': source_vector, \n",
    "                'target_vector': target_vector,\n",
    "                'length': length}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, full_df, data_type):\n",
    "        # Create sequence vocabulary\n",
    "        char_vocab = SequenceVocabulary()\n",
    "        \n",
    "        # Get dataframe subset to built vocabulary\n",
    "        target_df = full_df[full_df['data_type'].isin(data_type)]\n",
    "        \n",
    "        # Add tokens to vocabulary from train dataset\n",
    "        for _, row in target_df.iterrows():\n",
    "            for char in row['word']:\n",
    "                char_vocab.add_token(char)\n",
    "            \n",
    "        return cls(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMDataset(Dataset):\n",
    "    def __init__(self, full_df, vectorizer):\n",
    "        # Save original dataset (train/val/test)\n",
    "        self.full_df = full_df\n",
    "        \n",
    "        # Save vectorizer\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        # Save train/val/test datasets separately\n",
    "        # and save its sizes (number of rows)\n",
    "        self.train_df = self.full_df[self.full_df['data_type'] == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.full_df[self.full_df['data_type'] == 'val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.full_df[self.full_df['data_type'] == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        # Store information about datasets in dictionary\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.val_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "        \n",
    "        # Set train data as default\n",
    "        self.set_data_type('train')\n",
    "    \n",
    "    @classmethod\n",
    "    def read_dataset(cls, file_path, data_type):\n",
    "        # Read specific file and save its data type (train/dev/test)\n",
    "        df = pd.read_csv(file_path, sep='\\t', \n",
    "                         header=None, names=['word'], \n",
    "                         usecols=[0])\n",
    "        df['data_type'] = data_type\n",
    "        \n",
    "        # Return dataframe with data and its type\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset(cls, file_paths):\n",
    "        dfs_list = []\n",
    "        \n",
    "        # Read all datasets specified in files_path\n",
    "        for data_type, file_path in file_paths.items():\n",
    "            df = cls.read_dataset(file_path, data_type)\n",
    "            dfs_list.append(df)\n",
    "        \n",
    "        # Concatenate all datasets\n",
    "        full_df = pd.concat(dfs_list, axis=0, ignore_index=True)\n",
    "        \n",
    "        # Return concatenated dataframe with specified data types\n",
    "        return full_df\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file_paths(cls, file_paths):\n",
    "        # Load all data from files specified in files_path\n",
    "        full_df = cls.load_dataset(file_paths)\n",
    "        \n",
    "        # Create CharLMDataset class using full dataset and vectorizer\n",
    "        return cls(full_df, CharLMVectorizer.from_dataframe(full_df, \n",
    "                                                            data_type=['train']))\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        # Return vectorizer related to Dataset\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_data_type(self, data_type='train'):\n",
    "        # Set type, data, and its size as current dataset\n",
    "        self._target_type = data_type\n",
    "        self._target_df, self._target_size = self._lookup_dict[data_type] \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return length of the current dataset\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get example by index from the current dataset\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        # Vectorize example (generate source/target vector and its length)\n",
    "        vector_dict = self._vectorizer.vectorize(row['word'])\n",
    "        \n",
    "        # Return generated vectors with its length\n",
    "        return vector_dict\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        # Calculate the number of full batches\n",
    "        # for tracking progress in tqdm\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad batch element to max batch length\n",
    "def pad_sequence(elem, item_name, max_length, value=0):\n",
    "    data = elem[item_name]\n",
    "    data_len = elem['length']\n",
    "    data = np.pad(data, (0, max_length - data_len), \n",
    "                  mode='constant', constant_values=value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine padded source/target vectors and its lengths in batch for DataLoader\n",
    "def collate_fn(batch):\n",
    "    get_length_item = itemgetter('length')\n",
    "    \n",
    "    batch_lengths = torch.tensor(list(map(get_length_item, batch)))\n",
    "    max_batch_length = torch.max(batch_lengths)\n",
    "    \n",
    "    padded_source_batch = partial(pad_sequence, item_name='source_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_source_batch = list(map(padded_source_batch, batch))\n",
    "    padded_source_batch = np.vstack(padded_source_batch)\n",
    "    padded_source_batch = torch.from_numpy(padded_source_batch)\n",
    "    \n",
    "    padded_target_batch = partial(pad_sequence, item_name='target_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_target_batch = list(map(padded_target_batch, batch))\n",
    "    padded_target_batch = np.vstack(padded_target_batch)\n",
    "    padded_target_batch = torch.from_numpy(padded_target_batch)\n",
    "    \n",
    "    return {'source_batch': padded_source_batch, \n",
    "            'target_batch': padded_target_batch,\n",
    "            'batch_lengths': batch_lengths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches with padding within specific batch\n",
    "def generate_batches(dataset, batch_size, collate_fn,\n",
    "                     shuffle=True, drop_last=True,\n",
    "                     device='cpu'):\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                             shuffle=shuffle, drop_last=drop_last,\n",
    "                             collate_fn=collate_fn)\n",
    "    \n",
    "    for data_dict in data_loader:\n",
    "        lengths = data_dict['batch_lengths'].numpy()\n",
    "        sort_idx = lengths.argsort()[::-1].tolist()\n",
    "        \n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sort_idx].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size,\n",
    "                 hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_size, \n",
    "                                      padding_idx=0)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, \n",
    "                          bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=hidden_size,\n",
    "                             out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x_source, x_lengths, apply_softmax=False):\n",
    "        x_embedded = self.embedding(x_source)\n",
    "        x_packed = pack_padded_sequence(x_embedded, x_lengths.detach().cpu().numpy(),\n",
    "                                        batch_first=True)\n",
    "        x_rnn_out, x_rnn_h = self.rnn(x_packed)\n",
    "        x_unpacked, _ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        y_out = self.fc1(x_unpacked)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=2)\n",
    "        \n",
    "        return y_out # x_unpacked #, x_rnn_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "{'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'в': 4, 'а': 5, 'л': 6, 'о': 7, 'н': 8, 'с': 9, 'к': 10, 'и': 11, 'й': 12, 'е': 13, 'з': 14, 'ч': 15, 'ы': 16, 'т': 17, 'р': 18, 'ё': 19, 'п': 20, 'ь': 21, 'г': 22, 'б': 23, 'ю': 24, 'я': 25, 'д': 26, 'у': 27, 'ш': 28, 'м': 29, 'х': 30, 'ж': 31, 'ц': 32, ' ': 33, 'щ': 34, '-': 35, 'ф': 36, 'э': 37, 'ъ': 38, 'С': 39, 'Ш': 40, 'И': 41, 'З': 42, 'А': 43, 'Г': 44, 'Э': 45, 'Л': 46, 'Ф': 47, 'В': 48, 'П': 49, 'М': 50, 'Р': 51, 'Б': 52, 'Х': 53, 'Н': 54, 'Е': 55}\n",
      "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'в', 5: 'а', 6: 'л', 7: 'о', 8: 'н', 9: 'с', 10: 'к', 11: 'и', 12: 'й', 13: 'е', 14: 'з', 15: 'ч', 16: 'ы', 17: 'т', 18: 'р', 19: 'ё', 20: 'п', 21: 'ь', 22: 'г', 23: 'б', 24: 'ю', 25: 'я', 26: 'д', 27: 'у', 28: 'ш', 29: 'м', 30: 'х', 31: 'ж', 32: 'ц', 33: ' ', 34: 'щ', 35: '-', 36: 'ф', 37: 'э', 38: 'ъ', 39: 'С', 40: 'Ш', 41: 'И', 42: 'З', 43: 'А', 44: 'Г', 45: 'Э', 46: 'Л', 47: 'Ф', 48: 'В', 49: 'П', 50: 'М', 51: 'Р', 52: 'Б', 53: 'Х', 54: 'Н', 55: 'Е'}\n"
     ]
    }
   ],
   "source": [
    "lm_dataset = CharLMDataset.from_file_paths(file_paths)\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "\n",
    "print(len(vectorizer.char_vocab))\n",
    "print(vectorizer.char_vocab._token_to_idx)\n",
    "print(vectorizer.char_vocab._idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_batch': tensor([[ 2,  8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12],\n",
      "        [ 2, 11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  0,  0],\n",
      "        [ 2,  4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0]]), 'target_batch': tensor([[ 8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12,  3],\n",
      "        [11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  3,  0,  0],\n",
      "        [ 4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  3,  0,  0,  0]]), 'batch_lengths': tensor([14, 12, 11])}\n",
      "tensor([[ 2,  8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12],\n",
      "        [ 2, 11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  0,  0],\n",
      "        [ 2,  4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0]]) tensor([14, 12, 11])\n"
     ]
    }
   ],
   "source": [
    "for batch in islice(generate_batches(lm_dataset, batch_size=3, \n",
    "                                     shuffle=False, collate_fn=collate_fn), 1):\n",
    "    print(batch)\n",
    "    x_source = batch['source_batch']\n",
    "    lengths = batch['batch_lengths']\n",
    "    print(x_source, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=3,\n",
    "                    hidden_size=2,\n",
    "                    num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 56])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out = model(x_source, lengths)\n",
    "y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all possible random states to fixed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create namespace with all parameters for training (specified values were used for the final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "                  'val': DATA_PATH/'russian-dev',\n",
    "                  'test': DATA_PATH/'russian-test'},\n",
    "    model_state_path = MODELS_PATH/'charLMModel.pth',\n",
    "    \n",
    "    embedding_size = 5,\n",
    "    hidden_size = 3,\n",
    "    \n",
    "    seed = 42,\n",
    "    \n",
    "    num_epochs = 10,\n",
    "    batch_size = 100,\n",
    "    learning_rate = 0.03,\n",
    "    save_iterations = 1e8,\n",
    "    early_stopping_criteria = 1e8,\n",
    "    factor=0.5,\n",
    "    patience=1e8,\n",
    "    clip_norm=5,\n",
    "    \n",
    "    cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions for creating and updating necessary parameters while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': [], \n",
    "            'epoch_idx': 0,\n",
    "            'batch_idx': 0,\n",
    "            'train_loss': [],\n",
    "            'train_perplexity': [],\n",
    "            'val_loss': [],\n",
    "            'val_perplexity': [],\n",
    "            'test_loss': -1,\n",
    "            'test_perplexity': -1,\n",
    "            'model_file_name': args.model_state_path}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    if train_state['epoch_idx'] == 0:\n",
    "        train_state['stop_early'] = False\n",
    "        torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "    else:\n",
    "        loss = train_state['dev_loss'][-1]\n",
    "\n",
    "        if loss < train_state['early_stopping_best_val']:\n",
    "            train_state['early_stopping_best_val'] = loss\n",
    "            train_state['early_stopping_step'] = 0\n",
    "            \n",
    "            if train_state['batch_idx'] % args.save_iterations == 0:\n",
    "                torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "        else:\n",
    "            train_state['early_stopping_step'] += 1 \n",
    "    \n",
    "        train_state['stop_early'] = train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we can use GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    args.cuda=False\n",
    "    \n",
    "print(f'Using CUDA: {args.cuda}')\n",
    "args.device = torch.device('cuda' if args.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c360c8585b7c4ac8bbe931be1c9808bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=10, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055e619181a246b6b0c641e5131c5573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train data', style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa65874ec4e5407c8be9a4ea082e518c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation data', max=10, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds(args.seed)\n",
    "\n",
    "lm_dataset = CharLMDataset.from_file_paths(args.file_paths)\n",
    "\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "mask_index = vectorizer.char_vocab.mask_index\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=args.embedding_size,\n",
    "                    hidden_size=args.hidden_size,\n",
    "                    num_classes=vocab_size)\n",
    "model = model.to(args.device)\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(),\n",
    "                      lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', \n",
    "                                                 factor=args.factor,\n",
    "                                                 patience=args.patience)\n",
    "\n",
    "epoch_bar = tqdm_notebook(desc='Epochs', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('train')\n",
    "train_bar = tqdm_notebook(desc='Train data',\n",
    "                          total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('val')\n",
    "val_bar = tqdm_notebook(desc='Validation data',\n",
    "                        total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                        position=0)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "# writer = SummaryWriter(log_dir='logs', comment='task_1')\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(1, args.num_epochs + 1):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "        \n",
    "        lm_dataset.set_data_type('train')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_perplexity = 0.0\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(batch_dict['source_batch'], \n",
    "                           batch_dict['batch_lengths'])\n",
    "            y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "            \n",
    "            y_true = batch_dict['target_batch']\n",
    "            y_true = y_true.reshape(-1)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y_true, \n",
    "                                   ignore_index=mask_index,\n",
    "                                   reduction='mean')\n",
    "                  \n",
    "            loss_value = loss.item()\n",
    "            running_loss += (loss_value - running_loss) / batch_idx\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "            \n",
    "            perplexity = 2 ** loss_value\n",
    "            running_perplexity += (perplexity - running_perplexity) / batch_idx\n",
    "            \n",
    "            learning_rate = optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "            train_state = update_train_state(args=args,\n",
    "                                             model=model,\n",
    "                                             train_state=train_state)\n",
    "\n",
    "            train_params = dict(loss=running_loss,\n",
    "                                perplexity=running_perplexity,\n",
    "                                lr=learning_rate)\n",
    "            train_bar.set_postfix(train_params)\n",
    "            train_bar.update()\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_state['learning_rate'].append(learning_rate)\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_perplexity'].append(running_perplexity)\n",
    "        \n",
    "        lm_dataset.set_data_type('val')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_perplexity = 0.0\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "                y_pred = model(batch_dict['source_batch'], \n",
    "                               batch_dict['batch_lengths'])\n",
    "                y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "\n",
    "                y_true = batch_dict['target_batch']\n",
    "                y_true = y_true.reshape(-1)\n",
    "\n",
    "                loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                                       reduction='mean')\n",
    "                \n",
    "                loss_value = loss.item()\n",
    "                running_loss += (loss_value - running_loss) / batch_idx\n",
    "                \n",
    "                perplexity = 2 ** loss_value\n",
    "                running_perplexity += (perplexity - running_perplexity) / batch_idx\n",
    "                \n",
    "                val_params = dict(loss=running_loss, \n",
    "                                  perplexity=running_perplexity)\n",
    "                val_bar.set_postfix(val_params)\n",
    "                val_bar.update()\n",
    "        \n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_perplexity'].append(running_perplexity)\n",
    "\n",
    "        train_state = update_train_state(args=args, \n",
    "                                         model=model, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print('Exit training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VdW99/HPL+eczBMZyUCYIUGGAGESUJA41KEqorXO3vpQqrXqVavtvZ1s+zz23l6t3jrUodYK16ogSr0qFWTQCmiAIEOYxxAIISETycm4nj/2AUIkEznJzjn5vV+v88oZ1t7nl/OC715ZZ+21xRiDUkop/xJgdwFKKaW8T8NdKaX8kIa7Ukr5IQ13pZTyQxruSinlhzTclVLKD2m4K6WUH9JwV0opP6ThrpRSfshp1xvHxcWZAQMG2PX2Sinlk9avX3/cGBPfVjvbwn3AgAHk5OTY9fZKKeWTRORAe9rpsIxSSvkhDXellPJDGu5KKeWHbBtzV0r5n7q6OvLz83G73XaX4vOCg4NJTU3F5XKd1/Ya7kopr8nPzyciIoIBAwYgInaX47OMMRQXF5Ofn8/AgQPPax86LKOU8hq3201sbKwGeyeJCLGxsZ36C0jDXSnlVRrs3tHZz9Hnwn1XYQW//mAbNfUNdpeilFI9ls+Fe/6Jal79fB9r95bYXYpSSvVYPhfuUwbHEuJysGxbod2lKKV6mNLSUp5//vkOb3fllVdSWlra4e3uuusuFi5c2OHtuoPPhXuwy8FFw+JYlleIMcbucpRSPUhL4d7Q0Pow7ocffkh0dHRXlWULn5wKOSsjkaVbC9laUM7IlCi7y1FKncOv/r6VbQXlXt3niORIfnHNBS2+/vjjj7Nnzx4yMzNxuVyEh4eTlJREbm4u27Zt47rrruPQoUO43W4eeOAB5s6dC5xZ66qyspJvfetbTJs2jS+++IKUlBTef/99QkJC2qxt+fLlPPLII9TX1zNhwgReeOEFgoKCePzxx1myZAlOp5PLLruM3//+97zzzjv86le/wuFwEBUVxerVq732GZ3ik+F+SXoCIrAsr1DDXSl12pNPPsmWLVvIzc1l5cqVXHXVVWzZsuX0XPE///nPxMTEUF1dzYQJE7jhhhuIjY09ax+7du3izTff5OWXX+amm25i0aJF3Hbbba2+r9vt5q677mL58uUMGzaMO+64gxdeeIE77riDxYsXs337dkTk9NDPE088wdKlS0lJSTmv4aD2aDPcRSQYWA0EedovNMb8olmbIOCvwHigGPiOMWa/16v1iAsPYlxaH5bnHePB7GFd9TZKqU5orYfdXSZOnHjWSUDPPvssixcvBuDQoUPs2rXrG+E+cOBAMjMzARg/fjz79+9v83127NjBwIEDGTbMyqM777yT5557jh/+8IcEBwdzzz33cNVVV3H11VcDMHXqVO666y5uuukmZs+e7Y1f9RvaM+ZeA1xijBkDZAJXiMjkZm2+B5wwxgwBngZ+590yvyk7I5HNh8s4Ulbd1W+llPJRYWFhp++vXLmSZcuWsWbNGjZt2sTYsWPPeZJQUFDQ6fsOh4P6+vo236el7/+cTidffvklN9xwA++99x5XXHEFAC+++CK/+c1vOHToEJmZmRQXF3f0V2tTm+FuLJWehy7Prflvci3wuuf+QmCWdPGZDJeOSABged6xrnwbpZQPiYiIoKKi4pyvlZWV0adPH0JDQ9m+fTtr16712vump6ezf/9+du/eDcAbb7zBxRdfTGVlJWVlZVx55ZX84Q9/IDc3F4A9e/YwadIknnjiCeLi4jh06JDXajmlXWPuIuIA1gNDgOeMMeuaNUkBDgEYY+pFpAyIBY57sdazDI4PZ0BsKMvyCrltcv+uehullA+JjY1l6tSpjBw5kpCQEBITE0+/dsUVV/Diiy8yevRohg8fzuTJzQcgzl9wcDCvvfYaN9544+kvVOfNm0dJSQnXXnstbrcbYwxPP/00AI8++ii7du3CGMOsWbMYM2aM12o5RToynVBEooHFwP3GmC1Nnt8KXG6Myfc83gNMNMYUN9t+LjAXIC0tbfyBA+26oEiLfv3BNt5Yc4CNP7+UsCCf/G5YKb+Sl5dHRkaG3WX4jXN9niKy3hiT1da2HZrnbowpBVYCVzR7KR/o53ljJxAFfOMUUmPMS8aYLGNMVnx8m5cAbFN2RiK1DY18tqvL/kBQSimf1Ga4i0i8p8eOiIQA2cD2Zs2WAHd67s8BPjXdcIZR1oA+RIW4WJanZ6sqpbrOfffdR2Zm5lm31157ze6yWtWesYwk4HXPuHsA8LYx5gMReQLIMcYsAV4F3hCR3Vg99pu7rOImXI4AZg6P59Ptx2hoNDgCdDU6pZT3Pffcc3aX0GFthrsx5mtg7Dme/3mT+27gRu+W1j7ZIxJ5L7eAjQdPkDUgxo4SlFKqx/G5tWWau2hYPM4A4RMdmlFKqdN8Ptwjg11MHhSr892VUqoJnw93gOyMBHYfq2Tf8ZN2l6KUUj2CX4T7rAzrRIXlOjSjlOqg8PDwFl/bv38/I0eO7MZqvMcvwr1fTCjpfSP4RC/goZRSgI8u+Xsu2RmJvLBqD6VVtUSHBtpdjlLqo8fh6Gbv7rPvKPjWk602eeyxx+jfvz/33nsvAL/85S8REVavXs2JEyeoq6vjN7/5Dddee22H3trtdvODH/yAnJwcnE4nTz31FDNnzmTr1q3cfffd1NbW0tjYyKJFi0hOTuamm24iPz+fhoYGfvazn/Gd73znvH/t8+EXPXewpkQ2NBpW7iiyuxSllI1uvvlm3nrrrdOP3377be6++24WL17Mhg0bWLFiBQ8//HCHr+R2aq775s2befPNN7nzzjtxu928+OKLPPDAA+Tm5pKTk0Nqaioff/wxycnJbNq0iS1btpxeDbI7+U3PfXRKFPERQXySV8h1Y1PsLkcp1UYPu6uMHTuWY8eOUVBQQFFREX369CEpKYmHHnqI1atXExAQwOHDhyksLKRv377t3u/nn3/O/fffD1irQPbv35+dO3cyZcoUfvvb35Kfn8/s2bMZOnQoo0aN4pFHHuGxxx7j6quvZvr06V3167bIb3ruAQFCdkYCq3YUUVvfaHc5SikbzZkzh4ULF/LWW29x8803s2DBAoqKili/fj25ubkkJiaecy331rTU07/llltYsmQJISEhXH755Xz66acMGzaM9evXM2rUKH7yk5/wxBNPeOPX6hC/CXewxt0ra+pZt8/7C98rpXzHzTffzN/+9jcWLlzInDlzKCsrIyEhAZfLxYoVKzifFWkvuugiFixYAMDOnTs5ePAgw4cPZ+/evQwaNIgf/ehHfPvb3+brr7+moKCA0NBQbrvtNh555BE2bNjg7V+xTX4zLAMwdUgcwa4Alm0rZPrQzq86qZTyTRdccAEVFRWkpKSQlJTErbfeyjXXXENWVhaZmZmkp6d3eJ/33nsv8+bNY9SoUTidTv7yl78QFBTEW2+9xfz583G5XPTt25ef//znfPXVVzz66KMEBATgcrl44YUXuuC3bF2H1nP3pqysLJOTk+P1/d7zeg55R8r5/LGZdPHFoJRSzeh67t7Vbeu5+4JLRyRwuLSa7UfPfaktpZTqDfxqWAbgkvRERDazbFshGUmRdpejlPIBmzdv5vbbbz/ruaCgINata35FUd/hd+EeHxFEZr9oluUVcv+soXaXo1SvY4zxuSHRUaNGnb54dU/R2SFzvxuWAWvWzKb8MgrLOzbVSSnVOcHBwRQXF3c6mHo7YwzFxcUEBwef9z78rucOVrj/59IdLM87xi2T0uwuR6leIzU1lfz8fIqK9EzxzgoODiY1NfW8t/fLcB+WGE6/mBCW5xVquCvVjVwuFwMHDrS7DIWfDsuICNkZiXy++zhVtfV2l6OUUt3OL8Md4NKMRGrqG/l813G7S1FKqW7nt+E+YWAMEcFOlukFPJRSvZDfhrvLEcCM4Ql8uv0YjY36zb1SqndpM9xFpJ+IrBCRPBHZKiIPnKNNHxFZLCJfi8iXItIjrkuVnZHA8cpacvNL7S5FKaW6VXt67vXAw8aYDGAycJ+IjGjW5qdArjFmNHAH8Ix3yzw/M4Yl4AwQlunl95RSvUyb4W6MOWKM2eC5XwHkAc2vhjECWO5psx0YICKJXq61w6JCXUwcGKPj7kqpXqdDY+4iMgAYCzRfcGETMNvTZiLQHzj/2fdelJ2RyM7CSg4Un7S7FKWU6jbtDncRCQcWAQ8aY8qbvfwk0EdEcoH7gY1YwznN9zFXRHJEJKe7zmDLzrD+gFiWd6xb3k8ppXqCdoW7iLiwgn2BMebd5q8bY8qNMXcbYzKxxtzjgX3naPeSMSbLGJMVH989F9NIiw1lWGI4y3VoRinVi7RntowArwJ5xpinWmgTLSKBnof3AKvP0bu3TXZGIuv2lVBWVWd3KUop1S3a03OfCtwOXCIiuZ7blSIyT0TmedpkAFtFZDvwLeAb0yXtlD0ikYZGw8qdOjSjlOod2lw4zBjzOdDq4szGmDVAj108PTM1mrjwQJblHePazOYTfZRSyv/47RmqTQUECJekJ7ByxzHqGhrtLkcppbpcrwh3sMbdK9z1fLWvxO5SlFKqy/WacJ82NI4gZwCf6KwZpVQv0GvCPTTQybQhcSzLK9RLgCml/F6vCXewZs0cKqlmZ2Gl3aUopVSX6lXhPis9AUDXmlFK+b1eFe4JkcGMSY3ScFdK+b1eFe5gzZrJPVTKsQq33aUopVSX6X3hPiIRY2DFdj1bVSnlv3pduKf3jSAlOoRPtmm4K6X8V68LdxHh0hGJfL67iOraBrvLUUqpLtHrwh1gVkYC7rpG/rn7uN2lKKVUl+iV4T5pYCzhQU6Wb9dZM0op/9Qrwz3QGcDFw+NZlneMxkY9W1Up5X96ZbgDXJqRSFFFDV8fLrO7FKWU8rpeG+4zhsfjCBCWbdOhGaWU/+m14R4dGkhW/z56tqpSyi/12nAHuHREItuPVnCopMruUpRSyqt6dbjPykgEYLn23pVSfqZXh/vAuDCGJISzLE/PVlVK+ZdeHe5gLSS2dm8x5e46u0tRSimv0XDPSKC+0bBqR5HdpSillNe0Ge4i0k9EVohInohsFZEHztEmSkT+LiKbPG3u7ppyvW9sWh9iwgJ13F0p5Vfa03OvBx42xmQAk4H7RGREszb3AduMMWOAGcB/iUigVyvtIo4A4ZL0BD7dfoy6hka7y1FKKa9oM9yNMUeMMRs89yuAPCCleTMgQkQECAdKsA4KPiE7I5Fydz05+0/YXYpSSnlFh8bcRWQAMBZY1+ylPwIZQAGwGXjAGOMz3eDpQ+MIdAboCU1KKb/R7nAXkXBgEfCgMaa82cuXA7lAMpAJ/FFEIs+xj7kikiMiOUVFPecLzLAgJxcOjmVZXiHG6EJiSinf165wFxEXVrAvMMa8e44mdwPvGstuYB+Q3ryRMeYlY0yWMSYrPj6+M3V7XXZGIgeKq9hTVGl3KUop1WntmS0jwKtAnjHmqRaaHQRmedonAsOBvd4qsjvMykgA0MvvKaX8Qnt67lOB24FLRCTXc7tSROaJyDxPm18DF4rIZmA58Jgxxqcuc5QUFcKolCgdd1dK+QVnWw2MMZ8D0kabAuAybxVll+yMRP6wfCfHK2uICw+yuxyllDpvvf4M1aZmZSRgDHy6XYdmlFK+TcO9iQuSI0mKCtazVZVSPs/3wr2qBFb9BzQ2eH3XIkJ2RiKrdx7HXef9/SulVHfxvXDfvRxW/BbWPNclu88ekUh1XQNr9hR3yf6VUqo7+F64j5oDGdfAp7+Go1u8vvvJg2IIC3TwiQ7NKKV8mO+Fuwhc/QwER8Pi70N9jVd3H+R0cPHweJbr2apKKR/me+EOEBYL1/4RCrdYQzReNis9kcLyGrYcbr7KglJK+QbfDHeAYZfD+Lvgn8/CgS+8uuuZ6QkECDo0o5TyWb4b7gCX/Rb6DLCGZ9ze62XHhAWS1T+GZds03JVSvsm3wz0oHK7/E5Tlw9KfeHXX2SMS2HaknMOl1V7dr1JKdQffDneAtEkw7SHYOB+2/6/XdpudkQigJzQppXyS74c7wMWPQ9/RsORHUOmdpQMGxYczKC6MT3RoRinlg/wj3J2BMPtlqKmwAt5LUxizRySydm8xFe46r+xPKaW6i3+EO0BCOmT/EnZ+BBvf8MouszMSqWswfLbLp1YvVkopPwp3gEnzYOBF8PFPoGRfp3c3Li2aPqEunTWjlPI5/hXuAQFw7fMgDlg8r9OLizkdAcxMT+DTHceob/CZ630rpZSfhTtAdD+48j/h0Fr45zOd3l12RiKlVXWsP3DCC8UppVT38L9wBxh9E4y4Dlb8Xzjydad2ddGweAIdASzXC3gopXyIf4a7CFz9NITGwrtzoc593rsKD3IyeXCsjrsrpXyKf4Y7QGiMtbhYUZ61PHAnXJqRwN7jJ9lTVOml4pRSqmv5b7gDDL0Usr5nXdhj32fnvZtZnrNVtfeulPIV/h3uAJf9GmIGwXs/AHfZee0iOTqEEUmRLNOlCJRSPsL/wz0wDGa/BOUF8NFj572b7BGJrD9wgpKTtV4sTimlukab4S4i/URkhYjkichWEXngHG0eFZFcz22LiDSISEzXlHweUrNg+sOw6U3Y9v557eLSjEQaDazQWTNKKR/Qnp57PfCwMSYDmAzcJyIjmjYwxvynMSbTGJMJ/ARYZYwp8X65nXDxjyEpE/7+IFQc7fDmI1MiSYwM0qEZpZRPaDPcjTFHjDEbPPcrgDwgpZVNvgu86Z3yvMjhshYXq6uCJfd3eHExESE7I5FVO4tw13XuzFellOpqHRpzF5EBwFhgXQuvhwJXAItaeH2uiOSISE5RUVHHKvWG+GFw6ROw6x+w/rUOb549IpGq2gbW7i3uguKUUsp72h3uIhKOFdoPGmNauqbdNcA/WxqSMca8ZIzJMsZkxcfHd7xab5jwf2DQDFj6b1C8p0ObThkUS2igg+V5Ou6ulOrZ2hXuIuLCCvYFxph3W2l6Mz1xSKapU4uLOVzWtVcb6tu9abDLwfShcSzLK8R4ac14pZTqCu2ZLSPAq0CeMeapVtpFARcD5zcdpTtFpcBVT0H+V/DPpzu0aXZGIkfK3Gwt8N4FuZVSytva03OfCtwOXNJkuuOVIjJPROY1aXc98A9jzMkuqdTbRs2BkTfAyiehILfdm12SnoAIOmtGKdWjiV3DC1lZWSYnJ8eW9z6tqgReuBCCIuH7q8AV0q7N5rzwBe76Bj64f3oXF6iUUmcTkfXGmKy22vn/GaqtCY2Ba5+D4ztg+RPt3mxWRiJbDpdzpKy6C4tTSqnz17vDHWDILJg4F9Y+D3tXtmuTS0ckAOisGaVUj6XhDpD9K4gdCu/dC9WlbTYfHB/OgNhQHXdXSvVYGu4AgaEw+0/WsgQfPtpmcxHh8gv68tmu47yfe7gbClRKqY7RcD8lZby1/szmt2FLa1P5LT+8ZAhZ/fvw4Fu5zF97oBsKVEqp9tNwb2r6w1bIf/AQlB9ptWlEsIvX/2UiM4cn8O/vbeH5lbu7qUillGqbhntTDhdc/xLU18D797W5uFiwy8Gfbh/PtZnJ/MfHO3jyo+165qpSqkfQcG8uboh19aY9y+GrV9ps7nIE8PRNmdw6KY0XV+3h397bQkOjBrxSyl5OuwvokSbcAzs+gn/8DAbNtAK/FQEBwm+uG0lUiIvnV+6hwl3PUzeNweXQY6dSyh6aPuciYp3c5AyCxXPbtbiYiPDjK9J5/Fvp/H1TAXP/mkN1ra77rpSyh4Z7SyKT4Oqn4fB6+Oy/2r3ZvIsH83+vH8XKnUXc+ecvKXfXdWGRSil1bhrurRk5G0bdBKt+Z4V8O90yKY1nbx7LhoMnuOXltRRX1nRhkUop9U0a7m258j8hoi+8+32orWr3ZteMSeblO7LYVVjJTX9ao+vQKKW6lYZ7W0Ki4brnoXgXLPtFhzadmZ7AG9+bxLHyGua8sIZ9x31jNWSllO/TcG+PQTNg0g/gy5dg9/IObTpxYAxvzp1MdV0DN764hm16kQ+lVDfQcG+v7F9A3HDr5Kaqc14itkUjU6J4+/tTcDmEm19aw/oDHdteKaU6SsO9vVwh1uJiJ4vgw0c6vPmQhHDemTeFmLBAbnvlSz7bVdQFRSqllEXDvSOSx8LFj8OWRbB5YYc3T+0TyjvzLmRAXBj/8pev+Ghz6+vXKKXU+dJw76hpD0HqBPjff4Wyji/3Gx8RxN/mTmZ0ajT3/c8G3s451AVFKqV6Ow33jnI44fo/QUMdLPoelOV3eBdRIS7e+N5Epg6J48cLv+bVz/d1QaFKqd5Mw/18xA4+c/bqs+Pg45/CyeMd2kVooJNX7sziWyP78usPtvHUJzt1RUmllNdouJ+vMTfD/eth1I2w7gV4Zgys+H/gbv9UxyCng//+7lhuykrl2eW7+NXft9GoK0oqpbygzXAXkX4iskJE8kRkq4g80EK7GSKS62mzyvul9kDRaXDdc3DvWhg8E1Y9Cc9mwprnoM7drl04HQH87obR3DNtIH/5Yj+PLNxEfUNjFxeulPJ30tZQgIgkAUnGmA0iEgGsB64zxmxr0iYa+AK4whhzUEQSjDHHWttvVlaWycnJ6fxv0JMcXg/Ln4C9KyEyFWY8BmNuscbp22CM4Y+f7ua/PtnJZSMSefa7Ywl2Obq+ZqWUTxGR9caYrLbatdlzN8YcMcZs8NyvAPKAlGbNbgHeNcYc9LRrNdj9Vsp4uON96xaRCEvuh+cnw9b32ryqk4hw/6yh/PKaEfxjWyHfe/0rTta0vdSwUkqdS4fG3EVkADAWWNfspWFAHxFZKSLrReSOFrafKyI5IpJTVOTHJ/EMmgH3LIfvzAcJgHfuhJdmWEsXtBHyd00dyH/dOIa1e0u49ZV1lFbVdkfFSik/0+5wF5FwYBHwoDGm+beGTmA8cBVwOfAzERnWfB/GmJeMMVnGmKz4+PhOlO0DRCDjGrh3DVz3AlQVw/zZ8Po1kN/6cNQN41N5/tZxbCso5zt/Wsux8vaN3yul1CntCncRcWEF+wJjzLvnaJIPfGyMOWmMOQ6sBsZ4r0wfFuCAzFusmTVX/A6O5cErs+DNW6z7Lbj8gr68dvcEDp2oYs6LazhU0v7lhpVSqj2zZQR4FcgzxjzVQrP3geki4hSRUGAS1ti8OsUZBJPnwQO5MPPfYP9n8PwUWDwPThw45yZTh8Sx4J5JlFXXMefFL9hVWNHNRSulfFV7ZstMAz4DNgOn5uj9FEgDMMa86Gn3KHC3p80rxpg/tLZfv5wt0xFVJfD5U/Dly9DYAFl3w0WPQnjCN5ruOFrB7a+uo66hkb/cPZEx/aJtKFgp1RO0d7ZMm+HeVXp9uJ9SXmBdxm/DG+AMhsk/gAvvty4S0sSB4pPc9uo6SipreeXOCUwZHGtTwUopO3ltKqTqYpHJcM0zcN+XMOxy+Oz31tmun//hrMv69Y8N453vX0hydAh3vvYly7YV2li0Uqqn03DvKeKGwI2vwfdXW6tOLvsF/Pc4yPmztUgZ0DcqmLe/P4WMvhF8f/563tvY8VUplVK9g4Z7T5M0Bm5bCHd9aC1v8MFD8NxEa/34xkb6hAWy4P9MZuKAGB56O5c31uy3u2KlVA+k4d5TDZgK/7IUvvsWuEKt5YX/dBHs/AfhgQ5eu3sCs9IT+Nn7W/n1B9so1LnwSqkm9AtVX9DYaF39acVv4MR+SJsCs35BXeok/n3xFt7KOYQjQLhsRCK3Te7PhYNjsWawKqX8jc6W8Uf1tbDxr7DqP6CyEIZeBrN+zn7nIP7ny4O8nXOI0qo6BsWHceuk/swZl0pUqMvuqpVSXqTh7s9qq+DLP8HnT4O7DNKvhtHfwT1wFh/mneCNtQfYeLCUYFcA3x6TzG2T+zM6VefGK+UPNNx7g+pS+OK/YcNf4eQxCIqEjG/DqDlsDRrD/C8P897Gw1TXNTAmNYpbJ/fnmtHJhATqUsJK+SoN996koR72r7Zm1GxbArUVEJ4II2+gcvh1LCpI4I11B9l9rJKoEBdzxqdy66Q0BsWH2125UqqDNNx7q7pq2LkUNr8Du/4BDbUQMxgzag6boi/l5TwHS7ccpb7RMG1IHLdNTiM7IxGnQydOKeULNNyVNWyT93fY/Dbs+wwwkJRJxbDrWeiewMu5bgrK3CRGBvHdiWl8d2IaiZHBdletlGqFhrs6W/kR2Pqu1aMv2AgIjQOmkxd3OX88msFHu906nVIpH6Dhrlp2fLcV8pvfgZI94Aikqv8lLA2YzpN7+lNYHaDTKZXqoTTcVduMsXrxmxdaJ0lVHsUEhnMwcRavlU/gjcL+uFwunU6pVA+i4a46prHBuoDI5nesGTc15dSHxPFl6AyeOZbJurqBjEmN1umUStlMw12dvzq3NdNm8zvWzJuGGipCUnm/4UJeq5hAUVB/bszqp9MplbKBhrvyDncZ5H0Am9/G7FuNmEYOBQ1h/slJvF8/mSFDhut0SqW6kYa78r6Ko7B1sdWjP7weg7BRRvBO7WRyQqdzxYQRXD82RXvzSnUhDXfVtYr3wOaFmK/fRkp2U4+T5Q2ZvN1wMSeSZ3D9+DSuHp1Mn7BAuytVyq9ouKvuYQwc2QSb36Fh099wVB2nRKJ5u24a75kZpA0fy+xxKcxMTyDIqV/CKtVZGu6q+zXUWV/EblyA2fkxYhr4WobxZu10VrumMzNzCNePTWVcWrSeIKXUedJwV/aqPAZfv4XZMB85vp1aCeKjhgn8rf5ijkaP5/rxaVw/NoV+MaF2V6qUT/FauItIP+CvQF+gEXjJGPNMszYzgPeBfZ6n3jXGPNHafjXcewlj4PAG2PgGZstCpKaCQkdfFrinsahhOikDhnP9uBSuHJVEVIieCatUW7wZ7klAkjFmg4hEAOuB64wx25q0mQE8Yoy5ur0Farj3QrVVsP0D2Dgf9q3CIGxwjOb16umsCJjIRSP6MXtsChcNi8el0yqVOqf2hruzrQbGmCPAEc/9ChHJA1KAba1uqFRzgaEw+ibrduIAsulNxm2cz/iGP+J2hLNk11Se2TyNH4ek8+2xKcwem8rIlEgKD4QBAAAN4klEQVQdn1fqPHRozF1EBgCrgZHGmPImz88AFgH5QAFWL37rObafC8wFSEtLG3/gwIFOlK78QmOjtezBxvmYvCVIvZvDgQP5a/U0FtZdSExCCtePS+G6zBSSo0PsrlYp23n9C1URCQdWAb81xrzb7LVIoNEYUykiVwLPGGOGtrY/HZZR3+AusxYw27gADufQKE6+CpzASxUXsspkMnFQArPHpXLFyL6EB7X5R6dSfsmr4S4iLuADYKkx5ql2tN8PZBljjrfURsNdterYdsidD5vegpPHOOmKYYm5iFdPXshhZ38uvyCR2eNSmTokDkeADtuo3sObX6gK8DpQYox5sIU2fYFCY4wRkYnAQqC/aWXnGu6qXRrqYNcnkOuZO99Yz8HQEbxWNY2F7omERPThurEpzB6XQnrfSLurVarLeTPcpwGfAZuxpkIC/BRIAzDGvCgiPwR+ANQD1cC/GmO+aG2/Gu6qwyqL4Ou3rNk2RXk0OIL5Mngaz5VO5p8N6aQnRXPDuBQuv6Cvzp9XfktPYlL+yxgo2GCF/OZFUFNGRXAyfw+YyXMlEzlMPEMSwpkxLJ6Z6QlMGBBDoFOnVir/oOGueoe6amtJ4tz5sHcVBjgWOZJVksVfj2ewpSGFsEAnU4fEMWN4AjOGx+usG+XTNNxV71N60Bq22f6h1bMHqsNSyQ2exNvlI/nfikHU4iK9bwQXD49n5vAExvfvoydMKZ+i4a56t4qjsPNj2PEx7F0J9dU0uMLZHz2ZpXWZvHZsKEWNEUQEOZk+LI4Zw6xefUJksN2VK9UqDXelTqmrhr2rYOdH1mUDK45gJIDSmEzWuibyenE6ayviAeGC5EhmeHr1mf2i9epSqsfRcFfqXBob4egm2PGRdTv6NQC1EWnkRU3jvZOj+Z/CFGoaHUSFuJg+NI6ZwxO4eHg8ceFBNhevlIa7Uu1Tdtgavtn5sdW7b6jBBEVyJH4aK8w4Xj06hL0nratJjU6NYsbwBGYOj2d0arSePKVsoeGuVEfVnrTG53d8CDv/ASePYcTBycQsckMm87eyC/jfI+EYAzFhgVw0NI6Z6QlcNDReLyeouo2Gu1Kd0dhozbjZ8ZHVqy/cAkBDn8Hsi53Ox7VjeT2/L0VVDQQIZPaL9vTqE7ggOZIA7dWrLqLhrpQ3lR60vozd8SHs/xwaajHB0ZxIuZg1joksOD6ELwoaAIgLD+LiYfFMHRLLlMGxJEXpvHrlPRruSnWVmgrY86k1zXLXUqgqhgAntSmT2R55IYurRrP4QBClVXUADIgNZcrgWCYPimXKoFidbqk6RcNdqe7Q2AD5OdY0yx0fQdF2AEzsUMqjM9jdmMxXlXF8UhTFFnc8NQQyOD6MKYNjmTIojkmDYnQWjuoQDXel7FCyzxqj37MCivKg9BBg/R8zCOXBKeyXZDZUJbC9PondjckQN5SRQwYyZXAckwfFEB2qX86qlmm4K9UT1FZByR4o2gHHd8Fx66c5vgtpqDndrNhEstsks8ckUxE+iPCUEaQNz2T0BSOJCtWevTpDw12pnqyxwfqS1hP4Dcd2UlWwDWfJLkLqy043qzaBFDhTcUcNJjQ5g6QhYwhOyoCYweDSsfveyGsXyFZKdYEAB8QMtG7DLsMBRJx67WQxNUfzyN+1idKDW5Dju4gvziWleBkBW6zOWCMB1ISnEtg3HUfCcIgbduYWGmPXb6V6EA13pXqasFiCBk9j8OBpp5+qrm1g7Z4CduZtpHj/FlwndjOo7DCDK7YzePcKAqk7s31oHMQPh7ihVg8/PMF6LizW8zMOXDo909/psIxSPuhkTT1f7S9h7d4S1u05Rsnh3QyUAtIdR5gQfpx01xES3Adw1ZaeeweusCZhH28Ffmis52dck5+eNoFhIHpiVk+gY+5K9SIV7jq+2l/Cmj3FrNlbzNaCcoyB6IBqLoiqYXhEDYNC3fQLriLJWUmMVBDVWIbLXQJVx+FksfWz3n3uN3AGN+v9t3RA8DwOitSDQRfRMXelepGIYBeXpCdySXoiAGVVdazbV8zGQ6UcLKniq+IqFh2ooqy67qztYsIC6RcTSv+kUNL6hDAoCgaGVpMaWEWslBNQXQwnj599ADh5HIp3WT/rqs5dkCPQCvpTB4SQGAiKOHMLDIegcM/9U883fRwOTp0l1Bnac1eqFymrquNgSVWz20kOllRRUOqmofFMHgQ6AkiNCSEtJvTsW6z1MzTQaU31PBX4VU0PBM0OCFUlUFsJNZVQd7J9xToCPQeB9h4Uwpu1a7KdHx0otOeulPqGqFAXo0KjGJUa9Y3X6hoaKSitPjv4i62f6/efoKKm/qz2ceFBpJ0K/9hw0mISSIsJpf+gUOLDg1pePK2xwRP0FVbY11ZCTbl1v6aihcee56qOw4l9Z15r74EiwGUdBE79VXDqIBEYfvZBo7XHgWFn9uHo+dHZ8ytUSnULlyOA/rFh9I8N+8ZrxhhKm/f6PcH/1f4TLNlUQJNOP0HOAGu4JyaUfjGhpPYJITk6hKSoYJKiQoiPiMQR/M0DTIedPlBUNjlgVDQ5KDR/3KSdu8xaz//08xVgGtv3vs7gJgeAtg4YYd9sE5kKEYmd//1bK7GtBiLSD/gr0BdoBF4yxjzTQtsJwFrgO8aYhd4sVCllHxGhT1ggfcICGdMv+huv19Y3crhpr7/4pOd+NWv3FnOytuGs9o4AITEiiL6esE+KCqZvVDDJ0SGe54JJiAhu+4IoAQ4IjrJunWWMdUnG2spmBwJP8J/z8ckzB4uq43Bi/9nb0sKw99QH4NInOl9zK9rTc68HHjbGbBCRCGC9iHxijNnWtJGIOIDfAUu7oE6lVA8W6AxgYFwYA+Na7vUfKXNztLyaglI3R8vcHClzc6Ssmrwj5SzfXoi77uxesyNASIgIOt3bPxX6p+4nRwcTHx7kvevcikBgqHUjofP7a2y0vnCu9RwEmv710Kd/5/ffhjbD3RhzBDjiuV8hInlACrCtWdP7gUXABG8XqZTyXU17/SOSI8/ZxhhDWXXd6cA/UmYdAApKrQNCSweAAIHEyOCzgv/UXwGn7idEePEA0BEBAZ4ve8O7/73p4Ji7iAwAxgLrmj2fAlwPXIKGu1Kqg0SE6NBAokMDyUhq+QBQXl1PQVm1Ffyen6cOCNuPVrBiexHVdWcPAQUIJERYgR8XHkh4kJOIYBfhwU7Cg5xEBjs9911EeJ4789NFoNOGA4MXtDvcRSQcq2f+oDGmvNnLfwAeM8Y0SCsnLojIXGAuQFpaWserVUr1WiJCVKiLqFBXmweAI+XVHCl1n/WXwJEya0iosqaeCncdFe566hvbngoe6Awg4lTgNwn9iKCzH4cHO8+087wWGew6fd/VzX89tGueu4i4gA+ApcaYp87x+j7gVKrHAVXAXGPMey3tU+e5K6XsZIyhpr6RCnc9lTX1VLrrqaixQr/S81yFu46KmqaPT7WzXjv1XEM7DhJBzgDroBDs5NZJadwzfdB51e21ee5idcVfBfLOFewAxpiBTdr/BfigtWBXSim7iQjBLgfBLgfxEed/ktOpg0S5u+6sg8CZg0bd6fsVnte64+pb7RmWmQrcDmwWkVzPcz8F0gCMMS92UW1KKdXjNT1IJES03b67tGe2zOecGXJpkzHmrs4UpJRSqvN882tgpZRSrdJwV0opP6ThrpRSfkjDXSml/JCGu1JK+SENd6WU8kMa7kop5Ydsu8yeiBQBB85z8zjguBfL8XX6eZxNP48z9LM4mz98Hv2NMfFtNbIt3DtDRHLas7ZCb6Gfx9n08zhDP4uz9abPQ4dllFLKD2m4K6WUH/LVcH/J7gJ6GP08zqafxxn6WZyt13wePjnmrpRSqnW+2nNXSinVCp8LdxG5QkR2iMhuEXnc7nrsJCL9RGSFiOSJyFYRecDumuwmIg4R2SgiH9hdi91EJFpEForIds+/kSl212QXEXnI839ki4i8KSLBdtfU1Xwq3EXEATwHfAsYAXxXREbYW5Wt6oGHjTEZwGTgvl7+eQA8AOTZXUQP8QzwsTEmHRhDL/1cRCQF+BGQZYwZCTiAm+2tquv5VLgDE4Hdxpi9xpha4G/AtTbXZBtjzBFjzAbP/Qqs/7wp9lZlHxFJBa4CXrG7FruJSCRwEdYlMjHG1BpjSu2tylZOIEREnEAoUGBzPV3O18I9BTjU5HE+vTjMmhKRAcBYYJ29ldjqD8CPgUa7C+kBBgFFwGueYapXRCTM7qLsYIw5DPweOAgcAcqMMf+wt6qu52vhfq7L/fX66T4iEg4sAh40xpTbXY8dRORq4JgxZr3dtfQQTmAc8IIxZixwEuiV31GJSB+sv/AHAslAmIjcZm9VXc/Xwj0f6NfkcSq94M+r1oiICyvYFxhj3rW7HhtNBb4tIvuxhusuEZH59pZkq3wg3xhz6i+5hVhh3xtlA/uMMUXGmDrgXeBCm2vqcr4W7l8BQ0VkoIgEYn0pssTmmmwjIoI1pppnjHnK7nrsZIz5iTEm1RgzAOvfxafGGL/vnbXEGHMUOCQiwz1PzQK22ViSnQ4Ck0Uk1PN/Zha94Mtlp90FdIQxpl5EfggsxfrG+8/GmK02l2WnqcDtwGYRyfU891NjzIc21qR6jvuBBZ6O0F7gbpvrsYUxZp2ILAQ2YM0w20gvOFNVz1BVSik/5GvDMkoppdpBw10ppfyQhrtSSvkhDXellPJDGu5KKeWHNNyVUsoPabgrpZQf0nBXSik/9P8B+CGkwfz1csIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_state_df = pd.DataFrame(train_state)\n",
    "train_state_df.filter(regex='(train|val)_loss').plot()\n",
    "train_state_df.filter(regex='(train|val)_perplexity').plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_words(model, vectorizer, sample):\n",
    "    num_samples = samples\n",
    "    indices = torch.full((num_samples, 1), \n",
    "                         vectorizer.char_vocab.begin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                word data_type\n",
       " 11000    мальтийский      test\n",
       " 11001     расчленить      test\n",
       " 11002       лопаться      test\n",
       " 11003  индексировать      test\n",
       " 11004  своевременный      test, 1000)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset.set_data_type('test')\n",
    "lm_dataset._target_df.head(), len(lm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_batch': tensor([[ 2, 29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12],\n",
       "         [ 2, 18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  0]]),\n",
       " 'target_batch': tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "         [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]),\n",
       " 'batch_lengths': tensor([12, 11])}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                   batch_size=2,\n",
    "                                   collate_fn=collate_fn,\n",
    "                                   shuffle=False,\n",
    "                                   drop_last=False,\n",
    "                                   device=args.device)\n",
    "for batch_dict in islice(batch_generator, 1):\n",
    "    pass\n",
    "\n",
    "batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2, 29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12],\n",
       "         [ 2, 18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  0]]),\n",
       " tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "         [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]),\n",
       " tensor([12, 11]))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_batch = batch_dict['source_batch']\n",
    "target_batch = batch_dict['target_batch']\n",
    "batch_lengths = batch_dict['batch_lengths']\n",
    "\n",
    "source_batch, target_batch, batch_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[2],\n",
       "         [2]])]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.full((source_batch.shape[0], 1),\n",
    "                     vectorizer.char_vocab.begin_index,\n",
    "                     dtype=torch.int64)\n",
    "h_t = None\n",
    "\n",
    "indices = [indices]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2],\n",
       "         [2]]])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_batch[:, time_step].unsqueeze(0).unsqueeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n",
      "torch.Size([1, 2, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 1, 3), got (1, 2, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-ee0900397f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx_emb_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mrnn_out_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    154\u001b[0m                               'Expected hidden[1] size {}, got {}')\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 1, 3), got (1, 2, 3)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for time_step in range(source_batch.shape[1]):\n",
    "        x_t = source_batch[:, time_step].unsqueeze(0)\n",
    "        print(x_t.shape)\n",
    "        x_emb_t = model.embedding(x_t)\n",
    "        print(x_emb_t.shape)\n",
    "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
    "        print(rnn_out.shape, h_t.shape)\n",
    "        y_pred = model.fc1(rnn_out_t)\n",
    "        print(y_pred.shape)\n",
    "        y_pred_proba = F.softmax(y_pred, dim=2, dtype=torch.int64).squeeze(1)\n",
    "        print(y_pred_proba.shape)\n",
    "        probs = y_pred_proba[range(source_batch.shape[0]), target_batch[:, 0]].unsqueeze(1)\n",
    "        print(target_batch.shape)\n",
    "        indices.append(probs)\n",
    "        print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 56]), torch.Size([2, 12]))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.zeros_like(target_batch)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0364],\n",
       "        [0.0847]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba[range(len(source_batch)), target_batch[:, 0]].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[2, 1]}, size=[2]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-a73e66d229da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[2, 1]}, size=[2]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "probs[:, 0] = y_pred_proba[range(len(source_batch)), target_batch[:, 0]].unsqueeze(1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 29 is out of bounds for dim with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-99c9ad36d476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: index 29 is out of bounds for dim with size 1"
     ]
    }
   ],
   "source": [
    "y_pred_proba[range(len(source_batch)), target_batch[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 56])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3]],\n",
       "\n",
       "        [[18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.6059e-02, 7.0550e-02, 3.3150e-02, 5.1875e-07, 1.5935e-02,\n",
       "          2.4803e-02, 3.3445e-04, 8.4979e-02, 3.4252e-02, 2.4803e-02,\n",
       "          3.3445e-04, 4.1297e-04]],\n",
       "\n",
       "        [[8.5163e-02, 7.0550e-02, 8.4979e-02, 8.2856e-03, 3.3150e-02,\n",
       "          3.5834e-02, 3.3697e-02, 2.4803e-02, 1.5935e-02, 5.1875e-07,\n",
       "          4.1297e-04, 6.4077e-05]]], grad_fn=<GatherBackward>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = range(len(source_batch))\n",
    "y_pred_proba.gather(dim=2, index=target_batch.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
