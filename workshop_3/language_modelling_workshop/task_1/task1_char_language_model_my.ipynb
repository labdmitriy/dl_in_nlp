{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посимвольная языковая модель.\n",
    "\n",
    "В первом задании Вам нужно написать и обучить посимвольную нейронную языковую модель для вычисления вероятностей буквенных последовательностей (то есть слов). Такие модели используются в задачах словоизменения и распознавания/порождения звучащей речи. Для обучения модели используйте данные для русского языка из [репозитория](https://github.com/sigmorphon/conll2018/tree/master/task1/surprise).\n",
    "\n",
    "**В процессе написания Вам нужно решить следующие проблемы:**\n",
    "    \n",
    "* как будет выглядеть обучающая выборка; что будет являться признаками, и что - метками классов.\n",
    "* как сделать так, чтобы модель при предсказании символа учитывала все предыдущие символы слова.\n",
    "* какие специальные символы нужно использовать.\n",
    "* как передавать в модель текущее состояние рекуррентной сети\n",
    "\n",
    "**Результаты:**\n",
    "\n",
    "* предобработчик данных,\n",
    "* генератор обучающих данных (батчей),\n",
    "* обученная модель\n",
    "* перплексия модели на настроечной выборке\n",
    "* посимвольные вероятности слов в контрольной выборке\n",
    "\n",
    "**Дополнительно:**\n",
    "\n",
    "* дополнительный вход модели (часть речи слова, другие морфологические признаки), влияет ли его добавление на перплексию\n",
    "* сравнение различных архитектур нейронной сети (FC, RNN, LSTM, QRNN, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подумайте, какие вспомогательные токены могут быть вам полезны. Выдайте им индексы от `0` до `len(AUXILIARY) - 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**План**\n",
    "- Данные\n",
    "    - Признаки: набор символов токена, заканчивается токеном END\n",
    "    - Метки класса: набор символов того же токена, начинается с токена BEGIN\n",
    "- Для учета всех предыдущих символов, при предсказании следующего символа, дополнительно мы должны передавать на вход предыдущий токен\n",
    "- Специальные символы\n",
    "    - BEGIN, END, MASK, UNK\n",
    "- (???) Как передавать в модель текущее состояние рекуррентной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is better to do all imports at the first cell\n",
    "from pathlib import Path\n",
    "from itertools import islice\n",
    "from operator import itemgetter\n",
    "from functools import partial\n",
    "from argparse import Namespace\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download data\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-train-high\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-dev\n",
    "# !wget https://raw.githubusercontent.com/sigmorphon/conll2018/blob/master/task1/surprise/russian-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data')\n",
    "MODELS_PATH = Path('./models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "              'val': DATA_PATH/'russian-dev',\n",
    "              'test': DATA_PATH/'russian-test'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, token_to_idx=None):\n",
    "        # Initialize mapping (token -> idx) if empty\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        \n",
    "        # Generate 2 mappings (tokens -> idx, idx -> token)\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx: token \n",
    "                              for token, idx in self._token_to_idx.items()}\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            # get index of token if it is already exists in vocabulary\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            # for new token, append it to mapping with new index\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        \n",
    "        # return index of token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # return index by token\n",
    "        return self._token_to_idx[token]\n",
    "    \n",
    "    def lookup_index(self, index):\n",
    "        # return token by index\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        # override len function to get vocabulary size more easily\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceVocabulary(Vocabulary):\n",
    "    def __init__(self, token_to_idx=None,\n",
    "                 unk_token='<UNK>',\n",
    "                 mask_token='<MASK>',\n",
    "                 begin_token='<BEGIN>',\n",
    "                 end_token='<END>'):\n",
    "        super().__init__(token_to_idx)\n",
    "        \n",
    "        # Save special token symbols\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        self._begin_token = begin_token\n",
    "        self._end_token = end_token\n",
    "        \n",
    "        # Get and save indices for special token symbols\n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = self.add_token(self._unk_token)        \n",
    "        self.begin_index = self.add_token(self._begin_token)        \n",
    "        self.end_index = self.add_token(self._end_token)\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        # Override method to use <UNK> index \n",
    "        # if the token is not in vocabulary\n",
    "        return self._token_to_idx.get(token, self.unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMVectorizer:\n",
    "    def __init__(self, char_vocab):\n",
    "        # Save character vocabulary\n",
    "        self.char_vocab = char_vocab\n",
    "        \n",
    "    def vectorize(self, word):\n",
    "        # Wrap word with <BEGIN> and <END> tokens\n",
    "        indices = [self.char_vocab.begin_index]\n",
    "        indices.extend(self.char_vocab.lookup_token(token) for token in word)\n",
    "        indices.append(self.char_vocab.end_index)\n",
    "        \n",
    "        # Create source vector\n",
    "        # <BEGIN> <char1> ... <charN>\n",
    "        # where N - length of original word\n",
    "        source_vector = indices[:-1]\n",
    "        \n",
    "        # Create target vector\n",
    "        # <char1> ... <charN> <END> \n",
    "        # where N - length of original word\n",
    "        target_vector = indices[1:]\n",
    "        \n",
    "        # Calculate length of both created vectors\n",
    "        length = len(source_vector)\n",
    "        \n",
    "        # Return ource and target vectors with its length\n",
    "        return {'source_vector': source_vector, \n",
    "                'target_vector': target_vector,\n",
    "                'length': length}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, full_df, data_type):\n",
    "        # Create sequence vocabulary\n",
    "        char_vocab = SequenceVocabulary()\n",
    "        \n",
    "        # Get dataframe subset to built vocabulary\n",
    "        target_df = full_df[full_df['data_type'].isin(data_type)]\n",
    "        \n",
    "        # Add tokens to vocabulary from train dataset\n",
    "        for _, row in target_df.iterrows():\n",
    "            for char in row['word']:\n",
    "                char_vocab.add_token(char)\n",
    "            \n",
    "        return cls(char_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMDataset(Dataset):\n",
    "    def __init__(self, full_df, vectorizer):\n",
    "        # Save original dataset (train/val/test)\n",
    "        self.full_df = full_df\n",
    "        \n",
    "        # Save vectorizer\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        # Save train/val/test datasets separately\n",
    "        # and save its sizes (number of rows)\n",
    "        self.train_df = self.full_df[self.full_df['data_type'] == 'train']\n",
    "        self.train_size = len(self.train_df)\n",
    "        \n",
    "        self.val_df = self.full_df[self.full_df['data_type'] == 'val']\n",
    "        self.val_size = len(self.val_df)\n",
    "        \n",
    "        self.test_df = self.full_df[self.full_df['data_type'] == 'test']\n",
    "        self.test_size = len(self.test_df)\n",
    "\n",
    "        # Store information about datasets in dictionary\n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.val_size),\n",
    "                             'test': (self.test_df, self.test_size)}\n",
    "        \n",
    "        # Set train data as default\n",
    "        self.set_data_type('train')\n",
    "    \n",
    "    @classmethod\n",
    "    def read_dataset(cls, file_path, data_type):\n",
    "        # Read specific file and save its data type (train/dev/test)\n",
    "        df = pd.read_csv(file_path, sep='\\t', \n",
    "                         header=None, names=['word'], \n",
    "                         usecols=[0])\n",
    "        df['data_type'] = data_type\n",
    "        \n",
    "        # Return dataframe with data and its type\n",
    "        return df\n",
    "    \n",
    "    @classmethod\n",
    "    def load_dataset(cls, file_paths):\n",
    "        dfs_list = []\n",
    "        \n",
    "        # Read all datasets specified in files_path\n",
    "        for data_type, file_path in file_paths.items():\n",
    "            df = cls.read_dataset(file_path, data_type)\n",
    "            dfs_list.append(df)\n",
    "        \n",
    "        # Concatenate all datasets\n",
    "        full_df = pd.concat(dfs_list, axis=0, ignore_index=True)\n",
    "        \n",
    "        # Return concatenated dataframe with specified data types\n",
    "        return full_df\n",
    "    \n",
    "    @classmethod\n",
    "    def from_file_paths(cls, file_paths):\n",
    "        # Load all data from files specified in files_path\n",
    "        full_df = cls.load_dataset(file_paths)\n",
    "        \n",
    "        # Create CharLMDataset class using full dataset and vectorizer\n",
    "        return cls(full_df, CharLMVectorizer.from_dataframe(full_df, \n",
    "                                                            data_type=['train']))\n",
    "    \n",
    "    def get_vectorizer(self):\n",
    "        # Return vectorizer related to Dataset\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_data_type(self, data_type='train'):\n",
    "        # Set type, data, and its size as current dataset\n",
    "        self._target_type = data_type\n",
    "        self._target_df, self._target_size = self._lookup_dict[data_type] \n",
    "        \n",
    "    def __len__(self):\n",
    "        # Return length of the current dataset\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get example by index from the current dataset\n",
    "        row = self._target_df.iloc[index]\n",
    "        \n",
    "        # Vectorize example (generate source/target vector and its length)\n",
    "        vector_dict = self._vectorizer.vectorize(row['word'])\n",
    "        \n",
    "        # Return generated vectors with its length\n",
    "        return vector_dict\n",
    "    \n",
    "    def get_num_batches(self, batch_size):\n",
    "        # Calculate the number of full batches\n",
    "        # for tracking progress in tqdm\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad batch element to max batch length\n",
    "def pad_sequence(elem, item_name, max_length, value=0):\n",
    "    data = elem[item_name]\n",
    "    data_len = elem['length']\n",
    "    data = np.pad(data, (0, max_length - data_len), \n",
    "                  mode='constant', constant_values=value)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine padded source/target vectors and its lengths in batch for DataLoader\n",
    "def collate_fn(batch):\n",
    "    get_length_item = itemgetter('length')\n",
    "    \n",
    "    batch_lengths = torch.tensor(list(map(get_length_item, batch)))\n",
    "    max_batch_length = torch.max(batch_lengths)\n",
    "    \n",
    "    padded_source_batch = partial(pad_sequence, item_name='source_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_source_batch = list(map(padded_source_batch, batch))\n",
    "    padded_source_batch = np.vstack(padded_source_batch)\n",
    "    padded_source_batch = torch.from_numpy(padded_source_batch)\n",
    "    \n",
    "    padded_target_batch = partial(pad_sequence, item_name='target_vector', \n",
    "                                  max_length=max_batch_length, value=0)\n",
    "    padded_target_batch = list(map(padded_target_batch, batch))\n",
    "    padded_target_batch = np.vstack(padded_target_batch)\n",
    "    padded_target_batch = torch.from_numpy(padded_target_batch)\n",
    "    \n",
    "    return {'source_batch': padded_source_batch, \n",
    "            'target_batch': padded_target_batch,\n",
    "            'batch_lengths': batch_lengths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate batches with padding within specific batch\n",
    "def generate_batches(dataset, batch_size, collate_fn,\n",
    "                     shuffle=True, drop_last=True,\n",
    "                     device='cpu'):\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                             shuffle=shuffle, drop_last=drop_last,\n",
    "                             collate_fn=collate_fn)\n",
    "    \n",
    "    for data_dict in data_loader:\n",
    "        lengths = data_dict['batch_lengths'].numpy()\n",
    "        sort_idx = lengths.argsort()[::-1].tolist()\n",
    "        \n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name][sort_idx].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLMModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_size,\n",
    "                 hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_size, \n",
    "                                      padding_idx=0)\n",
    "        self.rnn = nn.GRU(embedding_size, hidden_size, \n",
    "                          bidirectional=False, batch_first=True)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=hidden_size,\n",
    "                             out_features=num_classes)\n",
    "        \n",
    "    def forward(self, x_source, x_lengths, apply_softmax=False):\n",
    "        x_embedded = self.embedding(x_source)\n",
    "        x_packed = pack_padded_sequence(x_embedded, x_lengths.detach().cpu().numpy(),\n",
    "                                        batch_first=True)\n",
    "        x_rnn_out, x_rnn_h = self.rnn(x_packed)\n",
    "        x_unpacked, _ = pad_packed_sequence(x_rnn_out, batch_first=True)\n",
    "        y_out = self.fc1(x_unpacked)\n",
    "        \n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out, dim=2)\n",
    "        \n",
    "        return y_out # x_unpacked #, x_rnn_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "{'<MASK>': 0, '<UNK>': 1, '<BEGIN>': 2, '<END>': 3, 'в': 4, 'а': 5, 'л': 6, 'о': 7, 'н': 8, 'с': 9, 'к': 10, 'и': 11, 'й': 12, 'е': 13, 'з': 14, 'ч': 15, 'ы': 16, 'т': 17, 'р': 18, 'ё': 19, 'п': 20, 'ь': 21, 'г': 22, 'б': 23, 'ю': 24, 'я': 25, 'д': 26, 'у': 27, 'ш': 28, 'м': 29, 'х': 30, 'ж': 31, 'ц': 32, ' ': 33, 'щ': 34, '-': 35, 'ф': 36, 'э': 37, 'ъ': 38, 'С': 39, 'Ш': 40, 'И': 41, 'З': 42, 'А': 43, 'Г': 44, 'Э': 45, 'Л': 46, 'Ф': 47, 'В': 48, 'П': 49, 'М': 50, 'Р': 51, 'Б': 52, 'Х': 53, 'Н': 54, 'Е': 55}\n",
      "{0: '<MASK>', 1: '<UNK>', 2: '<BEGIN>', 3: '<END>', 4: 'в', 5: 'а', 6: 'л', 7: 'о', 8: 'н', 9: 'с', 10: 'к', 11: 'и', 12: 'й', 13: 'е', 14: 'з', 15: 'ч', 16: 'ы', 17: 'т', 18: 'р', 19: 'ё', 20: 'п', 21: 'ь', 22: 'г', 23: 'б', 24: 'ю', 25: 'я', 26: 'д', 27: 'у', 28: 'ш', 29: 'м', 30: 'х', 31: 'ж', 32: 'ц', 33: ' ', 34: 'щ', 35: '-', 36: 'ф', 37: 'э', 38: 'ъ', 39: 'С', 40: 'Ш', 41: 'И', 42: 'З', 43: 'А', 44: 'Г', 45: 'Э', 46: 'Л', 47: 'Ф', 48: 'В', 49: 'П', 50: 'М', 51: 'Р', 52: 'Б', 53: 'Х', 54: 'Н', 55: 'Е'}\n"
     ]
    }
   ],
   "source": [
    "lm_dataset = CharLMDataset.from_file_paths(file_paths)\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "\n",
    "print(len(vectorizer.char_vocab))\n",
    "print(vectorizer.char_vocab._token_to_idx)\n",
    "print(vectorizer.char_vocab._idx_to_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source_batch': tensor([[ 2,  8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12],\n",
      "        [ 2, 11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  0,  0],\n",
      "        [ 2,  4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0]]), 'target_batch': tensor([[ 8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12,  3],\n",
      "        [11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  3,  0,  0],\n",
      "        [ 4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  3,  0,  0,  0]]), 'batch_lengths': tensor([14, 12, 11])}\n",
      "tensor([[ 2,  8, 13, 14,  5, 10,  7,  8, 15, 13,  8,  8, 16, 12],\n",
      "        [ 2, 11,  9, 17, 18, 19, 20, 16,  4,  5, 17, 21,  0,  0],\n",
      "        [ 2,  4,  5,  6,  6,  7,  8,  9, 10, 11, 12,  0,  0,  0]]) tensor([14, 12, 11])\n"
     ]
    }
   ],
   "source": [
    "for batch in islice(generate_batches(lm_dataset, batch_size=3, \n",
    "                                     shuffle=False, collate_fn=collate_fn), 1):\n",
    "    print(batch)\n",
    "    x_source = batch['source_batch']\n",
    "    lengths = batch['batch_lengths']\n",
    "    print(x_source, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=3,\n",
    "                    hidden_size=2,\n",
    "                    num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 14, 56])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out = model(x_source, lengths)\n",
    "y_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting all possible random states to fixed number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create namespace with all parameters for training (specified values were used for the final model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    file_paths = {'train': DATA_PATH/'russian-train-high',\n",
    "                  'val': DATA_PATH/'russian-dev',\n",
    "                  'test': DATA_PATH/'russian-test'},\n",
    "    model_state_path = MODELS_PATH/'charLMModel.pth',\n",
    "    \n",
    "    embedding_size = 5,\n",
    "    hidden_size = 3,\n",
    "    \n",
    "    seed = 42,\n",
    "    \n",
    "    num_epochs = 10,\n",
    "    batch_size = 100,\n",
    "    learning_rate = 0.03,\n",
    "    save_iterations = 1e8,\n",
    "    early_stopping_criteria = 1e8,\n",
    "    factor=0.5,\n",
    "    patience=1e8,\n",
    "    clip_norm=5,\n",
    "    \n",
    "    cuda=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions for creating and updating necessary parameters while training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_state(args):\n",
    "    return {'stop_early': False,\n",
    "            'early_stopping_step': 0,\n",
    "            'early_stopping_best_val': 1e8,\n",
    "            'learning_rate': [], \n",
    "            'epoch_idx': 0,\n",
    "            'batch_idx': 0,\n",
    "            'train_loss': [],\n",
    "            'train_perplexity': [],\n",
    "            'val_loss': [],\n",
    "            'val_perplexity': [],\n",
    "            'test_loss': -1,\n",
    "            'test_perplexity': -1,\n",
    "            'model_file_name': args.model_state_path}\n",
    "\n",
    "def update_train_state(args, model, train_state):\n",
    "    if train_state['epoch_idx'] == 0:\n",
    "        train_state['stop_early'] = False\n",
    "        torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "    else:\n",
    "        loss = train_state['dev_loss'][-1]\n",
    "\n",
    "        if loss < train_state['early_stopping_best_val']:\n",
    "            train_state['early_stopping_best_val'] = loss\n",
    "            train_state['early_stopping_step'] = 0\n",
    "            \n",
    "            if train_state['batch_idx'] % args.save_iterations == 0:\n",
    "                torch.save(model.state_dict(), train_state['model_file_name'])\n",
    "        else:\n",
    "            train_state['early_stopping_step'] += 1 \n",
    "    \n",
    "        train_state['stop_early'] = train_state['early_stopping_step'] >= args.early_stopping_criteria\n",
    "    return train_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if we can use GPU or CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    }
   ],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    args.cuda=False\n",
    "    \n",
    "print(f'Using CUDA: {args.cuda}')\n",
    "args.device = torch.device('cuda' if args.cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Training Cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7147f39697b84c2dbb795aef1af77f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=10, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2a2ed10f244dd59242992366b7dcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train data', style=ProgressStyle(description_width='initial')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7859cad0864e03a27f9c0e0e8c4504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validation data', max=10, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exit training\n"
     ]
    }
   ],
   "source": [
    "set_seeds(args.seed)\n",
    "\n",
    "lm_dataset = CharLMDataset.from_file_paths(args.file_paths)\n",
    "\n",
    "vectorizer = lm_dataset.get_vectorizer()\n",
    "mask_index = vectorizer.char_vocab.mask_index\n",
    "vocab_size = len(vectorizer.char_vocab)\n",
    "\n",
    "model = CharLMModel(num_embeddings=vocab_size,\n",
    "                    embedding_size=args.embedding_size,\n",
    "                    hidden_size=args.hidden_size,\n",
    "                    num_classes=vocab_size)\n",
    "model = model.to(args.device)\n",
    "\n",
    "optimizer = optim.Adam(params=model.parameters(),\n",
    "                      lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                 mode='min', \n",
    "                                                 factor=args.factor,\n",
    "                                                 patience=args.patience)\n",
    "\n",
    "epoch_bar = tqdm_notebook(desc='Epochs', \n",
    "                          total=args.num_epochs,\n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('train')\n",
    "train_bar = tqdm_notebook(desc='Train data',\n",
    "                          total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                          position=0)\n",
    "\n",
    "lm_dataset.set_data_type('val')\n",
    "val_bar = tqdm_notebook(desc='Validation data',\n",
    "                        total=lm_dataset.get_num_batches(args.batch_size), \n",
    "                        position=0)\n",
    "\n",
    "train_state = make_train_state(args)\n",
    "\n",
    "# writer = SummaryWriter(log_dir='logs', comment='task_1')\n",
    "\n",
    "try:\n",
    "    for epoch_index in range(1, args.num_epochs + 1):\n",
    "        train_state['epoch_index'] = epoch_index\n",
    "        \n",
    "        lm_dataset.set_data_type('train')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        ce_sum = 0.0\n",
    "        ce_len = 0\n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            y_pred = model(batch_dict['source_batch'], \n",
    "                           batch_dict['batch_lengths'])\n",
    "            y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "            \n",
    "            y_true = batch_dict['target_batch']\n",
    "            y_true = y_true.reshape(-1)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                               reduction='none')\n",
    "            ce_sum += loss.sum().detach().item()\n",
    "            ce_values = loss[torch.nonzero(loss).flatten()]\n",
    "            loss = ce_values.mean()\n",
    "\n",
    "            ce_len += len(ce_values.detach())\n",
    "                  \n",
    "            loss_value = loss.item()\n",
    "            running_loss += (loss_value - running_loss) / batch_idx\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_norm)\n",
    "            \n",
    "            perplexity = np.exp(ce_sum / ce_len)\n",
    "            \n",
    "            learning_rate = optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "            train_state = update_train_state(args=args,\n",
    "                                             model=model,\n",
    "                                             train_state=train_state)\n",
    "\n",
    "            train_params = dict(loss=running_loss,\n",
    "                                perplexity=perplexity,\n",
    "                                lr=learning_rate)\n",
    "            train_bar.set_postfix(train_params)\n",
    "            train_bar.update()\n",
    "\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_state['learning_rate'].append(learning_rate)\n",
    "        train_state['train_loss'].append(running_loss)\n",
    "        train_state['train_perplexity'].append(perplexity)\n",
    "        \n",
    "        lm_dataset.set_data_type('val')\n",
    "        batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                           batch_size=args.batch_size,\n",
    "                                           collate_fn=collate_fn,\n",
    "                                           shuffle=False,\n",
    "                                           drop_last=False,\n",
    "                                           device=args.device)\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        ce_sum = 0.0\n",
    "        ce_len = 0\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, batch_dict in enumerate(batch_generator, 1):\n",
    "                y_pred = model(batch_dict['source_batch'], \n",
    "                               batch_dict['batch_lengths'])\n",
    "                y_pred = y_pred.reshape(-1, y_pred.shape[2])\n",
    "\n",
    "                y_true = batch_dict['target_batch']\n",
    "                y_true = y_true.reshape(-1)\n",
    "\n",
    "                loss = F.cross_entropy(y_pred, y_true, ignore_index=mask_index,\n",
    "                               reduction='none')\n",
    "                ce_sum += loss.sum().detach().item()\n",
    "                ce_values = loss[torch.nonzero(loss).flatten()]\n",
    "                loss = ce_values.mean()\n",
    "\n",
    "                ce_len += len(ce_values.detach())\n",
    "\n",
    "                loss_value = loss.item()\n",
    "                running_loss += (loss_value - running_loss) / batch_idx\n",
    "                \n",
    "                perplexity = np.exp(ce_sum / ce_len)\n",
    "                \n",
    "                val_params = dict(loss=running_loss, \n",
    "                                  perplexity=perplexity)\n",
    "                val_bar.set_postfix(val_params)\n",
    "                val_bar.update()\n",
    "        \n",
    "        train_state['val_loss'].append(running_loss)\n",
    "        train_state['val_perplexity'].append(perplexity)\n",
    "\n",
    "        train_state = update_train_state(args=args, \n",
    "                                         model=model, \n",
    "                                         train_state=train_state)\n",
    "\n",
    "        scheduler.step(train_state['val_loss'][-1])\n",
    "\n",
    "        if train_state['stop_early']:\n",
    "            break\n",
    "            \n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        epoch_bar.update()\n",
    "except KeyboardInterrupt:\n",
    "    print('Exit training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_state_df = pd.DataFrame(train_state)\n",
    "train_state_df.filter(regex='(train|val)_loss').plot()\n",
    "train_state_df.filter(regex='(train|val)_perplexity').plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_words(model, vectorizer, sample):\n",
    "    num_samples = samples\n",
    "    indices = torch.full((num_samples, 1), \n",
    "                         vectorizer.char_vocab.begin_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                word data_type\n",
       " 11000    мальтийский      test\n",
       " 11001     расчленить      test\n",
       " 11002       лопаться      test\n",
       " 11003  индексировать      test\n",
       " 11004  своевременный      test, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_dataset.set_data_type('test')\n",
    "lm_dataset._target_df.head(), len(lm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source_batch': tensor([[ 2, 29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12],\n",
       "         [ 2, 18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  0]]),\n",
       " 'target_batch': tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "         [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]),\n",
       " 'batch_lengths': tensor([12, 11])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_generator = generate_batches(dataset=lm_dataset, \n",
    "                                   batch_size=2,\n",
    "                                   collate_fn=collate_fn,\n",
    "                                   shuffle=False,\n",
    "                                   drop_last=False,\n",
    "                                   device=args.device)\n",
    "for batch_dict in islice(batch_generator, 1):\n",
    "    pass\n",
    "\n",
    "batch_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2, 29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12],\n",
       "         [ 2, 18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  0]]),\n",
       " tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "         [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]),\n",
       " tensor([12, 11]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_batch = batch_dict['source_batch']\n",
    "target_batch = batch_dict['target_batch']\n",
    "batch_lengths = batch_dict['batch_lengths']\n",
    "\n",
    "source_batch, target_batch, batch_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[2],\n",
       "         [2]])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = torch.full((source_batch.shape[0], 1),\n",
    "                     vectorizer.char_vocab.begin_index,\n",
    "                     dtype=torch.int64)\n",
    "h_t = None\n",
    "\n",
    "indices = [indices]\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "h_t = torch.zeros(1, source_batch.shape[0], args.hidden_size)\n",
    "print(h_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0454, 0.0195, 0.0213, 0.0079, 0.0092, 0.0011, 0.0164, 0.0020, 0.0032,\n",
       "         0.0049, 0.0181, 0.0016],\n",
       "        [0.0906, 0.0760, 0.0649, 0.0685, 0.0396, 0.0286, 0.0237, 0.0228, 0.0186,\n",
       "         0.0128, 0.0053, 0.0316]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = []\n",
    "with(torch.no_grad()):\n",
    "    for time_step in range(source_batch.shape[1]):\n",
    "        x_t = source_batch[:, time_step].unsqueeze(1)\n",
    "#         print(x_t.shape)\n",
    "        emb_t = model.embedding(x_t)\n",
    "#         print(emb_t.shape)\n",
    "        rnn_out_t, h_t = model.rnn(emb_t, h_t)\n",
    "#         print(rnn_out_t.shape, h_t.shape)\n",
    "#         print(rnn_out_t.shape)\n",
    "        y_pred = model.fc1(rnn_out_t.squeeze(1))\n",
    "#         print(y_pred.shape)\n",
    "        y_pred_proba = F.softmax(y_pred, dim=1)\n",
    "#         print(y_pred_proba.shape)\n",
    "        y_true_proba = y_pred_proba[range(source_batch.shape[0]), \n",
    "                                          target_batch[:, 0]]\n",
    "        probs.append(y_true_proba)\n",
    "probs = torch.stack(probs, dim=1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3],\n",
       "        [18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "м: 0.04542377218604088\n",
      "а: 0.01947995088994503\n",
      "л: 0.021266799420118332\n",
      "ь: 0.007854786701500416\n",
      "т: 0.009223837405443192\n",
      "и: 0.001107070012949407\n",
      "й: 0.016374735161662102\n",
      "с: 0.0019611262250691652\n",
      "к: 0.0032304723281413317\n",
      "и: 0.004923509433865547\n",
      "й: 0.01813102327287197\n",
      "<END>: 0.001570182852447033\n",
      "Word propability: 2.1947624934556815e-26\n",
      "р: 0.09061463177204132\n",
      "а: 0.07604116946458817\n",
      "с: 0.06489808857440948\n",
      "ч: 0.06847822666168213\n",
      "л: 0.03961785137653351\n",
      "е: 0.028586266562342644\n",
      "н: 0.023708298802375793\n",
      "и: 0.022808272391557693\n",
      "т: 0.018595276400446892\n",
      "ь: 0.012797767296433449\n",
      "<END>: 0.005268452223390341\n",
      "Word propability: 2.3512160579927808e-17\n"
     ]
    }
   ],
   "source": [
    "for sample_idx in range(target_batch.shape[0]):\n",
    "    word_prob = 1\n",
    "    for time_step in range(batch_lengths[sample_idx]):\n",
    "        char = vectorizer.char_vocab.lookup_index(target_batch[sample_idx, time_step].item())\n",
    "        char_prob = probs[sample_idx, time_step]\n",
    "        print(f'{char}: {char_prob}')\n",
    "        word_prob *= char_prob\n",
    "    print(f'Word propability: {word_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'м'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.char_vocab.lookup_index(29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2])\n",
      "torch.Size([2, 1, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden size (1, 2, 3), got (1, 1, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-3e7a7aaed395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mx_emb_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mrnn_out_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_emb_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_out_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    154\u001b[0m                               'Expected hidden[1] size {}, got {}')\n\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m             \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ml/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Expected hidden size {}, got {}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'LSTM'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 2, 3), got (1, 1, 3)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for time_step in range(source_batch.shape[1]):\n",
    "        x_t = source_batch[:, time_step]\n",
    "        print(x_t)\n",
    "        x_emb_t = model.embedding(x_t).unsqueeze(1)\n",
    "        print(x_emb_t.shape)\n",
    "        rnn_out_t, h_t = model.rnn(x_emb_t, h_t)\n",
    "        print(rnn_out_t.shape, h_t.shape)\n",
    "        y_pred = model.fc1(rnn_out_t)\n",
    "        print(y_pred.shape)\n",
    "        y_pred_proba = F.softmax(y_pred, dim=2, dtype=torch.int64).squeeze(1)\n",
    "        print(y_pred_proba.shape)\n",
    "        probs = y_pred_proba[range(source_batch.shape[0]), target_batch[:, 0]].unsqueeze(1)\n",
    "        print(target_batch.shape)\n",
    "        indices.append(probs)\n",
    "        print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 56]), torch.Size([2, 12]))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba.shape, target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.zeros_like(target_batch)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0364],\n",
       "        [0.0847]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba[range(len(source_batch)), target_batch[:, 0]].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[2, 1]}, size=[2]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-238-a73e66d229da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[2, 1]}, size=[2]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (2)"
     ]
    }
   ],
   "source": [
    "probs[:, 0] = y_pred_proba[range(len(source_batch)), target_batch[:, 0]].unsqueeze(1)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "index 29 is out of bounds for dim with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-99c9ad36d476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: index 29 is out of bounds for dim with size 1"
     ]
    }
   ],
   "source": [
    "y_pred_proba[range(len(source_batch)), target_batch[:, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 56])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[29,  5,  6, 21, 17, 11, 12,  9, 10, 11, 12,  3]],\n",
       "\n",
       "        [[18,  5,  9, 15,  6, 13,  8, 11, 17, 21,  3,  0]]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_batch.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.6059e-02, 7.0550e-02, 3.3150e-02, 5.1875e-07, 1.5935e-02,\n",
       "          2.4803e-02, 3.3445e-04, 8.4979e-02, 3.4252e-02, 2.4803e-02,\n",
       "          3.3445e-04, 4.1297e-04]],\n",
       "\n",
       "        [[8.5163e-02, 7.0550e-02, 8.4979e-02, 8.2856e-03, 3.3150e-02,\n",
       "          3.5834e-02, 3.3697e-02, 2.4803e-02, 1.5935e-02, 5.1875e-07,\n",
       "          4.1297e-04, 6.4077e-05]]], grad_fn=<GatherBackward>)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = range(len(source_batch))\n",
    "y_pred_proba.gather(dim=2, index=target_batch.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
