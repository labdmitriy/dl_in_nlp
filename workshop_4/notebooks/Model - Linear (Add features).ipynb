{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, StandardScaler, KBinsDiscretizer, QuantileTransformer, RobustScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198c6765e1544629bc01b8742251310d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 50 # default - 50\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "RANDOM_SEED = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train.csv')\n",
    "valid_df = pd.read_csv(DATA_PATH/'valid.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH/'X_train_ftfy_spacy.pkl', 'rb') as  f:\n",
    "    X_train_clean = pickle.load(f)\n",
    "\n",
    "train_df['title'] = X_train_clean['clean_title']\n",
    "train_df['text'] = X_train_clean['clean_text']\n",
    "\n",
    "with open(DATA_PATH/'X_valid_ftfy_spacy.pkl', 'rb') as  f:\n",
    "    X_valid_clean = pickle.load(f)\n",
    "\n",
    "valid_df['title'] = X_valid_clean['clean_title']\n",
    "valid_df['text'] = X_valid_clean['clean_text']\n",
    "\n",
    "with open(DATA_PATH/'X_test_ftfy_spacy.pkl', 'rb') as  f:\n",
    "    X_test_clean = pickle.load(f)\n",
    "\n",
    "test_df['title'] = X_test_clean['clean_title']\n",
    "test_df['text'] = X_test_clean['clean_text']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['title_length'] = train_df['title'].str.len().fillna(0)\n",
    "valid_df['title_length'] = valid_df['title'].str.len().fillna(0)\n",
    "test_df['title_length'] = test_df['title'].str.len().fillna(0)\n",
    "\n",
    "train_df['text_length'] = train_df['text'].str.len().fillna(0)\n",
    "valid_df['text_length'] = valid_df['text'].str.len().fillna(0)\n",
    "test_df['text_length'] = test_df['text'].str.len().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_title_na'] = train_df['title'].isnull().astype(np.int8)\n",
    "valid_df['is_title_na'] = valid_df['title'].isnull().astype(np.int8)\n",
    "test_df['is_title_na'] = test_df['title'].isnull().astype(np.int8)\n",
    "\n",
    "train_df['is_text_na'] = train_df['text'].isnull().astype(np.int8)\n",
    "valid_df['is_text_na'] = valid_df['text'].isnull().astype(np.int8)\n",
    "test_df['is_text_na'] = test_df['text'].isnull().astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_cols = ['title_length', 'text_length']\n",
    "na_cols = ['is_title_na', 'is_text_na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24871 entries, 0 to 24870\n",
      "Data columns (total 7 columns):\n",
      "label           24871 non-null object\n",
      "title           24871 non-null object\n",
      "text            24871 non-null object\n",
      "title_length    24871 non-null int64\n",
      "text_length     24871 non-null int64\n",
      "is_title_na     24871 non-null int8\n",
      "is_text_na      24871 non-null int8\n",
      "dtypes: int64(2), int8(2), object(3)\n",
      "memory usage: 1020.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.fillna('')\n",
    "X_valid = valid_df.fillna('')\n",
    "X_test = test_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X_train['class'] = le.fit_transform(X_train['label'])\n",
    "X_valid['class'] = le.transform(X_valid['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['clickbait', 'news', 'other'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d762e356a1ab4cfaac4c701ffe24caa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24871), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34055d3c2f4747948b3f69a8ffda214d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24871), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0    PROPN CCONJ PROPN PROPN PUNCT PROPN PROPN PART...\n",
       " 1    NOUN PART VERB DET PROPN NOUN ADP PROPN PROPN ...\n",
       " 2    DET PROPN PROPN ADP DET PROPN PUNCT VERB ADP P...\n",
       " 3    PROPN PART PROPN VERB PROPN PROPN ADP PROPN PR...\n",
       " 4    NOUN VERB PRON VERB NOUN NOUN PART NOUN ADP DE...\n",
       " Name: title, dtype: object,\n",
       " 0    NOUN ADV VERB PUNCT PROPN VERB VERB ADJ ADJ CC...\n",
       " 1    PROPN NUM ADJ PROPN PROPN PROPN PROPN VERB PRO...\n",
       " 2    NOUN VERB ADP DET NOUN ADP NOUN CCONJ NOUN ADP...\n",
       " 3    DET NOUN ADP NOUN VERB ADP PROPN PROPN PUNCT D...\n",
       " 4    DET ADJ NOUN NOUN VERB VERB ADP NOUN ADP PRON ...\n",
       " Name: text, dtype: object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pos_title = X_train['title'].str.findall(r'_([A-Z]+)').progress_apply(lambda x: ' '.join(x))\n",
    "X_train_pos_text = X_train['text'].str.findall(r'_([A-Z]+)').progress_apply(lambda x: ' '.join(x))\n",
    "X_train_pos_title.head(), X_train_pos_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5715ccfa774bd2a7d60239202f6ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82f075900cc446c90a3177ec06399d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=3552), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0    PROPN VERB PRON VERB VERB NOUN PART ADJ ADP NO...\n",
       " 1    PROPN PROPN PART NOUN VERB ADJ ADJ NOUN ADP PROPN\n",
       " 2    PROPN PROPN VERB SYM NUM NUM ADP PROPN PROPN P...\n",
       " 3    NOUN VERB ADJ ADP DET PROPN PROPN PROPN PROPN ...\n",
       " 4    PROPN PROPN CCONJ PROPN PROPN PROPN PROPN PART...\n",
       " Name: title, dtype: object,\n",
       " 0    PROPN PROPN PUNCT PROPN PROPN NUM PUNCT NUM NU...\n",
       " 1    PROPN VERB VERB VERB DET NOUN ADP PROPN ADP PR...\n",
       " 2    PROPN PUNCT DET PROPN NOUN VERB PROPN PRON VER...\n",
       " 3    DET ADJ NOUN NOUN VERB NOUN NOUN NOUN VERB VER...\n",
       " 4    DET NOUN ADP PROPN PROPN VERB ADJ PROPN NOUN P...\n",
       " Name: text, dtype: object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_pos_title = X_valid['title'].str.findall(r'_([A-Z]+)').progress_apply(lambda x: ' '.join(x))\n",
    "X_valid_pos_text = X_valid['text'].str.findall(r'_([A-Z]+)').progress_apply(lambda x: ' '.join(x))\n",
    "X_valid_pos_title.head(), X_valid_pos_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c748baacf4e0499291b79be0252d77ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5647), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d585449d164545098f04d896db7553fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5647), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0    PROPN PROPN PROPN PROPN VERB ADV DET ADJ ADJ N...\n",
       " 1    VERB PROPN PROPN PROPN DET PROPN ADP DET PROPN...\n",
       " 2    ADP DET NOUN PART NOUN NOUN PUNCT VERB ADP ADP...\n",
       " 3    NUM PROPN PART VERB ADJ NOUN PART VERB PART AD...\n",
       " 4    PROPN VERB VERB PRON VERB VERB ADP PROPN VERB ...\n",
       " Name: title, dtype: object,\n",
       " 0    ADJ VERB PROPN PROPN ADP PROPN SPACE PROPN PRO...\n",
       " 1    ADJ PROPN PROPN VERB PART VERB ADV DET NOUN PU...\n",
       " 2    PROPN VERB DET NOUN ADP ADJ PROPN ADP DET ADJ ...\n",
       " 3    NOUN VERB ADP NOUN VERB DET NOUN ADP DET ADJ N...\n",
       " 4    VERB DET ADP PROPN PROPN PROPN PROPN PROPN PRO...\n",
       " Name: text, dtype: object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_pos_title = X_test['title'].str.findall(r'_([A-Z]+)').progress_apply(lambda x: ' '.join(x))\n",
    "X_test_pos_text = X_test['text'].str.findall(r'_([A-Z]+)').progress_apply(lambda x: ' '.join(x))\n",
    "X_test_pos_title.head(), X_test_pos_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['title_pos'] = X_train_pos_title\n",
    "X_train['text_pos'] = X_train_pos_text\n",
    "\n",
    "X_valid['title_pos'] = X_valid_pos_title\n",
    "X_valid['text_pos'] = X_valid_pos_text\n",
    "\n",
    "X_test['title_pos'] = X_test_pos_title\n",
    "X_test['text_pos'] = X_test_pos_text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        y = y.values\n",
    "        \n",
    "        pos_count = X[y==1].sum(0) \n",
    "        neg_count = X[y==0].sum(0)\n",
    "        n = X.shape[1]\n",
    "        p = (pos_count + self.alpha) / (pos_count.sum() + self.alpha * n)\n",
    "        q = (neg_count + self.alpha) / (neg_count.sum() + self.alpha * n)\n",
    "        self.r_ = np.log(p / q)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.multiply(self.r_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfVectorizerPlus(TfidfVectorizer):\n",
    "    def __init__(self, fit_add=None, norm_type=None, pivot=5, slope=0.2, \n",
    "                       input='content', encoding='utf-8', decode_error='strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer='word', stop_words=None, \n",
    "                       token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), \n",
    "                       max_df=1.0, min_df=1, max_features=None, vocabulary=None, \n",
    "                       binary=False, dtype=np.float64, norm='l2', \n",
    "                       use_idf=True, smooth_idf=True, sublinear_tf=False):\n",
    "        super().__init__(input, encoding, decode_error,\n",
    "                         strip_accents, lowercase, preprocessor,\n",
    "                         tokenizer, analyzer, stop_words,\n",
    "                         token_pattern, ngram_range,\n",
    "                         max_df, min_df, max_features, vocabulary,\n",
    "                         binary, dtype, norm,\n",
    "                         use_idf, smooth_idf, sublinear_tf)\n",
    "        \n",
    "        self.fit_add = fit_add\n",
    "        self.norm_type = norm_type\n",
    "        self.pivot = pivot\n",
    "        self.slope = slope\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self.fit_add is not None:\n",
    "            X_new = pd.concat([X, self.fit_add])\n",
    "        else:\n",
    "            X_new = X\n",
    "        \n",
    "        super().fit(X_new, y)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        res = super().transform(X)\n",
    "            \n",
    "        if self.norm_type == 'pivot_cosine':\n",
    "            norm_factor = (1 - self.slope) * self.pivot + self.slope * sparse.linalg.norm(res, axis=1).reshape(-1, 1)\n",
    "            res = sparse.csr_matrix(res.multiply(1 / norm_factor))\n",
    "        elif self.norm_type == 'pivot_unique':\n",
    "            unique_terms_num = (res > 0).sum(axis=1)\n",
    "            norm_factor = (1 - self.slope) * self.pivot + self.slope * unique_terms_num\n",
    "            res = sparse.csr_matrix(res.multiply(1 / norm_factor))\n",
    "        elif self.norm_type is not None:\n",
    "            raise ValueError('Incorrect normalization type')\n",
    "            \n",
    "        return res"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pattern = re.compile(r'(\\s)+')\n",
    "\n",
    "def tokenize(s):\n",
    "    return pattern.split(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "#         ('title_pos', Pipeline([\n",
    "#             ('extract', ColumnExtractor('title_pos')),\n",
    "#             ('vec', TfidfVectorizer())\n",
    "#         ])),\n",
    "        ('text_pos', Pipeline([\n",
    "            ('extract', ColumnExtractor('text_pos')),\n",
    "            ('vec', TfidfVectorizer())\n",
    "        ])),\n",
    "    ], \n",
    "#         transformer_weights={\n",
    "#             'comment_text': 0.9,\n",
    "#             'char_length': 0.1,\n",
    "#         }\n",
    "    )),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe.fit_transform(X_train, X_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "#     'features__title_pos__vec': [TfidfVectorizer()],\n",
    "#     'features__title_pos__vec__strip_accents': [None], #[None, 'unicode', 'ascii'],\n",
    "#     'features__title_pos_pos__vec__lowercase': [True], #[True, False],\n",
    "#     'features__title_pos__vec__analyzer': ['word'], #['word', 'char', 'char_wb'],\n",
    "#     'features__title_pos__vec__stop_words': [None], #[None, 'english'],\n",
    "#     'features__title_pos__vec__ngram_range': [(1, 6)],\n",
    "#     'features__title_pos__vec__max_df': [0.4],\n",
    "#     'features__title_pos__vec__min_df': [60],\n",
    "#     'features__title_pos__vec__max_features': [None], #[None, 50000, 100000],\n",
    "#     'features__title_pos__vec__binary': [False], #[True, False],\n",
    "#     'features__title_pos__vec__use_idf': [True], #[True, False],\n",
    "#     'features__title_pos__vec__smooth_idf': [True], #[True, False],\n",
    "#     'features__title_pos__vec__sublinear_tf': [True], #[True, False],\n",
    "    \n",
    "    'features__text_pos__vec': [TfidfVectorizer()],\n",
    "    'features__text_pos__vec__strip_accents': [None], #[None, 'unicode', 'ascii'],\n",
    "    'features__text_pos__vec__lowercase': [True], #[True, False],\n",
    "    'features__text_pos__vec__analyzer': ['word'], #['char', 'char_wb'],\n",
    "    'features__text_pos__vec__stop_words': [None], #[None, 'english'],\n",
    "    'features__text_pos__vec__ngram_range': [(1, 3)],\n",
    "    'features__text_pos__vec__max_df': [1.0],\n",
    "    'features__text_pos__vec__min_df': [10],\n",
    "    'features__text_pos__vec__max_features': [None], #[None, 50000, 100000],\n",
    "    'features__text_pos__vec__binary': [True, False],\n",
    "    'features__text_pos__vec__use_idf': [True, False],\n",
    "    'features__text_pos__vec__smooth_idf': [True, False],\n",
    "    'features__text_pos__vec__sublinear_tf': [True, False],\n",
    "    \n",
    "    'clf': [LogisticRegression()],\n",
    "    'clf__penalty': ['l2'], # ['l1', 'l2'], # ['l2'],\n",
    "    'clf__C': [100], #[0.01], # [2], \n",
    "    'clf__class_weight': ['balanced'], #['balanced']\n",
    "    'clf__random_state': [RANDOM_SEED],\n",
    "    'clf__solver':  ['lbfgs'], #['lbfgs']\n",
    "    'clf__max_iter': [200],\n",
    "    'clf__multi_class': ['ovr'],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  32 out of  32 | elapsed:  5.6min finished\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=2, random_state=17, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('text_pos', Pipeline(memory=None,\n",
       "     steps=[('extract', ColumnExtractor(columns='text_pos')), ('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8...penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'features__text_pos__vec': [TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "        ngram_range=(1, 3), norm='l2', preprocesso..._random_state': [17], 'clf__solver': ['lbfgs'], 'clf__max_iter': [200], 'clf__multi_class': ['ovr']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1_macro', verbose=2)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, scoring='f1_macro', \n",
    "                           cv=cv, n_jobs=-1, return_train_score=True,\n",
    "                           verbose=2, iid=True)\n",
    "\n",
    "grid_search.fit(X_train, X_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7440271841645821,\n",
       " {'clf': LogisticRegression(C=100, class_weight='balanced', dual=False,\n",
       "            fit_intercept=True, intercept_scaling=1, max_iter=200,\n",
       "            multi_class='ovr', n_jobs=None, penalty='l2', random_state=17,\n",
       "            solver='lbfgs', tol=0.0001, verbose=0, warm_start=False),\n",
       "  'clf__C': 100,\n",
       "  'clf__class_weight': 'balanced',\n",
       "  'clf__max_iter': 200,\n",
       "  'clf__multi_class': 'ovr',\n",
       "  'clf__penalty': 'l2',\n",
       "  'clf__random_state': 17,\n",
       "  'clf__solver': 'lbfgs',\n",
       "  'features__text_pos__vec': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=10,\n",
       "          ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words=None, strip_accents=None, sublinear_tf=True,\n",
       "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=False,\n",
       "          vocabulary=None),\n",
       "  'features__text_pos__vec__analyzer': 'word',\n",
       "  'features__text_pos__vec__binary': False,\n",
       "  'features__text_pos__vec__lowercase': True,\n",
       "  'features__text_pos__vec__max_df': 1.0,\n",
       "  'features__text_pos__vec__max_features': None,\n",
       "  'features__text_pos__vec__min_df': 10,\n",
       "  'features__text_pos__vec__ngram_range': (1, 3),\n",
       "  'features__text_pos__vec__smooth_idf': True,\n",
       "  'features__text_pos__vec__stop_words': None,\n",
       "  'features__text_pos__vec__strip_accents': None,\n",
       "  'features__text_pos__vec__sublinear_tf': True,\n",
       "  'features__text_pos__vec__use_idf': False})"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>28.469</td>\n",
       "      <td>33.4141</td>\n",
       "      <td>34.0399</td>\n",
       "      <td>34.3871</td>\n",
       "      <td>34.3179</td>\n",
       "      <td>34.9398</td>\n",
       "      <td>35.215</td>\n",
       "      <td>34.4091</td>\n",
       "      <td>34.0196</td>\n",
       "      <td>34.1863</td>\n",
       "      <td>34.807</td>\n",
       "      <td>34.9496</td>\n",
       "      <td>33.8157</td>\n",
       "      <td>34.0348</td>\n",
       "      <td>35.8806</td>\n",
       "      <td>34.2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.731908</td>\n",
       "      <td>0.665383</td>\n",
       "      <td>0.738125</td>\n",
       "      <td>0.374219</td>\n",
       "      <td>0.497879</td>\n",
       "      <td>0.919513</td>\n",
       "      <td>0.310313</td>\n",
       "      <td>0.757699</td>\n",
       "      <td>0.360251</td>\n",
       "      <td>0.242812</td>\n",
       "      <td>0.811014</td>\n",
       "      <td>0.232687</td>\n",
       "      <td>0.912039</td>\n",
       "      <td>0.412863</td>\n",
       "      <td>0.287447</td>\n",
       "      <td>0.0374224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>24.0312</td>\n",
       "      <td>25.6666</td>\n",
       "      <td>25.0534</td>\n",
       "      <td>24.3531</td>\n",
       "      <td>23.8818</td>\n",
       "      <td>24.3719</td>\n",
       "      <td>25.4194</td>\n",
       "      <td>24.4535</td>\n",
       "      <td>23.89</td>\n",
       "      <td>23.9885</td>\n",
       "      <td>24.9325</td>\n",
       "      <td>25.2435</td>\n",
       "      <td>23.7658</td>\n",
       "      <td>24.1269</td>\n",
       "      <td>25.949</td>\n",
       "      <td>23.9928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.579283</td>\n",
       "      <td>0.446885</td>\n",
       "      <td>0.720688</td>\n",
       "      <td>1.48077</td>\n",
       "      <td>0.810509</td>\n",
       "      <td>0.910487</td>\n",
       "      <td>0.151614</td>\n",
       "      <td>0.555195</td>\n",
       "      <td>0.566707</td>\n",
       "      <td>0.539792</td>\n",
       "      <td>0.405259</td>\n",
       "      <td>0.522554</td>\n",
       "      <td>0.181392</td>\n",
       "      <td>0.459244</td>\n",
       "      <td>0.175753</td>\n",
       "      <td>0.369038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf</th>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "      <td>LogisticRegression(C=100, class_weight='balanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__C</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__class_weight</th>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__max_iter</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__multi_class</th>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "      <td>ovr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__random_state</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__solver</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>lbfgs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec</th>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__analyzer</th>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__binary</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__lowercase</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__max_df</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__max_features</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__min_df</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__ngram_range</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>(1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__smooth_idf</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__stop_words</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__strip_accents</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__sublinear_tf</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text_pos__vec__use_idf</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "      <td>{'clf': LogisticRegression(C=100, class_weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.71522</td>\n",
       "      <td>0.719685</td>\n",
       "      <td>0.71522</td>\n",
       "      <td>0.719685</td>\n",
       "      <td>0.715555</td>\n",
       "      <td>0.719685</td>\n",
       "      <td>0.715555</td>\n",
       "      <td>0.719685</td>\n",
       "      <td>0.729737</td>\n",
       "      <td>0.741236</td>\n",
       "      <td>0.738389</td>\n",
       "      <td>0.741357</td>\n",
       "      <td>0.729567</td>\n",
       "      <td>0.741236</td>\n",
       "      <td>0.737111</td>\n",
       "      <td>0.741357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.722666</td>\n",
       "      <td>0.730926</td>\n",
       "      <td>0.722666</td>\n",
       "      <td>0.730926</td>\n",
       "      <td>0.722528</td>\n",
       "      <td>0.730926</td>\n",
       "      <td>0.722528</td>\n",
       "      <td>0.730926</td>\n",
       "      <td>0.731837</td>\n",
       "      <td>0.746818</td>\n",
       "      <td>0.735432</td>\n",
       "      <td>0.742741</td>\n",
       "      <td>0.731668</td>\n",
       "      <td>0.746818</td>\n",
       "      <td>0.736589</td>\n",
       "      <td>0.742741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.718943</td>\n",
       "      <td>0.725305</td>\n",
       "      <td>0.718943</td>\n",
       "      <td>0.725305</td>\n",
       "      <td>0.719041</td>\n",
       "      <td>0.725305</td>\n",
       "      <td>0.719041</td>\n",
       "      <td>0.725305</td>\n",
       "      <td>0.730787</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.73691</td>\n",
       "      <td>0.742049</td>\n",
       "      <td>0.730617</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.73685</td>\n",
       "      <td>0.742049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00372301</td>\n",
       "      <td>0.00562005</td>\n",
       "      <td>0.00372301</td>\n",
       "      <td>0.00562005</td>\n",
       "      <td>0.00348647</td>\n",
       "      <td>0.00562005</td>\n",
       "      <td>0.00348647</td>\n",
       "      <td>0.00562005</td>\n",
       "      <td>0.0010497</td>\n",
       "      <td>0.00279117</td>\n",
       "      <td>0.00147878</td>\n",
       "      <td>0.000691914</td>\n",
       "      <td>0.00105027</td>\n",
       "      <td>0.00279117</td>\n",
       "      <td>0.000260902</td>\n",
       "      <td>0.000691914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.874688</td>\n",
       "      <td>0.857704</td>\n",
       "      <td>0.874688</td>\n",
       "      <td>0.857704</td>\n",
       "      <td>0.874461</td>\n",
       "      <td>0.857704</td>\n",
       "      <td>0.874461</td>\n",
       "      <td>0.857704</td>\n",
       "      <td>0.874465</td>\n",
       "      <td>0.844897</td>\n",
       "      <td>0.843731</td>\n",
       "      <td>0.79789</td>\n",
       "      <td>0.876094</td>\n",
       "      <td>0.844897</td>\n",
       "      <td>0.843419</td>\n",
       "      <td>0.79789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.876056</td>\n",
       "      <td>0.856596</td>\n",
       "      <td>0.876056</td>\n",
       "      <td>0.856596</td>\n",
       "      <td>0.877637</td>\n",
       "      <td>0.856596</td>\n",
       "      <td>0.877637</td>\n",
       "      <td>0.856596</td>\n",
       "      <td>0.870244</td>\n",
       "      <td>0.84226</td>\n",
       "      <td>0.832128</td>\n",
       "      <td>0.790116</td>\n",
       "      <td>0.870945</td>\n",
       "      <td>0.84226</td>\n",
       "      <td>0.83355</td>\n",
       "      <td>0.790116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.875372</td>\n",
       "      <td>0.85715</td>\n",
       "      <td>0.875372</td>\n",
       "      <td>0.85715</td>\n",
       "      <td>0.876049</td>\n",
       "      <td>0.85715</td>\n",
       "      <td>0.876049</td>\n",
       "      <td>0.85715</td>\n",
       "      <td>0.872355</td>\n",
       "      <td>0.843578</td>\n",
       "      <td>0.83793</td>\n",
       "      <td>0.794003</td>\n",
       "      <td>0.873519</td>\n",
       "      <td>0.843578</td>\n",
       "      <td>0.838485</td>\n",
       "      <td>0.794003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.000684135</td>\n",
       "      <td>0.000554346</td>\n",
       "      <td>0.000684135</td>\n",
       "      <td>0.000554346</td>\n",
       "      <td>0.00158821</td>\n",
       "      <td>0.000554346</td>\n",
       "      <td>0.00158821</td>\n",
       "      <td>0.000554346</td>\n",
       "      <td>0.00211067</td>\n",
       "      <td>0.0013186</td>\n",
       "      <td>0.00580111</td>\n",
       "      <td>0.00388677</td>\n",
       "      <td>0.00257446</td>\n",
       "      <td>0.0013186</td>\n",
       "      <td>0.00493445</td>\n",
       "      <td>0.00388677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             0   \\\n",
       "mean_fit_time                                                                            28.469   \n",
       "std_fit_time                                                                           0.731908   \n",
       "mean_score_time                                                                         24.0312   \n",
       "std_score_time                                                                         0.579283   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                      True   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                  True   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                                True   \n",
       "param_features__text_pos__vec__use_idf                                                     True   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                       0.71522   \n",
       "split1_test_score                                                                      0.722666   \n",
       "mean_test_score                                                                        0.718943   \n",
       "std_test_score                                                                       0.00372301   \n",
       "rank_test_score                                                                              15   \n",
       "split0_train_score                                                                     0.874688   \n",
       "split1_train_score                                                                     0.876056   \n",
       "mean_train_score                                                                       0.875372   \n",
       "std_train_score                                                                     0.000684135   \n",
       "\n",
       "                                                                                             1   \\\n",
       "mean_fit_time                                                                           33.4141   \n",
       "std_fit_time                                                                           0.665383   \n",
       "mean_score_time                                                                         25.6666   \n",
       "std_score_time                                                                         0.446885   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                      True   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                  True   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                                True   \n",
       "param_features__text_pos__vec__use_idf                                                    False   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.719685   \n",
       "split1_test_score                                                                      0.730926   \n",
       "mean_test_score                                                                        0.725305   \n",
       "std_test_score                                                                       0.00562005   \n",
       "rank_test_score                                                                               9   \n",
       "split0_train_score                                                                     0.857704   \n",
       "split1_train_score                                                                     0.856596   \n",
       "mean_train_score                                                                        0.85715   \n",
       "std_train_score                                                                     0.000554346   \n",
       "\n",
       "                                                                                             2   \\\n",
       "mean_fit_time                                                                           34.0399   \n",
       "std_fit_time                                                                           0.738125   \n",
       "mean_score_time                                                                         25.0534   \n",
       "std_score_time                                                                         0.720688   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                      True   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                  True   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                               False   \n",
       "param_features__text_pos__vec__use_idf                                                     True   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                       0.71522   \n",
       "split1_test_score                                                                      0.722666   \n",
       "mean_test_score                                                                        0.718943   \n",
       "std_test_score                                                                       0.00372301   \n",
       "rank_test_score                                                                              15   \n",
       "split0_train_score                                                                     0.874688   \n",
       "split1_train_score                                                                     0.876056   \n",
       "mean_train_score                                                                       0.875372   \n",
       "std_train_score                                                                     0.000684135   \n",
       "\n",
       "                                                                                             3   \\\n",
       "mean_fit_time                                                                           34.3871   \n",
       "std_fit_time                                                                           0.374219   \n",
       "mean_score_time                                                                         24.3531   \n",
       "std_score_time                                                                          1.48077   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                      True   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                  True   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                               False   \n",
       "param_features__text_pos__vec__use_idf                                                    False   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.719685   \n",
       "split1_test_score                                                                      0.730926   \n",
       "mean_test_score                                                                        0.725305   \n",
       "std_test_score                                                                       0.00562005   \n",
       "rank_test_score                                                                               9   \n",
       "split0_train_score                                                                     0.857704   \n",
       "split1_train_score                                                                     0.856596   \n",
       "mean_train_score                                                                        0.85715   \n",
       "std_train_score                                                                     0.000554346   \n",
       "\n",
       "                                                                                             4   \\\n",
       "mean_fit_time                                                                           34.3179   \n",
       "std_fit_time                                                                           0.497879   \n",
       "mean_score_time                                                                         23.8818   \n",
       "std_score_time                                                                         0.810509   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                      True   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                 False   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                                True   \n",
       "param_features__text_pos__vec__use_idf                                                     True   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.715555   \n",
       "split1_test_score                                                                      0.722528   \n",
       "mean_test_score                                                                        0.719041   \n",
       "std_test_score                                                                       0.00348647   \n",
       "rank_test_score                                                                              13   \n",
       "split0_train_score                                                                     0.874461   \n",
       "split1_train_score                                                                     0.877637   \n",
       "mean_train_score                                                                       0.876049   \n",
       "std_train_score                                                                      0.00158821   \n",
       "\n",
       "                                                                                             5   \\\n",
       "mean_fit_time                                                                           34.9398   \n",
       "std_fit_time                                                                           0.919513   \n",
       "mean_score_time                                                                         24.3719   \n",
       "std_score_time                                                                         0.910487   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                      True   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                 False   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                                True   \n",
       "param_features__text_pos__vec__use_idf                                                    False   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.719685   \n",
       "split1_test_score                                                                      0.730926   \n",
       "mean_test_score                                                                        0.725305   \n",
       "std_test_score                                                                       0.00562005   \n",
       "rank_test_score                                                                               9   \n",
       "split0_train_score                                                                     0.857704   \n",
       "split1_train_score                                                                     0.856596   \n",
       "mean_train_score                                                                        0.85715   \n",
       "std_train_score                                                                     0.000554346   \n",
       "\n",
       "                                                                                             6   \\\n",
       "mean_fit_time                                                                            35.215   \n",
       "std_fit_time                                                                           0.310313   \n",
       "mean_score_time                                                                         25.4194   \n",
       "std_score_time                                                                         0.151614   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                      True   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                 False   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                               False   \n",
       "param_features__text_pos__vec__use_idf                                                     True   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.715555   \n",
       "split1_test_score                                                                      0.722528   \n",
       "mean_test_score                                                                        0.719041   \n",
       "std_test_score                                                                       0.00348647   \n",
       "rank_test_score                                                                              13   \n",
       "split0_train_score                                                                     0.874461   \n",
       "split1_train_score                                                                     0.877637   \n",
       "mean_train_score                                                                       0.876049   \n",
       "std_train_score                                                                      0.00158821   \n",
       "\n",
       "                                                                                             7   \\\n",
       "mean_fit_time                                                                           34.4091   \n",
       "std_fit_time                                                                           0.757699   \n",
       "mean_score_time                                                                         24.4535   \n",
       "std_score_time                                                                         0.555195   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                      True   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                 False   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                               False   \n",
       "param_features__text_pos__vec__use_idf                                                    False   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.719685   \n",
       "split1_test_score                                                                      0.730926   \n",
       "mean_test_score                                                                        0.725305   \n",
       "std_test_score                                                                       0.00562005   \n",
       "rank_test_score                                                                               9   \n",
       "split0_train_score                                                                     0.857704   \n",
       "split1_train_score                                                                     0.856596   \n",
       "mean_train_score                                                                        0.85715   \n",
       "std_train_score                                                                     0.000554346   \n",
       "\n",
       "                                                                                             8   \\\n",
       "mean_fit_time                                                                           34.0196   \n",
       "std_fit_time                                                                           0.360251   \n",
       "mean_score_time                                                                           23.89   \n",
       "std_score_time                                                                         0.566707   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                     False   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                  True   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                                True   \n",
       "param_features__text_pos__vec__use_idf                                                     True   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.729737   \n",
       "split1_test_score                                                                      0.731837   \n",
       "mean_test_score                                                                        0.730787   \n",
       "std_test_score                                                                        0.0010497   \n",
       "rank_test_score                                                                               7   \n",
       "split0_train_score                                                                     0.874465   \n",
       "split1_train_score                                                                     0.870244   \n",
       "mean_train_score                                                                       0.872355   \n",
       "std_train_score                                                                      0.00211067   \n",
       "\n",
       "                                                                                             9   \\\n",
       "mean_fit_time                                                                           34.1863   \n",
       "std_fit_time                                                                           0.242812   \n",
       "mean_score_time                                                                         23.9885   \n",
       "std_score_time                                                                         0.539792   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                     False   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                  True   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                                True   \n",
       "param_features__text_pos__vec__use_idf                                                    False   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.741236   \n",
       "split1_test_score                                                                      0.746818   \n",
       "mean_test_score                                                                        0.744027   \n",
       "std_test_score                                                                       0.00279117   \n",
       "rank_test_score                                                                               1   \n",
       "split0_train_score                                                                     0.844897   \n",
       "split1_train_score                                                                      0.84226   \n",
       "mean_train_score                                                                       0.843578   \n",
       "std_train_score                                                                       0.0013186   \n",
       "\n",
       "                                                                                             10  \\\n",
       "mean_fit_time                                                                            34.807   \n",
       "std_fit_time                                                                           0.811014   \n",
       "mean_score_time                                                                         24.9325   \n",
       "std_score_time                                                                         0.405259   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                     False   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                  True   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                               False   \n",
       "param_features__text_pos__vec__use_idf                                                     True   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.738389   \n",
       "split1_test_score                                                                      0.735432   \n",
       "mean_test_score                                                                         0.73691   \n",
       "std_test_score                                                                       0.00147878   \n",
       "rank_test_score                                                                               5   \n",
       "split0_train_score                                                                     0.843731   \n",
       "split1_train_score                                                                     0.832128   \n",
       "mean_train_score                                                                        0.83793   \n",
       "std_train_score                                                                      0.00580111   \n",
       "\n",
       "                                                                                             11  \\\n",
       "mean_fit_time                                                                           34.9496   \n",
       "std_fit_time                                                                           0.232687   \n",
       "mean_score_time                                                                         25.2435   \n",
       "std_score_time                                                                         0.522554   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                     False   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                  True   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                               False   \n",
       "param_features__text_pos__vec__use_idf                                                    False   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.741357   \n",
       "split1_test_score                                                                      0.742741   \n",
       "mean_test_score                                                                        0.742049   \n",
       "std_test_score                                                                      0.000691914   \n",
       "rank_test_score                                                                               3   \n",
       "split0_train_score                                                                      0.79789   \n",
       "split1_train_score                                                                     0.790116   \n",
       "mean_train_score                                                                       0.794003   \n",
       "std_train_score                                                                      0.00388677   \n",
       "\n",
       "                                                                                             12  \\\n",
       "mean_fit_time                                                                           33.8157   \n",
       "std_fit_time                                                                           0.912039   \n",
       "mean_score_time                                                                         23.7658   \n",
       "std_score_time                                                                         0.181392   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                     False   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                 False   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                                True   \n",
       "param_features__text_pos__vec__use_idf                                                     True   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.729567   \n",
       "split1_test_score                                                                      0.731668   \n",
       "mean_test_score                                                                        0.730617   \n",
       "std_test_score                                                                       0.00105027   \n",
       "rank_test_score                                                                               8   \n",
       "split0_train_score                                                                     0.876094   \n",
       "split1_train_score                                                                     0.870945   \n",
       "mean_train_score                                                                       0.873519   \n",
       "std_train_score                                                                      0.00257446   \n",
       "\n",
       "                                                                                             13  \\\n",
       "mean_fit_time                                                                           34.0348   \n",
       "std_fit_time                                                                           0.412863   \n",
       "mean_score_time                                                                         24.1269   \n",
       "std_score_time                                                                         0.459244   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                     False   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                 False   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                                True   \n",
       "param_features__text_pos__vec__use_idf                                                    False   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.741236   \n",
       "split1_test_score                                                                      0.746818   \n",
       "mean_test_score                                                                        0.744027   \n",
       "std_test_score                                                                       0.00279117   \n",
       "rank_test_score                                                                               1   \n",
       "split0_train_score                                                                     0.844897   \n",
       "split1_train_score                                                                      0.84226   \n",
       "mean_train_score                                                                       0.843578   \n",
       "std_train_score                                                                       0.0013186   \n",
       "\n",
       "                                                                                             14  \\\n",
       "mean_fit_time                                                                           35.8806   \n",
       "std_fit_time                                                                           0.287447   \n",
       "mean_score_time                                                                          25.949   \n",
       "std_score_time                                                                         0.175753   \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...   \n",
       "param_clf__C                                                                                100   \n",
       "param_clf__class_weight                                                                balanced   \n",
       "param_clf__max_iter                                                                         200   \n",
       "param_clf__multi_class                                                                      ovr   \n",
       "param_clf__penalty                                                                           l2   \n",
       "param_clf__random_state                                                                      17   \n",
       "param_clf__solver                                                                         lbfgs   \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "param_features__text_pos__vec__analyzer                                                    word   \n",
       "param_features__text_pos__vec__binary                                                     False   \n",
       "param_features__text_pos__vec__lowercase                                                   True   \n",
       "param_features__text_pos__vec__max_df                                                         1   \n",
       "param_features__text_pos__vec__max_features                                                None   \n",
       "param_features__text_pos__vec__min_df                                                        10   \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)   \n",
       "param_features__text_pos__vec__smooth_idf                                                 False   \n",
       "param_features__text_pos__vec__stop_words                                                  None   \n",
       "param_features__text_pos__vec__strip_accents                                               None   \n",
       "param_features__text_pos__vec__sublinear_tf                                               False   \n",
       "param_features__text_pos__vec__use_idf                                                     True   \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...   \n",
       "split0_test_score                                                                      0.737111   \n",
       "split1_test_score                                                                      0.736589   \n",
       "mean_test_score                                                                         0.73685   \n",
       "std_test_score                                                                      0.000260902   \n",
       "rank_test_score                                                                               6   \n",
       "split0_train_score                                                                     0.843419   \n",
       "split1_train_score                                                                      0.83355   \n",
       "mean_train_score                                                                       0.838485   \n",
       "std_train_score                                                                      0.00493445   \n",
       "\n",
       "                                                                                             15  \n",
       "mean_fit_time                                                                           34.2509  \n",
       "std_fit_time                                                                          0.0374224  \n",
       "mean_score_time                                                                         23.9928  \n",
       "std_score_time                                                                         0.369038  \n",
       "param_clf                                     LogisticRegression(C=100, class_weight='balanc...  \n",
       "param_clf__C                                                                                100  \n",
       "param_clf__class_weight                                                                balanced  \n",
       "param_clf__max_iter                                                                         200  \n",
       "param_clf__multi_class                                                                      ovr  \n",
       "param_clf__penalty                                                                           l2  \n",
       "param_clf__random_state                                                                      17  \n",
       "param_clf__solver                                                                         lbfgs  \n",
       "param_features__text_pos__vec                 TfidfVectorizer(analyzer='word', binary=False,...  \n",
       "param_features__text_pos__vec__analyzer                                                    word  \n",
       "param_features__text_pos__vec__binary                                                     False  \n",
       "param_features__text_pos__vec__lowercase                                                   True  \n",
       "param_features__text_pos__vec__max_df                                                         1  \n",
       "param_features__text_pos__vec__max_features                                                None  \n",
       "param_features__text_pos__vec__min_df                                                        10  \n",
       "param_features__text_pos__vec__ngram_range                                               (1, 3)  \n",
       "param_features__text_pos__vec__smooth_idf                                                 False  \n",
       "param_features__text_pos__vec__stop_words                                                  None  \n",
       "param_features__text_pos__vec__strip_accents                                               None  \n",
       "param_features__text_pos__vec__sublinear_tf                                               False  \n",
       "param_features__text_pos__vec__use_idf                                                    False  \n",
       "params                                        {'clf': LogisticRegression(C=100, class_weight...  \n",
       "split0_test_score                                                                      0.741357  \n",
       "split1_test_score                                                                      0.742741  \n",
       "mean_test_score                                                                        0.742049  \n",
       "std_test_score                                                                      0.000691914  \n",
       "rank_test_score                                                                               3  \n",
       "split0_train_score                                                                      0.79789  \n",
       "split1_train_score                                                                     0.790116  \n",
       "mean_train_score                                                                       0.794003  \n",
       "std_train_score                                                                      0.00388677  "
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df = pd.DataFrame(grid_search.cv_results_).T\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2730\n"
     ]
    }
   ],
   "source": [
    "print(len(grid_search.best_estimator_.get_params()['features__text_pos__vec'].vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 1, 1])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = grid_search.predict_proba(X_valid).argmax(axis=1)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['news', 'news', 'news', ..., 'other', 'news', 'news'], dtype=object)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(y_val_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_margins = grid_search.decision_function(X_valid)\n",
    "y_val_pred = (y_margins - y_margins.min()) / (y_margins.max() - y_margins.min())\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18496622, 0.54757883, 0.26745495])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_val_pred) / len(y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, X_train['class'])\n",
    "y_val_pred = best_model.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, X_train['class'])\n",
    "y_margins = best_model.decision_function(X_valid)\n",
    "y_val_pred = (y_margins - y_margins.min()) / (y_margins.max() - y_margins.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7457499690738061"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(X_valid['class'], y_val_pred, average='macro')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perm = PermutationImportance(grid_search, random_state=RANDOM_SEED).fit(X_valid, X_valid['class'])\n",
    "\n",
    "eli5.show_weights(perm, feature_names = X_valid.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict & Submit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = pd.concat([train_df, valid_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-634-a4a3faf5011d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.fit(full_train_df, full_train_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-635-f30534ee1421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmission_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'sample_submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msubmission_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prediction'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msubmission_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "submission_df = pd.read_csv(DATA_PATH/'sample_submission.csv', index_col='id')\n",
    "submission_df['prediction'] = best_model.predict_proba(test_df)[:, 1]\n",
    "submission_df.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>target</th>\n",
       "      <th>target_class</th>\n",
       "      <th>target_pred</th>\n",
       "      <th>class_pred</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423701</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147193</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088030</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136164</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332197</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127364</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849122</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113174</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448612</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132020</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          male  female  homosexual_gay_or_lesbian  christian  jewish  muslim  \\\n",
       "423701   False   False                      False      False   False   False   \n",
       "1088030  False   False                      False      False   False   False   \n",
       "332197   False   False                      False      False   False   False   \n",
       "849122   False   False                      False      False   False   False   \n",
       "448612   False   False                      False      False   False   False   \n",
       "\n",
       "         black  white  psychiatric_or_mental_illness  target  target_class  \\\n",
       "423701   False  False                          False       0             0   \n",
       "1088030  False  False                          False       0             0   \n",
       "332197   False  False                          False       0             0   \n",
       "849122   False  False                          False       0             0   \n",
       "448612   False  False                          False       0             0   \n",
       "\n",
       "         target_pred  class_pred  is_correct  \n",
       "423701      0.147193           0        True  \n",
       "1088030     0.136164           0        True  \n",
       "332197      0.127364           0        True  \n",
       "849122      0.113174           0        True  \n",
       "448612      0.132020           0        True  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df['is_correct'] = (validate_df['target_class'] == validate_df['class_pred'])\n",
    "validate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_class</th>\n",
       "      <th>is_correct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>False</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3777</td>\n",
       "      <td>4754</td>\n",
       "      <td>783</td>\n",
       "      <td>3757</td>\n",
       "      <td>692</td>\n",
       "      <td>1572</td>\n",
       "      <td>1061</td>\n",
       "      <td>1864</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>False</th>\n",
       "      <td>637</td>\n",
       "      <td>726</td>\n",
       "      <td>331</td>\n",
       "      <td>346</td>\n",
       "      <td>112</td>\n",
       "      <td>459</td>\n",
       "      <td>426</td>\n",
       "      <td>712</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         male  female  homosexual_gay_or_lesbian  christian  \\\n",
       "target_class is_correct                                                       \n",
       "0            False          0       0                          0          0   \n",
       "             True        3777    4754                        783       3757   \n",
       "1            False        637     726                        331        346   \n",
       "             True           3       4                          1          0   \n",
       "\n",
       "                         jewish  muslim  black  white  \\\n",
       "target_class is_correct                                 \n",
       "0            False            0       0      0      0   \n",
       "             True           692    1572   1061   1864   \n",
       "1            False          112     459    426    712   \n",
       "             True             0       0      1      0   \n",
       "\n",
       "                         psychiatric_or_mental_illness  \n",
       "target_class is_correct                                 \n",
       "0            False                                   0  \n",
       "             True                                  357  \n",
       "1            False                                 112  \n",
       "             True                                    0  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_count_df = validate_df.groupby(['target_class', 'is_correct'])[identity_cols].sum().astype(np.int)\n",
    "errors_count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa893ae9518>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "validate_df['target_pred'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "      <th>homosexual_gay_or_lesbian</th>\n",
       "      <th>christian</th>\n",
       "      <th>jewish</th>\n",
       "      <th>muslim</th>\n",
       "      <th>black</th>\n",
       "      <th>white</th>\n",
       "      <th>psychiatric_or_mental_illness</th>\n",
       "      <th>target</th>\n",
       "      <th>target_class</th>\n",
       "      <th>target_pred</th>\n",
       "      <th>class_pred</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423701</th>\n",
       "      <td>For a historical perspective have a listen to ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.147193</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088030</th>\n",
       "      <td>\" And everyone knows what a thug Saddam Hussei...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.136164</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332197</th>\n",
       "      <td>Best qualified ? How so ? She is another exalt...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127364</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849122</th>\n",
       "      <td>Among its other transgressions , JPMorgan has ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.113174</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448612</th>\n",
       "      <td>It 's 1956 all over again . \\n\\n And if Soros ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132020</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment_text   male  female  \\\n",
       "423701   For a historical perspective have a listen to ...  False   False   \n",
       "1088030  \" And everyone knows what a thug Saddam Hussei...  False   False   \n",
       "332197   Best qualified ? How so ? She is another exalt...  False   False   \n",
       "849122   Among its other transgressions , JPMorgan has ...  False   False   \n",
       "448612   It 's 1956 all over again . \\n\\n And if Soros ...  False   False   \n",
       "\n",
       "         homosexual_gay_or_lesbian  christian  jewish  muslim  black  white  \\\n",
       "423701                       False      False   False   False  False  False   \n",
       "1088030                      False      False   False   False  False  False   \n",
       "332197                       False      False   False   False  False  False   \n",
       "849122                       False      False   False   False  False  False   \n",
       "448612                       False      False   False   False  False  False   \n",
       "\n",
       "         psychiatric_or_mental_illness  target  target_class  target_pred  \\\n",
       "423701                           False       0             0     0.147193   \n",
       "1088030                          False       0             0     0.136164   \n",
       "332197                           False       0             0     0.127364   \n",
       "849122                           False       0             0     0.113174   \n",
       "448612                           False       0             0     0.132020   \n",
       "\n",
       "         class_pred  is_correct  \n",
       "423701            0        True  \n",
       "1088030           0        True  \n",
       "332197            0        True  \n",
       "849122            0        True  \n",
       "448612            0        True  "
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_analysis_df = pd.merge(X_valid['comment_text'], validate_df, \n",
    "                             right_index=True, left_index=True)\n",
    "error_analysis_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_analysis_df['comment_length'] = error_analysis_df['comment_text'].str.len()\n",
    "error_analysis_df['identities_count'] = error_analysis_df[identity_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">comment_length</th>\n",
       "      <th colspan=\"4\" halign=\"left\">identities_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_class</th>\n",
       "      <th>class_pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1251</td>\n",
       "      <td>310.557304</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.112115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "      <td>145</td>\n",
       "      <td>89.500000</td>\n",
       "      <td>89.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1113</td>\n",
       "      <td>289.730002</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>699</td>\n",
       "      <td>88.549180</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        comment_length                           \\\n",
       "                                   min   max        mean median   \n",
       "target_class class_pred                                           \n",
       "0            0                       1  1251  310.557304  210.0   \n",
       "             1                      34   145   89.500000   89.5   \n",
       "1            0                       4  1113  289.730002  205.0   \n",
       "             1                       5   699   88.549180   49.0   \n",
       "\n",
       "                        identities_count                       \n",
       "                                     min max      mean median  \n",
       "target_class class_pred                                        \n",
       "0            0                         0   7  0.112115      0  \n",
       "             1                         0   0  0.000000      0  \n",
       "1            0                         0   6  0.272112      0  \n",
       "             1                         0   2  0.036885      0  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error_analysis_df.groupby(['target_class', 'class_pred'])['comment_length', 'identities_count']\n",
    "                  .agg(['min', 'max', 'mean', 'median']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_class</th>\n",
       "      <th>class_pred</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.112115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.272112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036885</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         min  max      mean  median\n",
       "target_class class_pred                            \n",
       "0            0             0    7  0.112115       0\n",
       "             1             0    0  0.000000       0\n",
       "1            0             0    6  0.272112       0\n",
       "             1             0    2  0.036885       0"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(error_analysis_df.groupby(['target_class', 'class_pred'])['identities_count']\n",
    "                  .agg(['min', 'max', 'mean', 'median']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
