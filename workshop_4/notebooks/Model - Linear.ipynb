{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 50 # default - 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('../data')\n",
    "RANDOM_SEED = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH/'train.csv')\n",
    "valid_df = pd.read_csv(DATA_PATH/'valid.csv')\n",
    "test_df = pd.read_csv(DATA_PATH/'test.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['title_length'] = train_df['title'].str.len().fillna(0)\n",
    "valid_df['title_length'] = valid_df['title'].str.len().fillna(0)\n",
    "test_df['title_length'] = test_df['title'].str.len().fillna(0)\n",
    "\n",
    "train_df['text_length'] = train_df['text'].str.len().fillna(0)\n",
    "valid_df['text_length'] = valid_df['text'].str.len().fillna(0)\n",
    "test_df['text_length'] = test_df['text'].str.len().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_title_na'] = train_df['title'].isnull().astype(np.int8)\n",
    "valid_df['is_title_na'] = valid_df['title'].isnull().astype(np.int8)\n",
    "test_df['is_title_na'] = test_df['title'].isnull().astype(np.int8)\n",
    "\n",
    "train_df['is_text_na'] = train_df['text'].isnull().astype(np.int8)\n",
    "valid_df['is_text_na'] = valid_df['text'].isnull().astype(np.int8)\n",
    "test_df['is_text_na'] = test_df['text'].isnull().astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_cols = ['title_length', 'text_length', 'is_title_na', 'is_text_na']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.fillna('')\n",
    "X_valid = valid_df.fillna('')\n",
    "X_test = test_df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X_train['class'] = le.fit_transform(X_train['label'])\n",
    "X_valid['class'] = le.transform(X_valid['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['clickbait', 'news', 'other'], dtype=object)"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[self.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        y = y.values\n",
    "        \n",
    "        pos_count = X[y==1].sum(0) \n",
    "        neg_count = X[y==0].sum(0)\n",
    "        n = X.shape[1]\n",
    "        p = (pos_count + self.alpha) / (pos_count.sum() + self.alpha * n)\n",
    "        q = (neg_count + self.alpha) / (neg_count.sum() + self.alpha * n)\n",
    "        self.r_ = np.log(p / q)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.multiply(self.r_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfidfVectorizerPlus(TfidfVectorizer):\n",
    "    def __init__(self, fit_add=None, norm_type=None, pivot=5, slope=0.2, \n",
    "                       input='content', encoding='utf-8', decode_error='strict', \n",
    "                       strip_accents=None, lowercase=True, preprocessor=None, \n",
    "                       tokenizer=None, analyzer='word', stop_words=None, \n",
    "                       token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', ngram_range=(1, 1), \n",
    "                       max_df=1.0, min_df=1, max_features=None, vocabulary=None, \n",
    "                       binary=False, dtype=np.float64, norm='l2', \n",
    "                       use_idf=True, smooth_idf=True, sublinear_tf=False):\n",
    "        super().__init__(input, encoding, decode_error,\n",
    "                         strip_accents, lowercase, preprocessor,\n",
    "                         tokenizer, analyzer, stop_words,\n",
    "                         token_pattern, ngram_range,\n",
    "                         max_df, min_df, max_features, vocabulary,\n",
    "                         binary, dtype, norm,\n",
    "                         use_idf, smooth_idf, sublinear_tf)\n",
    "        \n",
    "        self.fit_add = fit_add\n",
    "        self.norm_type = norm_type\n",
    "        self.pivot = pivot\n",
    "        self.slope = slope\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        if self.fit_add is not None:\n",
    "            X_new = pd.concat([X, self.fit_add])\n",
    "        else:\n",
    "            X_new = X\n",
    "        \n",
    "        super().fit(X_new, y)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        res = super().transform(X)\n",
    "            \n",
    "        if self.norm_type == 'pivot_cosine':\n",
    "            norm_factor = (1 - self.slope) * self.pivot + self.slope * sparse.linalg.norm(res, axis=1).reshape(-1, 1)\n",
    "            res = sparse.csr_matrix(res.multiply(1 / norm_factor))\n",
    "        elif self.norm_type == 'pivot_unique':\n",
    "            unique_terms_num = (res > 0).sum(axis=1)\n",
    "            norm_factor = (1 - self.slope) * self.pivot + self.slope * unique_terms_num\n",
    "            res = sparse.csr_matrix(res.multiply(1 / norm_factor))\n",
    "        elif self.norm_type is not None:\n",
    "            raise ValueError('Incorrect normalization type')\n",
    "            \n",
    "        return res"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pattern = re.compile(r'(\\s)+')\n",
    "\n",
    "def tokenize(s):\n",
    "    return pattern.split(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "#         ('title', Pipeline([\n",
    "#             ('extract', ColumnExtractor(columns='title')),\n",
    "#             ('vec', TfidfVectorizer()),\n",
    "# #             ('nb_features', NBTransformer())\n",
    "#         ])),\n",
    "        ('text', Pipeline([\n",
    "            ('extract', ColumnExtractor(columns='text')),\n",
    "            ('vec', TfidfVectorizer()),\n",
    "            ('nb_features', NBTransformer())\n",
    "        ])),       \n",
    "#         ('title_length', Pipeline([\n",
    "#             ('extract', ColumnExtractor(columns=['title_length']))\n",
    "#         ])),\n",
    "#         ('text_length', Pipeline([\n",
    "#             ('extract', ColumnExtractor(columns=['text_length']))\n",
    "#         ])),\n",
    "#         ('is_title_na', Pipeline([\n",
    "#             ('extract', ColumnExtractor(columns=['is_title_na']))\n",
    "#         ])),\n",
    "#         ('is_text_na', Pipeline([\n",
    "#             ('extract', ColumnExtractor(columns=['is_text_na']))\n",
    "#         ])),\n",
    "    ], \n",
    "#         transformer_weights={\n",
    "#             'comment_text': 0.9,\n",
    "#             'char_length': 0.1,\n",
    "#         }\n",
    "    )),\n",
    "    ('clf', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pipe.fit_transform(X_train, X_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "#               'features__title__vec': [TfidfVectorizer()],\n",
    "#               'features__title__vec__strip_accents': ['ascii'], #[None, 'unicode', 'ascii'],\n",
    "#               'features__title__vec__lowercase': [True], #[True, False],\n",
    "#               'features__title__vec__analyzer': ['word'], #['word', 'char', 'char_wb'],\n",
    "#               'features__title__vec__stop_words': [None], #[None, 'english'],\n",
    "#               'features__title__vec__token_pattern': [r'\\b\\w+\\b'], #[r'\\b\\w+\\b', r'(?u)\\b\\w\\w+\\b'],\n",
    "#               'features__title__vec__ngram_range': [(1, 3)], #[(1, 1), (1, 2), (1, 3)],\n",
    "#               'features__title__vec__max_df': [0.3], #[0.3, 0.4, 0.5],\n",
    "#               'features__title__vec__min_df': [1], #[1, 2, 3],\n",
    "#               'features__title__vec__max_features': [None], #[None, 100000, 200000, 300000],\n",
    "#               'features__title__vec__binary': [False],\n",
    "#               'features__title__vec__use_idf': [True], #[True, False],\n",
    "#               'features__title__vec__smooth_idf': [False], #[True, False],\n",
    "#               'features__title__vec__sublinear_tf': [False], #[True, False],\n",
    "                            \n",
    "              \n",
    "#               'features__text__vec': [TfidfVectorizer()],\n",
    "#               'features__text__vec__strip_accents': ['ascii'], #[None, 'unicode', 'ascii'],\n",
    "#               'features__text__vec__lowercase': [False], #[True, False],\n",
    "#               'features__text__vec__analyzer': ['word'], #['word', 'char', 'char_wb'],\n",
    "#               'features__text__vec__stop_words': [None], #[None, 'english'],\n",
    "#               'features__text__vec__token_pattern': [r'\\b\\w+\\b'], #[r'\\b\\w+\\b', r'(?u)\\b\\w\\w+\\b'],\n",
    "#               'features__text__vec__ngram_range': [(1, 2)], #[(1, 1), (1, 2), (1, 3)],\n",
    "#               'features__text__vec__max_df': [1.0],\n",
    "#               'features__text__vec__min_df': [1],\n",
    "#               'features__text__vec__max_features': [150000], #[50000, 100000, 150000],\n",
    "#               'features__text__vec__binary': [False], #[True, False],\n",
    "#               'features__text__vec__use_idf': [True], #[True, False],\n",
    "#               'features__text__vec__smooth_idf': [False], #[True, False],\n",
    "#               'features__text__vec__sublinear_tf': [True], #[True, False],\n",
    "              \n",
    "              \n",
    "#               'clf': [LogisticRegression()],\n",
    "#               'clf__penalty': ['l2'], # ['l1', 'l2'], # ['l2'],\n",
    "#               'clf__C': [5], #np.logspace(-2, 2, 5), # [2], \n",
    "#               'clf__class_weight': ['balanced'], #[None, 'balanced'], #['balanced']\n",
    "#               'clf__random_state': [random_seed],\n",
    "#               'clf__solver':  ['lbfgs'], #['lbfgs']\n",
    "#               'clf__max_iter': [200],\n",
    "              \n",
    "              \n",
    "              \n",
    "#               'features__title__vec': [TfidfVectorizer()],\n",
    "#               'features__title__vec__strip_accents': [None], #[None, 'unicode', 'ascii'],\n",
    "#               'features__title__vec__lowercase': [True], #[True, False],\n",
    "#               'features__title__vec__analyzer': ['word'], #['word', 'char', 'char_wb'],\n",
    "#               'features__title__vec__stop_words': [None], #[None, 'english'],\n",
    "#               'features__title__vec__token_pattern': [r'\\b\\w+\\b'], #[r'\\b\\w+\\b', r'(?u)\\b\\w\\w+\\b'],\n",
    "#               'features__title__vec__ngram_range': [(1, 4)],\n",
    "#               'features__title__vec__max_df': [0.8],\n",
    "#               'features__title__vec__min_df': [1], #[1, 5, 10],\n",
    "#               'features__title__vec__max_features': [70000],\n",
    "#               'features__title__vec__binary': [True], #[True, False],\n",
    "#               'features__title__vec__use_idf': [True], #[True, False],\n",
    "#               'features__title__vec__smooth_idf': [True], #[True, False],\n",
    "#               'features__title__vec__sublinear_tf': [True], #[True, False],\n",
    "\n",
    "#               'clf': [LinearSVC()],\n",
    "#               'clf__penalty': ['l2'],\n",
    "#               'clf__loss': ['squared_hinge'], #['squared_hinge', 'hinge'],\n",
    "#               'clf__dual': [False], #[True, False],\n",
    "#               'clf__C': [0.4],\n",
    "#               'clf__class_weight': ['balanced'],\n",
    "#               'clf__random_state': [random_seed],\n",
    "              \n",
    "              'features__text__vec': [TfidfVectorizer()],\n",
    "              'features__text__vec__strip_accents': [None, 'unicode', 'ascii'],\n",
    "              'features__text__vec__lowercase': [True, False],\n",
    "              'features__text__vec__analyzer': ['word', 'char', 'char_wb'],\n",
    "              'features__text__vec__stop_words': [None, 'english'],\n",
    "#               'features__text__vec__token_pattern': [r'\\b\\w+\\b'], #[r'\\b\\w+\\b', r'(?u)\\b\\w\\w+\\b'],\n",
    "#               'features__text__vec__ngram_range': [(1, 2)], #[(1, 1), (1, 2), (1, 3)],\n",
    "#               'features__text__vec__max_df': [1.0],\n",
    "#               'features__text__vec__min_df': [1],\n",
    "#               'features__text__vec__max_features': [150000], #[50000, 100000, 150000],\n",
    "#               'features__text__vec__binary': [False], #[True, False],\n",
    "#               'features__text__vec__use_idf': [True], #[True, False],\n",
    "#               'features__text__vec__smooth_idf': [False], #[True, False],\n",
    "#               'features__text__vec__sublinear_tf': [True], #[True, False],\n",
    "              \n",
    "#               'features__text__nb_features__alpha': [0.2, 0.5, 0.8], #np.linspace(0.1, 1, 10),\n",
    "    \n",
    "              'clf': [LinearSVC()],\n",
    "              'clf__penalty': ['l2'],\n",
    "              'clf__loss': ['squared_hinge'], #['squared_hinge', 'hinge'],\n",
    "              'clf__dual': [False], #[True, False],\n",
    "              'clf__C': [0.3],\n",
    "              'clf__class_weight': ['balanced'], #[None, 'balanced'],\n",
    "              'clf__random_state': [random_seed],\n",
    "             \n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 36 candidates, totalling 72 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(pipe, param_grid, scoring='f1_macro', \n",
    "                           cv=cv, n_jobs=-1, return_train_score=True,\n",
    "                           verbose=2, iid=True)\n",
    "\n",
    "grid_search.fit(X_train, X_train['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_, grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>10.2232</td>\n",
       "      <td>10.6665</td>\n",
       "      <td>12.5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0.283026</td>\n",
       "      <td>0.0136195</td>\n",
       "      <td>0.33712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>7.66202</td>\n",
       "      <td>8.22604</td>\n",
       "      <td>7.59158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.838299</td>\n",
       "      <td>1.22304</td>\n",
       "      <td>0.473638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf</th>\n",
       "      <td>LinearSVC(C=0.3, class_weight='balanced', dual...</td>\n",
       "      <td>LinearSVC(C=0.3, class_weight='balanced', dual...</td>\n",
       "      <td>LinearSVC(C=0.3, class_weight='balanced', dual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__C</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__class_weight</th>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__dual</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__loss</th>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>squared_hinge</td>\n",
       "      <td>squared_hinge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__penalty</th>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_clf__random_state</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text__nb_features__alpha</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_features__text__vec</th>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'clf': LinearSVC(C=0.3, class_weight='balance...</td>\n",
       "      <td>{'clf': LinearSVC(C=0.3, class_weight='balance...</td>\n",
       "      <td>{'clf': LinearSVC(C=0.3, class_weight='balance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.737049</td>\n",
       "      <td>0.743208</td>\n",
       "      <td>0.746514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.733554</td>\n",
       "      <td>0.741658</td>\n",
       "      <td>0.747869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.735301</td>\n",
       "      <td>0.742433</td>\n",
       "      <td>0.747192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.00174742</td>\n",
       "      <td>0.000775047</td>\n",
       "      <td>0.000677473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.896896</td>\n",
       "      <td>0.872329</td>\n",
       "      <td>0.85627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.894991</td>\n",
       "      <td>0.875059</td>\n",
       "      <td>0.853919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.895943</td>\n",
       "      <td>0.873694</td>\n",
       "      <td>0.855094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00095219</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.00117575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                          0  \\\n",
       "mean_fit_time                                                                       10.2232   \n",
       "std_fit_time                                                                       0.283026   \n",
       "mean_score_time                                                                     7.66202   \n",
       "std_score_time                                                                     0.838299   \n",
       "param_clf                                 LinearSVC(C=0.3, class_weight='balanced', dual...   \n",
       "param_clf__C                                                                            0.3   \n",
       "param_clf__class_weight                                                            balanced   \n",
       "param_clf__dual                                                                       False   \n",
       "param_clf__loss                                                               squared_hinge   \n",
       "param_clf__penalty                                                                       l2   \n",
       "param_clf__random_state                                                                  17   \n",
       "param_features__text__nb_features__alpha                                                0.2   \n",
       "param_features__text__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "params                                    {'clf': LinearSVC(C=0.3, class_weight='balance...   \n",
       "split0_test_score                                                                  0.737049   \n",
       "split1_test_score                                                                  0.733554   \n",
       "mean_test_score                                                                    0.735301   \n",
       "std_test_score                                                                   0.00174742   \n",
       "rank_test_score                                                                           3   \n",
       "split0_train_score                                                                 0.896896   \n",
       "split1_train_score                                                                 0.894991   \n",
       "mean_train_score                                                                   0.895943   \n",
       "std_train_score                                                                  0.00095219   \n",
       "\n",
       "                                                                                          1  \\\n",
       "mean_fit_time                                                                       10.6665   \n",
       "std_fit_time                                                                      0.0136195   \n",
       "mean_score_time                                                                     8.22604   \n",
       "std_score_time                                                                      1.22304   \n",
       "param_clf                                 LinearSVC(C=0.3, class_weight='balanced', dual...   \n",
       "param_clf__C                                                                            0.3   \n",
       "param_clf__class_weight                                                            balanced   \n",
       "param_clf__dual                                                                       False   \n",
       "param_clf__loss                                                               squared_hinge   \n",
       "param_clf__penalty                                                                       l2   \n",
       "param_clf__random_state                                                                  17   \n",
       "param_features__text__nb_features__alpha                                                0.5   \n",
       "param_features__text__vec                 TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "params                                    {'clf': LinearSVC(C=0.3, class_weight='balance...   \n",
       "split0_test_score                                                                  0.743208   \n",
       "split1_test_score                                                                  0.741658   \n",
       "mean_test_score                                                                    0.742433   \n",
       "std_test_score                                                                  0.000775047   \n",
       "rank_test_score                                                                           2   \n",
       "split0_train_score                                                                 0.872329   \n",
       "split1_train_score                                                                 0.875059   \n",
       "mean_train_score                                                                   0.873694   \n",
       "std_train_score                                                                    0.001365   \n",
       "\n",
       "                                                                                          2  \n",
       "mean_fit_time                                                                       12.5214  \n",
       "std_fit_time                                                                        0.33712  \n",
       "mean_score_time                                                                     7.59158  \n",
       "std_score_time                                                                     0.473638  \n",
       "param_clf                                 LinearSVC(C=0.3, class_weight='balanced', dual...  \n",
       "param_clf__C                                                                            0.3  \n",
       "param_clf__class_weight                                                            balanced  \n",
       "param_clf__dual                                                                       False  \n",
       "param_clf__loss                                                               squared_hinge  \n",
       "param_clf__penalty                                                                       l2  \n",
       "param_clf__random_state                                                                  17  \n",
       "param_features__text__nb_features__alpha                                                0.8  \n",
       "param_features__text__vec                 TfidfVectorizer(analyzer='word', binary=False,...  \n",
       "params                                    {'clf': LinearSVC(C=0.3, class_weight='balance...  \n",
       "split0_test_score                                                                  0.746514  \n",
       "split1_test_score                                                                  0.747869  \n",
       "mean_test_score                                                                    0.747192  \n",
       "std_test_score                                                                  0.000677473  \n",
       "rank_test_score                                                                           1  \n",
       "split0_train_score                                                                  0.85627  \n",
       "split1_train_score                                                                 0.853919  \n",
       "mean_train_score                                                                   0.855094  \n",
       "std_train_score                                                                  0.00117575  "
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_df = pd.DataFrame(grid_search.cv_results_).T\n",
    "cv_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138288\n"
     ]
    }
   ],
   "source": [
    "print(len(grid_search.best_estimator_.get_params()['features__text__vec'].vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "y_val_pred = grid_search.predict_proba(X_valid).argmax(axis=1)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 2, 1, 1])"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_margins = grid_search.decision_function(X_valid)\n",
    "y_val_pred = (y_margins - y_margins.min()) / (y_margins.max() - y_margins.min())\n",
    "y_val_pred = y_val_pred.argmax(axis=1)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['news', 'news', 'news', ..., 'other', 'news', 'news'], dtype=object)"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.inverse_transform(y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12471847, 0.6089527 , 0.26632883])"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_val_pred) / len(y_val_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluation**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, X_train['class'])\n",
    "y_val_pred = best_model.predict_proba(X_valid)[:, 1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, X_train['class'])\n",
    "y_margins = best_model.decision_function(X_valid)\n",
    "y_val_pred = (y_margins - y_margins.min()) / (y_margins.max() - y_margins.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.767289826049255"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(X_valid['class'], y_val_pred, average='macro')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Importance**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "perm = PermutationImportance(grid_search, random_state=RANDOM_SEED).fit(X_valid, X_valid['class'])\n",
    "\n",
    "eli5.show_weights(perm, feature_names = X_valid.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predict & Submit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_df = pd.concat([X_train, X_valid], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('features', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('title', Pipeline(memory=None,\n",
       "     steps=[('extract', ColumnExtractor(columns='title')), ('vec', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', inp... penalty='l2', random_state=17,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(full_train_df, full_train_df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>title_length</th>\n",
       "      <th>text_length</th>\n",
       "      <th>is_title_na</th>\n",
       "      <th>is_text_na</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Amazon CEO Jeff Bezos is now the second riches...</td>\n",
       "      <td>More Try Yahoo Finance on Firefox » Amazon CEO...</td>\n",
       "      <td>64</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Does Laura Dern Handle a Lightsaber in the New...</td>\n",
       "      <td>More Laura Dern seems to be everywhere these d...</td>\n",
       "      <td>67</td>\n",
       "      <td>2296.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>In this photographer’s home town, stepping out...</td>\n",
       "      <td>Kirkuk is a city of Northern Iraq in the Kurdi...</td>\n",
       "      <td>69</td>\n",
       "      <td>4732.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8 Ways To Get Your Spouse To Open Up More, Acc...</td>\n",
       "      <td>Experts say that communication is the cornerst...</td>\n",
       "      <td>66</td>\n",
       "      <td>4485.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>US says claim it supported IS in Syria is 'lud...</td>\n",
       "      <td>Share this with Email Facebook Messenger Messe...</td>\n",
       "      <td>53</td>\n",
       "      <td>2276.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title  \\\n",
       "0   0  Amazon CEO Jeff Bezos is now the second riches...   \n",
       "1   1  Does Laura Dern Handle a Lightsaber in the New...   \n",
       "2   2  In this photographer’s home town, stepping out...   \n",
       "3   3  8 Ways To Get Your Spouse To Open Up More, Acc...   \n",
       "4   4  US says claim it supported IS in Syria is 'lud...   \n",
       "\n",
       "                                                text  title_length  \\\n",
       "0  More Try Yahoo Finance on Firefox » Amazon CEO...            64   \n",
       "1  More Laura Dern seems to be everywhere these d...            67   \n",
       "2  Kirkuk is a city of Northern Iraq in the Kurdi...            69   \n",
       "3  Experts say that communication is the cornerst...            66   \n",
       "4  Share this with Email Facebook Messenger Messe...            53   \n",
       "\n",
       "   text_length  is_title_na  is_text_na  \n",
       "0       3499.0            0           0  \n",
       "1       2296.0            0           0  \n",
       "2       4732.0            0           0  \n",
       "3       4485.0            0           0  \n",
       "4       2276.0            0           0  "
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns = ['id', 'title', 'text', 'title_length', 'text_length',\n",
    "       'is_title_na', 'is_text_na']\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_df.index == X_test.id).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = best_model.predict_proba(X_test).argmax(axis=1)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['news', 'clickbait', 'news', ..., 'news', 'news', 'news'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_label = le.inverse_transform(y_test_pred)\n",
    "y_test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.17000177, 0.74836196, 0.08163627])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test_pred) / len(y_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>clickbait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id      label\n",
       "0   0       news\n",
       "1   1  clickbait\n",
       "2   2       news\n",
       "3   3  clickbait\n",
       "4   4       news"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.DataFrame({'id': X_test['id'], 'label': y_test_label})\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id,label\n",
      "0,news\n",
      "1,clickbait\n",
      "2,news\n",
      "3,clickbait\n",
      "4,news\n",
      "5,news\n",
      "6,news\n",
      "7,news\n",
      "8,news\n"
     ]
    }
   ],
   "source": [
    "!head submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5648 submission.csv\n"
     ]
    }
   ],
   "source": [
    "!wc -l submission.csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!kaggle competitions submit -c dlinnlp-spring-2019-clf -f submission.csv -m \"LR baseline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
