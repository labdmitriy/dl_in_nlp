{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    data_path = Path('../data'),\n",
    "    split_ratio = 0.8,\n",
    "    max_vocab_size = None,\n",
    "    min_freq = 1, \n",
    "    \n",
    "    epochs = 1, \n",
    "    batch_size = 64,\n",
    "    \n",
    "    random_seed = 17,\n",
    "    \n",
    "    device = 'cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "args.device = torch.device('cuda' if (torch.cuda.is_available and (args.device == 'cuda')) else 'cpu')\n",
    "print(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, device):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed_everywhere(args.random_seed, args.device)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24871, 3) (3552, 3) (28423, 3) (5647, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Index(['label', 'title', 'text'], dtype='object'),\n",
       " Index(['label', 'title', 'text'], dtype='object'),\n",
       " Index(['label', 'title', 'text'], dtype='object'),\n",
       " Index(['id', 'title', 'text'], dtype='object'))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(args.data_path/'train.csv')\n",
    "valid_df = pd.read_csv(args.data_path/'valid.csv')\n",
    "test_df = pd.read_csv(args.data_path/'test.csv', names=['id', 'title', 'text'], header=0)\n",
    "\n",
    "train_df = train_df.fillna('')\n",
    "valid_df = valid_df.fillna('')\n",
    "test_df = test_df.fillna('')\n",
    "\n",
    "full_train_df = pd.concat([train_df, valid_df], axis=0, ignore_index=True)\n",
    "\n",
    "print(train_df.shape, valid_df.shape, full_train_df.shape, test_df.shape)\n",
    "train_df.columns, valid_df.columns, full_train_df.columns, test_df.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json(args.data_path/'train.json', orient='records', lines=True)\n",
    "valid_df.to_json(args.data_path/'valid.json', orient='records', lines=True)\n",
    "full_train_df.to_json(args.data_path/'full_train.json', orient='records', lines=True)\n",
    "\n",
    "test_df.to_json(args.data_path/'test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!head -1 {DATA_PATH/'train.json'}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = data.Field()\n",
    "TITLE = data.Field()\n",
    "TEXT = data.Field()\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fields = {'title': ('title', TITLE), 'text': ('text', TEXT), 'label': ('label', LABEL)}\n",
    "test_fields = {'id': ('id', ID), 'title': ('title', TITLE), 'text': ('text', TEXT)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28423"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_data, = data.TabularDataset.splits(\n",
    "    path = '../data/',\n",
    "    train = 'full_train.json',\n",
    "    format = 'json',\n",
    "    fields = train_fields,\n",
    ")\n",
    "\n",
    "len(full_train_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(vars(full_train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22738, 5685)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, valid_data = full_train_data.split(\n",
    "    split_ratio = args.split_ratio,\n",
    "    stratified = True, \n",
    "    strata_field = 'label',\n",
    "    random_state = random.seed(args.random_seed)\n",
    ")\n",
    "\n",
    "len(train_data), len(valid_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(vars(train_data[0]), vars(valid_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': [], 'text': ['Your', 'site', 'appears', 'to', 'be', 'broken', 'in', 'Chrome', 'at', 'least.', 'The', 'questions', 'section', 'is', 'unstyled', 'in', 'full', 'desktop', 'width', '(its', 'edge', 'to', 'edge', 'which', 'looks', 'pretty', 'bad', 'compared', 'to', 'the', 'rest', 'of', 'the', 'site)', 'and', 'there', 'is', 'no', 'form', 'below', 'the', '\"fill', 'out', 'the', 'simple', 'form', 'below\"', 'Oh', 'wait', 'I', 'have', 'to', 'click', 'to', 'show', 'the', 'form?', 'Why', 'do', 'that', 'when', 'the', 'instruction', 'text', 'suggests', 'I', 'should', 'be', 'seeing', 'a', '2:', 'That', 'form', 'is', 'horrifyingly', 'bad.'], 'label': 'other'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5647"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data,  = data.TabularDataset.splits(\n",
    "    path = '../data/',\n",
    "    test = 'test.json',\n",
    "    format = 'json',\n",
    "    fields = test_fields,\n",
    ")\n",
    "\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(vars(test_data[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from torchtext.vocab import Vocab\n",
    "Vocab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('to', 4704),\n",
       " ('the', 3317),\n",
       " ('in', 3128),\n",
       " ('of', 2951),\n",
       " ('for', 2229),\n",
       " ('a', 2167),\n",
       " ('The', 1972),\n",
       " ('and', 1834),\n",
       " ('on', 1656),\n",
       " ('Trump', 1635)]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TITLE.build_vocab(train_data,\n",
    "                  max_size = args.max_vocab_size,\n",
    "                  min_freq = args.min_freq)\n",
    "\n",
    "print(len(TITLE.vocab))\n",
    "TITLE.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 523125),\n",
       " ('to', 292426),\n",
       " ('of', 252964),\n",
       " ('a', 243728),\n",
       " ('and', 238967),\n",
       " ('in', 191643),\n",
       " ('that', 115872),\n",
       " ('for', 98369),\n",
       " ('is', 95825),\n",
       " ('on', 90314)]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data,\n",
    "                 max_size = args.max_vocab_size,\n",
    "                 min_freq = args.min_freq)\n",
    "\n",
    "print(len(TEXT.vocab))\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('news', 13390), ('other', 5915), ('clickbait', 3433)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(len(LABEL.vocab))\n",
    "LABEL.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_within_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Defines an iterator that loads batches of data from a Dataset.\n",
       "\n",
       "Attributes:\n",
       "    dataset: The Dataset object to load Examples from.\n",
       "    batch_size: Batch size.\n",
       "    batch_size_fn: Function of three arguments (new example to add, current\n",
       "        count of examples in the batch, and current effective batch size)\n",
       "        that returns the new effective batch size resulting from adding\n",
       "        that example to a batch. This is useful for dynamic batching, where\n",
       "        this function would add to the current effective batch size the\n",
       "        number of tokens in the new example.\n",
       "    sort_key: A key to use for sorting examples in order to batch together\n",
       "        examples with similar lengths and minimize padding. The sort_key\n",
       "        provided to the Iterator constructor overrides the sort_key\n",
       "        attribute of the Dataset, or defers to it if None.\n",
       "    train: Whether the iterator represents a train set.\n",
       "    repeat: Whether to repeat the iterator for multiple epochs. Default: False.\n",
       "    shuffle: Whether to shuffle examples between epochs.\n",
       "    sort: Whether to sort examples according to self.sort_key.\n",
       "        Note that repeat, shuffle, and sort default to train, train, and\n",
       "        (not train).\n",
       "    sort_within_batch: Whether to sort (in descending order according to\n",
       "        self.sort_key) within each batch. If None, defaults to self.sort.\n",
       "        If self.sort is True and this is False, the batch is left in the\n",
       "        original (ascending) sorted order.\n",
       "    device (str or `torch.device`): A string or instance of `torch.device`\n",
       "        specifying which device the Variables are going to be created on.\n",
       "        If left as default, the tensors will be created on cpu. Default: None.\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/anaconda3/lib/python3.6/site-packages/torchtext/data/iterator.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.Iterator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter = data.BucketIterator.splits(\n",
    "    (train_data, valid_data),\n",
    "    batch_size = args.batch_size,\n",
    "    sort_within_batch = True,\n",
    "    sort_key=lambda x: data.interleave_keys(len(x.title), len(x.text)),\n",
    "    device = args.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.title]:[torch.LongTensor of size 24x64]\n",
       "\t[.text]:[torch.LongTensor of size 367x64]\n",
       "\t[.label]:[torch.LongTensor of size 64]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleFC(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, title):\n",
    "        embedded = self.embedding(title)\n",
    "        x = self.fc1(embedded)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41779, 100, 100, 3)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(TITLE.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 100\n",
    "output_dim = len(LABEL.vocab)\n",
    "\n",
    "input_dim, embedding_dim, hidden_dim, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleFC(input_dim, embedding_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4188303"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return np.sum(params.numel() for params in model.parameters() if params.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 64]\n",
      "\t[.title]:[torch.LongTensor of size 34x64]\n",
      "\t[.text]:[torch.LongTensor of size 847x64]\n",
      "\t[.label]:[torch.LongTensor of size 64]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([64]), torch.Size([34, 64, 3]))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch)\n",
    "\n",
    "y_true = batch.label\n",
    "y_pred = model(batch.title)\n",
    "y_true.shape, y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.label.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(batch.title)\n",
    "        f1_score = f1_score(batch.label, y_pred, average='macro')\n",
    "        \n",
    "        loss = criterion(y_pred, batch.label)\n",
    "        loss.backward()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_f1_score += f1_score.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_f1_score / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = model(batch.title)\n",
    "        f1_score = f1_score(batch.label, y_pred, average='macro')\n",
    "        \n",
    "        loss = criterion(y_pred, batch.label)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_f1_score += f1_score.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_f1_score / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'torch.dtype' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-7dd72d95c3ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbest_valid_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'torch.dtype' object is not callable"
     ]
    }
   ],
   "source": [
    "best_valid_loss = np.float('inf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
